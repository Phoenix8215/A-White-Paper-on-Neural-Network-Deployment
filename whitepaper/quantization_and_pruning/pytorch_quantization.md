# ğŸ¤ pytorch-quantizationä½¿ç”¨æ–‡æ¡£

### Basic Functionalities

#### Quantization function

`fake_tensor_quant` å‡½æ•°å¯¹è¾“å…¥çš„ tensor è¿›è¡Œ FQ æ“ä½œï¼Œå³ QDQ æ“ä½œï¼Œè¿”å›å‡é‡åŒ–å¼ é‡ï¼ˆæµ®ç‚¹å€¼ï¼‰ã€‚`tensor_quant` è¿”å›é‡åŒ–å¼ é‡ï¼ˆæ•´æ•°å€¼ï¼‰å’Œæ¯”ä¾‹ã€‚

```python
tensor_quant(inputs, amax, num_bits=8, output_dtype=torch.float, unsigned=False)
fake_tensor_quant(inputs, amax, num_bits=8, output_dtype=torch.float, unsigned=False)
```

Example:

```python
from pytorch_quantization import tensor_quant

# Generate random input. With fixed seed 12345, x should be
# tensor([0.9817, 0.8796, 0.9921, 0.4611, 0.0832, 0.1784, 0.3674, 0.5676, 0.3376, 0.2119])
torch.manual_seed(12345)
x = torch.rand(10)

# fake quantize tensor x. fake_quant_x will be
# tensor([0.9843, 0.8828, 0.9921, 0.4609, 0.0859, 0.1797, 0.3672, 0.5703, 0.3359, 0.2109])
fake_quant_x = tensor_quant.fake_tensor_quant(x, x.abs().max())

# quantize tensor x. quant_x will be
# tensor([126., 113., 127.,  59.,  11.,  23.,  47.,  73.,  43.,  27.])
# with scale=128.0057
quant_x, scale = tensor_quant.tensor_quant(x, x.abs().max())
```

è¿™ä¸¤ä¸ªå‡½æ•°çš„åå‘ä¼ æ’­å‡½æ•°è¢«å®šä¹‰ä¸º[ç›´é€šä¼°è®¡å™¨ï¼ˆSTEï¼‰](https://arxiv.org/pdf/1308.3432.pdf)ã€‚

#### Descriptor and quantizer

`QuantDescriptor` å®šä¹‰äº†å¼ é‡çš„é‡åŒ–æ–¹å¼ã€‚è¿˜æœ‰ä¸€äº›é¢„å®šä¹‰çš„ `QuantDescriptor`ï¼Œä¾‹å¦‚ `QUANT_DESC_8BIT_PER_TENSOR` å’Œ `QUANT_DESC_8BIT_CONV2D_WEIGHT_PER_CHANNEL`ã€‚

<mark style="color:red;">`TensorQuantizer`</mark> <mark style="color:red;"></mark><mark style="color:red;">æ˜¯ä¸“é—¨ç”¨æ¥é‡åŒ–å¼ é‡çš„ä¸€ä¸ªæ¨¡å—ï¼Œé‡åŒ–æ–¹å¼ç”±</mark> <mark style="color:red;"></mark><mark style="color:red;">`QuantDescriptor`</mark> <mark style="color:red;"></mark><mark style="color:red;">å®šä¹‰ã€‚</mark>

```python
from pytorch_quantization.tensor_quant import QuantDescriptor
from pytorch_quantization.nn.modules.tensor_quantizer import TensorQuantizer
import torch

quant_desc = QuantDescriptor(num_bits=4, fake_quant=False, axis=(0), unsigned=True)
quantizer = TensorQuantizer(quant_desc)

torch.manual_seed(12345)
x = torch.rand(10, 9, 8, 7)

quant_x = quantizer(x)
```

è¾“å‡ºç»“æœï¼š

```bash
tensor([[[[15., 13., 15.,  ...,  1.,  3.,  6.],
          [ 9.,  5.,  3.,  ..., 12., 14.,  4.],
          [ 3.,  7., 11.,  ...,  5., 10.,  6.],
          ....................................
          [ 8.,  1.,  6.,  ...,  7., 11., 10.],
          [ 7.,  5., 13.,  ...,  3.,  7., 14.],
          [14., 10., 11.,  ...,  2., 14.,  9.]]]])
```

æ¥çœ‹çœ‹æºç ä¸­å¯¹è¿™å‡ ä¸ªå‚æ•°çš„è§£é‡Šï¼š

```python
   """Supportive descriptor of quantization

    Describe how a tensor should be quantized. A QuantDescriptor and a tensor defines a quantized tensor.

    Args:
        num_bits: An integer. Number of bits of quantization. It is used to calculate scaling factor. Default 8.
        name: Seems a nice thing to have

    Keyword Arguments:
        fake_quant: A boolean. If True, use fake quantization mode. Default True.
        axis: None, int or tuple of int. axes which will have its own max for computing scaling factor.
            If None (the default), use per tensor scale.
            Must be in the range [-rank(input_tensor), rank(input_tensor)).
            e.g. For a KCRS weight tensor, quant_axis=(0) will yield per channel scaling.
            Default None.
        amax: A float or list/ndarray of floats of user specified absolute max range(ç»å¯¹å€¼æœ€å¤§çš„å…ƒç´ ). If supplied,
            ignore quant_axis and use this to quantize. If learn_amax is True, will be used to initialize
            learnable amax. Default None.
        learn_amax: A boolean. If True, learn amax. Default False.
        scale_amax: A float. If supplied, multiply amax by scale_amax. Default None. It is useful for some
            quick experiment.
        calib_method: A string. One of ["max", "histogram"] indicates which calibration to use. Except the simple
            max calibration, other methods are all hisogram based. Default "max".
        unsigned: A Boolean. If True, use unsigned. Default False.

    Raises:
        TypeError: If unsupported type is passed in.

    Read-only properties:
        - fake_quant:
        - name:
        - learn_amax:
        - scale_amax:
        - axis:
        - calib_method:
        - num_bits:
        - amax:
        - unsigned:
    """
```

#### Quantized module

è¯¥æ¨¡å—æœ‰ä¸¤ç§ä¸»è¦ç±»å‹ï¼š`Conv` å’Œ `Linear`ã€‚è¿™ä¸¤ç§æ¨¡å—éƒ½å¯ä»¥æ›¿ä»£ `torch.nn` ç‰ˆæœ¬ï¼Œå¹¶å¯¹æƒé‡å’Œæ¿€æ´»å€¼è¿›è¡Œé‡åŒ–ã€‚é™¤äº†åŸå§‹æ¨¡å—çš„å‚æ•°å¤–ï¼Œè¿™ä¸¤ç§æ¨¡å—éƒ½éœ€è¦ `quant_desc_input` å’Œ `quant_desc_weight`ã€‚

```python
from torch import nn

from pytorch_quantization import tensor_quant
import pytorch_quantization.nn as quant_nn

# pytorch's module
fc1 = nn.Linear(in_features, out_features, bias=True)
conv1 = nn.Conv2d(in_channels, out_channels, kernel_size)

# quantized version
quant_fc1 = quant_nn.Linear(
    in_features, out_features, bias=True,
    quant_desc_input=tensor_quant.QUANT_DESC_8BIT_PER_TENSOR,
    quant_desc_weight=tensor_quant.QUANT_DESC_8BIT_LINEAR_WEIGHT_PER_ROW)
quant_conv1 = quant_nn.Conv2d(
    in_channels, out_channels, kernel_size,
    quant_desc_input=tensor_quant.QUANT_DESC_8BIT_PER_TENSOR,
    quant_desc_weight=tensor_quant.QUANT_DESC_8BIT_CONV2D_WEIGHT_PER_CHANNEL)
```

ä»æºç å¯ä»¥æŸ¥çœ‹åˆ°æå‰å®šä¹‰å¥½çš„`descriptors`

```python
QUANT_DESC_8BIT_PER_TENSOR = QuantDescriptor(num_bits=8)
QUANT_DESC_UNSIGNED_8BIT_PER_TENSOR = QuantDescriptor(num_bits=8, unsigned=True)
QUANT_DESC_8BIT_CONV1D_WEIGHT_PER_CHANNEL = QuantDescriptor(num_bits=8, axis=(0))
QUANT_DESC_8BIT_CONV2D_WEIGHT_PER_CHANNEL = QuantDescriptor(num_bits=8, axis=(0))
QUANT_DESC_8BIT_CONV3D_WEIGHT_PER_CHANNEL = QuantDescriptor(num_bits=8, axis=(0))
QUANT_DESC_8BIT_LINEAR_WEIGHT_PER_ROW = QuantDescriptor(num_bits=8, axis=(0))
QUANT_DESC_8BIT_CONVTRANSPOSE1D_WEIGHT_PER_CHANNEL = QuantDescriptor(num_bits=8, axis=(0))
QUANT_DESC_8BIT_CONVTRANSPOSE2D_WEIGHT_PER_CHANNEL = QuantDescriptor(num_bits=8, axis=(0))
QUANT_DESC_8BIT_CONVTRANSPOSE3D_WEIGHT_PER_CHANNEL = QuantDescriptor(num_bits=8, axis=(0))
```

### <mark style="color:red;">Post training quantization</mark>

åªéœ€è°ƒç”¨ `quant_modules.initialize()`ï¼Œå³å¯å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒåé‡åŒ–(`PTQ`)ã€‚

```python
import torch
import torchvision
from pytorch_quantization import tensor_quant, quant_modules
from pytorch_quantization import nn as quant_nn

quant_modules.initialize()

model = torchvision.models.resnet18()
model.cuda()

inputs = torch.randn(1, 3, 224, 224, device='cuda')
quant_nn.TensorQuantizer.use_fb_fake_quant = True
torch.onnx.export(model, inputs, 'quant_resnet18.onnx', opset_version=13)
```

ä¸Šè¿°ç¤ºä¾‹ä»£ç é€šè¿‡æŒ‡å®š `quant_nn.TensorQuantizer.use_fb_fake_quant` æ¥å°† `resnet18` æ¨¡å‹ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹æ›¿æ¢ä¸º `QDQ` ç®—å­ï¼Œå¹¶å¯¼å‡ºä¸º `ONNX` æ ¼å¼çš„æ¨¡å‹æ–‡ä»¶ï¼Œå®ç°äº†æ¨¡å‹çš„é‡åŒ–ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼š

* `quant_modules.initialize()` å‡½æ•°ä¼šæŠŠ `PyTorch-Quantization` åº“ä¸­æ‰€æœ‰çš„é‡åŒ–ç®—å­æŒ‰ç…§æ•°æ®ç±»å‹ã€ä½å®½ç­‰ç‰¹æ€§è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å°†å…¶ä¿å­˜åœ¨å…¨å±€å˜é‡ `_DEFAULT_QUANT_MAP` ä¸­&#x20;
* <mark style="color:red;">å¯¼å‡ºçš„å¸¦æœ‰ QDQ èŠ‚ç‚¹çš„ ONNX æ¨¡å‹ä¸­ï¼Œå¯¹äºè¾“å…¥</mark> <mark style="color:red;"></mark><mark style="color:red;">`input`</mark><mark style="color:red;">çš„æ•´ä¸ª</mark> <mark style="color:red;"></mark><mark style="color:red;">`tensor`</mark><mark style="color:red;">æ˜¯å…±ç”¨ä¸€ä¸ª</mark> <mark style="color:red;"></mark><mark style="color:red;">`scale`</mark><mark style="color:red;">ï¼Œè€Œå¯¹äºæƒé‡</mark> <mark style="color:red;"></mark><mark style="color:red;">`weight`</mark><mark style="color:red;">åˆ™æ˜¯æ¯ä¸ª</mark> <mark style="color:red;"></mark><mark style="color:red;">`channel`</mark><mark style="color:red;">å…±ç”¨ä¸€ä¸ª</mark> <mark style="color:red;"></mark><mark style="color:red;">`scale`</mark>
* <mark style="color:red;">å¯¼å‡ºçš„å¸¦æœ‰ QDQ èŠ‚ç‚¹çš„ ONNX æ¨¡å‹ä¸­ï¼Œ</mark><mark style="color:red;">`x_zero_point`</mark><mark style="color:red;">æ˜¯ä¹‹å‰æåˆ°çš„åç§»é‡ï¼Œå…¶å€¼ä¸º0ï¼Œå› ä¸ºæ•´ä¸ªé‡åŒ–è¿‡ç¨‹æ˜¯å¯¹ç§°é‡åŒ–ï¼Œå…¶åç§»é‡ Z ä¸º0</mark>

ç”¨netronå¯è§†åŒ–é‡åŒ–åçš„æ¨¡å‹ï¼š

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (81).png" alt=""><figcaption></figcaption></figure>

#### Calibration

æ ¡å‡†æ˜¯ TensorRT çš„æœ¯è¯­ï¼Œå³æŠŠæ•°æ®æ ·æœ¬ä¼ é€’ç»™é‡åŒ–å™¨ï¼Œå¹¶å†³å®š`amax`(ç»å¯¹å€¼æœ€å¤§çš„å…ƒç´ )çš„æœ€ä½³å€¼ã€‚æˆ‘ä»¬æ”¯æŒ 4 ç§æ ¡å‡†æ–¹æ³•ï¼š

* `max`: åªéœ€ä½¿ç”¨å…¨å±€æœ€å¤§ç»å¯¹å€¼
* `entropy`: TensorRT çš„ç†µæ ¡å‡†
* `percentile`: æ ¹æ®ç»™å®šçš„ç™¾åˆ†ä½æ•°å»é™¤ç¦»ç¾¤å€¼ã€‚
* `mse`: åŸºäº MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰çš„æ ¡å‡†

ä»¥ä¸‹ç¤ºä¾‹æ ¡å‡†æ–¹æ³•è®¾ç½®ä¸º `mse`ï¼š

```python
# Find the TensorQuantizer and enable calibration
for name, module in model.named_modules():
    if name.endswith('_quantizer'):
        module.enable_calib()
        module.disable_quant()  # Use full precision data to calibrate

# Feeding data samples
model(x)
# ...

# Finalize calibration
for name, module in model.named_modules():
    if name.endswith('_quantizer'):
        module.load_calib_amax()
        module.disable_calib()
        module.enable_quant()

# If running on GPU, it needs to call .cuda() again because new tensors will be created by calibration process
model.cuda()

# Keep running the quantized model
# ...
```

{% hint style="info" %}
åœ¨å°†æ¨¡å‹å¯¼å‡ºåˆ° ONNX ä¹‹å‰éœ€è¦è¿›è¡Œæ ¡å‡†ã€‚
{% endhint %}

### Quantization Aware Training

`Quantization Aware Training` åŸºäºç›´é€šä¼°è®¡ï¼ˆSTEï¼‰å¯¼æ•°è¿‘ä¼¼ã€‚å®ƒæœ‰æ—¶è¢«ç§°ä¸º "é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ"ã€‚

æ ¡å‡†å®Œæˆåï¼Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒåªéœ€é€‰æ‹©ä¸€ä¸ªè®­ç»ƒè®¡åˆ’ï¼Œç„¶åç»§ç»­è®­ç»ƒæ ¡å‡†åçš„æ¨¡å‹ã€‚é€šå¸¸ï¼Œå®ƒä¸éœ€è¦å¾®è°ƒå¾ˆé•¿æ—¶é—´ã€‚æˆ‘ä»¬é€šå¸¸ä½¿ç”¨åŸå§‹è®­ç»ƒè®¡åˆ’çš„ 10% å·¦å³ï¼Œä»åˆå§‹è®­ç»ƒå­¦ä¹ ç‡çš„ 1% å¼€å§‹ï¼Œä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡ï¼ŒæŒ‰ç…§ä½™å¼¦å‘¨æœŸçš„ä¸€åŠé€’å‡ï¼Œç›´åˆ°åˆå§‹å¾®è°ƒå­¦ä¹ ç‡çš„ 1% ï¼ˆåˆå§‹è®­ç»ƒå­¦ä¹ ç‡çš„ 0.01%ï¼‰ã€‚

#### Some recommendations

é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªç¦»æ•£æ•°å€¼ä¼˜åŒ–é—®é¢˜ï¼‰åœ¨æ•°å­¦ä¸Šå¹¶ä¸æ˜¯ä¸€ä¸ªå·²ç»è§£å†³çš„é—®é¢˜ã€‚æ ¹æ®æˆ‘ä»¬çš„ç»éªŒï¼Œè¿™é‡Œæœ‰ä¸€äº›å»ºè®®ï¼š

* è¦ä½¿ STE è¿‘ä¼¼æ•ˆæœè‰¯å¥½ï¼Œæœ€å¥½ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ã€‚å¤§çš„å­¦ä¹ ç‡æ›´æœ‰å¯èƒ½æ‰©å¤§ STE è¿‘ä¼¼å¼•å…¥çš„æ–¹å·®ï¼Œç ´åè®­ç»ƒå¥½çš„ç½‘ç»œã€‚
* åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è¦æ”¹å˜é‡åŒ–scaleï¼Œè‡³å°‘ä¸è¦è¿‡äºé¢‘ç¹ã€‚æ¯ä¸€æ­¥éƒ½æ”¹å˜scaleï¼Œå®é™…ä¸Šå°±ç­‰äºæ¯ä¸€æ­¥éƒ½æ”¹å˜æ•°æ®æ ¼å¼ï¼ˆe8m7ã€e5m10ã€e3m4 ç­‰ï¼‰ï¼Œè¿™å¾ˆå®¹æ˜“å½±å“æ”¶æ•›æ€§ã€‚

### Export to ONNX

å¯¼å‡ºåˆ° ONNX çš„ç›®çš„æ˜¯éƒ¨ç½²åˆ° TensorRTï¼Œå› æ­¤ï¼Œæˆ‘ä»¬åª<mark style="color:red;">å°†å‡é‡åŒ–æ¨¡å‹å¯¼å‡ºä¸º TensorRT å¯ä»¥æ¥å—çš„å½¢å¼</mark>ã€‚å‡é‡åŒ–å°†åˆ†è§£ä¸ºä¸€å¯¹ `QuantizeLinear/DequantizeLinear` ONNX æ“ä½œã€‚TensorRT å°†è·å–ç”Ÿæˆçš„ ONNX å›¾ï¼Œå¹¶ä»¥æœ€ä¼˜åŒ–çš„æ–¹å¼åœ¨ int8 ä¸­æ‰§è¡Œã€‚

{% hint style="info" %}
ç›®å‰ï¼Œæˆ‘ä»¬åªæ”¯æŒå¯¼å‡º int8 å’Œ fp8 å‡é‡åŒ–æ¨¡å—ã€‚æ­¤å¤–ï¼Œé‡åŒ–æ¨¡å—åœ¨å¯¼å‡ºåˆ° ONNX ä¹‹å‰éœ€è¦è¿›è¡Œæ ¡å‡†ã€‚
{% endhint %}

å‡é‡åŒ–æ¨¡å‹å¯ä»¥åƒå…¶ä»– Pytorch æ¨¡å‹ä¸€æ ·å¯¼å‡ºåˆ° ONNXã€‚æœ‰å…³å°† Pytorch æ¨¡å‹å¯¼å‡ºåˆ° ONNX çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—® [torch.onnx](https://pytorch.org/docs/stable/onnx.html?highlight=onnx#module-torch.onnx)ã€‚ä¾‹å¦‚

```python
import pytorch_quantization
from pytorch_quantization import nn as quant_nn
from pytorch_quantization import quant_modules

quant_modules.initialize()
model = torchvision.models.resnet50()

# load the calibrated model
state_dict = torch.load("quant_resnet50-entropy-1024.pth", map_location="cpu")
model.load_state_dict(state_dict)
model.cuda()

dummy_input = torch.randn(128, 3, 224, 224, device='cuda')

input_names = [ "actual_input_1" ]
output_names = [ "output1" ]

with pytorch_quantization.enable_onnx_export():
     # enable_onnx_checker needs to be disabled. See notes below.
     torch.onnx.export(
         model, dummy_input, "quant_resnet50.onnx", verbose=True, opset_version=10, enable_onnx_checker=False
         )
```

{% hint style="info" %}
è¯·æ³¨æ„ï¼Œ`opset13` ä¸­çš„ `QuantizeLinear` å’Œ `DequantizeLinear` éƒ½æ·»åŠ äº†`axis`ã€‚
{% endhint %}

### Quantizing Resnet50

#### Create a quantized model

```python
import torch
import torch.utils.data
from torch import nn

from pytorch_quantization import nn as quant_nn
from pytorch_quantization import calib
from pytorch_quantization.tensor_quant import QuantDescriptor

from torchvision import models

sys.path.append("path to torchvision/references/classification/")
from train import evaluate, train_one_epoch, load_data
```

**Adding quantized modules**

ç¬¬ä¸€æ­¥æ˜¯åœ¨ç¥ç»ç½‘ç»œå›¾ä¸­æ·»åŠ é‡åŒ–æ¨¡å—ã€‚ä¾‹å¦‚ï¼Œ`quant_nn.QuantLinear` å¯ä»¥ç”¨æ¥æ›¿ä»£ `nn.Linear`ã€‚<mark style="color:red;">è¿™äº›é‡åŒ–å±‚å¯ä»¥é€šè¿‡ "</mark><mark style="color:red;">`Monkey-patching`</mark> <mark style="color:red;"></mark><mark style="color:red;">"è‡ªåŠ¨æ›¿æ¢ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æ‰‹åŠ¨ä¿®æ”¹æ¨¡å‹å®šä¹‰æ¥æ›¿æ¢ã€‚è‡ªåŠ¨å±‚æ›¿æ¢æ˜¯é€šè¿‡</mark> <mark style="color:red;"></mark><mark style="color:red;">`quant_modules`</mark><mark style="color:red;">å®Œæˆçš„ï¼Œåº”åœ¨åˆ›å»ºæ¨¡å‹å‰è°ƒç”¨å®ƒã€‚</mark>

```python
from pytorch_quantization import quant_modules
quant_modules.initialize()
```

<mark style="color:red;">è¿™å°†é€‚ç”¨äºæ¯ä¸ªæ¨¡å—çš„æ‰€æœ‰å®ä¾‹ã€‚å¦‚æœä¸å¸Œæœ›å¯¹æ‰€æœ‰æ¨¡å—è¿›è¡Œé‡åŒ–ï¼Œåˆ™åº”æ‰‹åŠ¨æ›¿æ¢å·²é‡åŒ–çš„æ¨¡å—ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨</mark> <mark style="color:red;"></mark><mark style="color:red;">`quant_nn.TensorQuantizer`</mark> <mark style="color:red;"></mark><mark style="color:red;">å°†é‡åŒ–å™¨æ·»åŠ åˆ°æ¨¡å‹ä¸­ã€‚</mark>

{% hint style="info" %}
`Monkey-patching` æ˜¯ä¸€ç§ç¼–ç¨‹æœ¯è¯­ï¼ŒæŒ‡çš„æ˜¯åœ¨è¿è¡Œæ—¶åŠ¨æ€ä¿®æ”¹æˆ–æ‰©å±•ç°æœ‰çš„ä»£ç ï¼Œé€šå¸¸æ˜¯åœ¨ä¸ä¿®æ”¹åŸå§‹æºä»£ç çš„æƒ…å†µä¸‹å®ç°ã€‚è¿™ç§æŠ€æœ¯å…è®¸å¼€å‘è€…åœ¨ç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­ä¿®æ”¹ç±»ã€å‡½æ•°ã€æ–¹æ³•æˆ–æ¨¡å—çš„è¡Œä¸ºï¼Œä»¥æ»¡è¶³ç‰¹å®šçš„éœ€æ±‚æˆ–ä¿®å¤ `bug`ã€‚
{% endhint %}

#### Post training quantization

ä¸ºäº†æé«˜æ¨ç†æ•ˆç‡ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸ºæ¯ä¸ªé‡åŒ–å™¨é€‰æ‹©ä¸€ä¸ªå›ºå®šçš„èŒƒå›´ã€‚ä»é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹å¼€å§‹ï¼Œæœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯æ ¡å‡†ã€‚

**Calibration**

<mark style="color:red;">æˆ‘ä»¬å¯¹æ¿€æ´»å€¼ä½¿ç”¨åŸºäºç›´æ–¹å›¾çš„æ ¡å‡†æ–¹å¼ï¼Œå¯¹æ¨¡å‹æƒé‡ä½¿ç”¨åŸºäºæœ€å¤§å€¼çš„æ ¡å‡†æ–¹å¼ã€‚</mark>

```python
quant_desc_input = QuantDescriptor(calib_method='histogram')
quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)
quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)

model = models.resnet50(pretrained=True)
model.cuda()
```

è¦æ”¶é›†æ¿€æ´»å€¼çš„ç›´æ–¹å›¾ï¼Œæˆ‘ä»¬å¿…é¡»å‘æ¨¡å‹è¾“å…¥æ ·æœ¬æ•°æ®ã€‚é¦–å…ˆï¼ŒæŒ‰ç…§è®­ç»ƒè„šæœ¬åˆ›å»º `ImageNet` æ•°æ®åŠ è½½å™¨ã€‚ç„¶åï¼Œåœ¨æ¯ä¸ªé‡åŒ–å™¨ä¸­å¯ç”¨æ ¡å‡†ï¼Œå¹¶å°†è®­ç»ƒæ•°æ®è¾“å…¥æ¨¡å‹ã€‚`1024` ä¸ªæ ·æœ¬ï¼ˆ2 æ‰¹ï¼Œæ¯æ‰¹ 512 ä¸ªï¼‰è¶³ä»¥ä¼°è®¡æ¿€æ´»å€¼çš„åˆ†å¸ƒã€‚

```python
data_path = "PATH to imagenet"
batch_size = 512

traindir = os.path.join(data_path, 'train')
valdir = os.path.join(data_path, 'val')
dataset, dataset_test, train_sampler, test_sampler = load_data(traindir, valdir, False, False)

data_loader = torch.utils.data.DataLoader(
    dataset, batch_size=batch_size,
    sampler=train_sampler, num_workers=4, pin_memory=True)

data_loader_test = torch.utils.data.DataLoader(
    dataset_test, batch_size=batch_size,
    sampler=test_sampler, num_workers=4, pin_memory=True)
```

```python
 def collect_stats(model, data_loader, num_batches):
     """Feed data to the network and collect statistic"""

     # Enable calibrators
     for name, module in model.named_modules():
         if isinstance(module, quant_nn.TensorQuantizer):
             if module._calibrator is not None:
                 module.disable_quant()
                 module.enable_calib()
             else:
                 module.disable()

     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):
         model(image.cuda())
         if i >= num_batches:
             break

     # Disable calibrators
     for name, module in model.named_modules():
         if isinstance(module, quant_nn.TensorQuantizer):
             if module._calibrator is not None:
                 module.enable_quant()
                 module.disable_calib()
             else:
                 module.enable()

 def compute_amax(model, **kwargs):
     # Load calib result
     for name, module in model.named_modules():
         if isinstance(module, quant_nn.TensorQuantizer):
             if module._calibrator is not None:
                 if isinstance(module._calibrator, calib.MaxCalibrator):
                     module.load_calib_amax()
                 else:
                     module.load_calib_amax(**kwargs)
             print(F"{name:40}: {module}")
     model.cuda()

# It is a bit slow since we collect histograms on CPU
 with torch.no_grad():
     collect_stats(model, data_loader, num_batches=2)
     compute_amax(model, method="percentile", percentile=99.99)
```

æ ¡å‡†å®Œæˆåï¼Œé‡åŒ–å™¨å°†è®¾ç½®ä¸€ä¸ªæœ€å¤§å€¼ï¼ˆ`amax`ï¼‰ï¼Œè¡¨ç¤ºé‡åŒ–ç©ºé—´ä¸­å¯è¡¨ç¤ºçš„ç»å¯¹å€¼æœ€å¤§çš„è¾“å…¥ã€‚<mark style="color:red;">é»˜è®¤æƒ…å†µä¸‹ï¼Œæƒé‡</mark><mark style="color:red;">`scale`</mark><mark style="color:red;">ä¸º</mark><mark style="color:red;">`per channel`</mark><mark style="color:red;">çš„ï¼Œè€Œæ¿€æ´»å‡½æ•°çš„</mark><mark style="color:red;">`scale`</mark><mark style="color:red;">ä¸º</mark><mark style="color:red;">`per tensor`</mark><mark style="color:red;">çš„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ‰“å°æ¯ä¸ª</mark> <mark style="color:red;"></mark><mark style="color:red;">`TensorQuantizer`</mark> <mark style="color:red;"></mark><mark style="color:red;">æ¨¡å—æ¥æŸ¥çœ‹</mark> <mark style="color:red;"></mark><mark style="color:red;">`amax`</mark><mark style="color:red;">ã€‚</mark>

```
conv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.6400 calibrator=MaxCalibrator(track_amax=False) quant)
conv1._weight_quantizer                 : TensorQuantizer(8bit fake axis=(0) amax=[0.0000, 0.7817](64) calibrator=MaxCalibrator(track_amax=False) quant)
layer1.0.conv1._input_quantizer         : TensorQuantizer(8bit fake per-tensor amax=6.8645 calibrator=MaxCalibrator(track_amax=False) quant)
layer1.0.conv1._weight_quantizer        : TensorQuantizer(8bit fake axis=(0) amax=[0.0000, 0.7266](64) calibrator=MaxCalibrator(track_amax=False) quant)
...
```

**Evaluate the calibrated model**

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åœ¨ ImageNet éªŒè¯é›†ä¸Šè¯„ä¼°è®­ç»ƒåé‡åŒ–(PTQ)æ¨¡å‹çš„åˆ†ç±»å‡†ç¡®æ€§ã€‚

```python
criterion = nn.CrossEntropyLoss()
with torch.no_grad():
    evaluate(model, criterion, data_loader_test, device="cuda", print_freq=20)

# Save the model
torch.save(model.state_dict(), "/tmp/quant_resnet50-calibrated.pth")
```

`top-1` çš„å‡†ç¡®ç‡ä¸º `76.1%`ï¼Œæ¥è¿‘é¢„è®­ç»ƒæ¨¡å‹ `76.2%` çš„å‡†ç¡®ç‡ã€‚

**Use different calibration**

æˆ‘ä»¬å¯ä»¥å°è¯•ä¸åŒçš„æ ¡å‡†æ–¹å¼ï¼Œè€Œæ— éœ€é‡æ–°æ”¶é›†ç›´æ–¹å›¾ï¼Œçœ‹çœ‹å“ªç§æ ¡å‡†æ–¹å¼èƒ½è·å¾—æœ€ä½³ç²¾åº¦ã€‚

```python
with torch.no_grad():
    compute_amax(model, method="percentile", percentile=99.9)
    evaluate(model, criterion, data_loader_test, device="cuda", print_freq=20)

with torch.no_grad():
    for method in ["mse", "entropy"]:
        print(F"{method} calibration")
        compute_amax(model, method=method)
        evaluate(model, criterion, data_loader_test, device="cuda", print_freq=20)
```

MSE å’Œç†µæ ¡å‡†æ¨¡å‹å‡†ç¡®ç‡å‡è¶…è¿‡ 76%ã€‚å¯¹äº resnet50 è€Œè¨€ï¼Œ99.9%åˆ†ä½æ•°è¿‡æ»¤çš„æ•°å€¼è¿‡å¤šï¼Œå‡†ç¡®ç‡ä¼šç¨ä½ã€‚

#### Quantization Aware Training

æˆ‘ä»¬è¿˜å¯ä»¥é€‰æ‹©å¯¹æ ¡å‡†æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥è¿›ä¸€æ­¥æé«˜ç²¾åº¦ã€‚

```python
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)

# Training takes about one and half hour per epoch on a single V100
train_one_epoch(model, criterion, optimizer, data_loader, "cuda", 0, 100)

# Save the model
torch.save(model.state_dict(), "/tmp/quant_resnet50-finetuned.pth")
```

ç»è¿‡ä¸€ä¸ª`epoch`çš„å¾®è°ƒï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—è¶…è¿‡`76.4%`çš„`top-1`å‡†ç¡®ç‡ã€‚åˆ©ç”¨ä½™å¼¦é€€ç«ç®—æ³•è¡°å‡å­¦ä¹ ç‡å¯¹æ›´å¤šçš„`epoch`è¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜å‡†ç¡®ç‡ã€‚ä¾‹å¦‚ï¼Œä»å­¦ä¹ ç‡ä¸º `0.001` å¼€å§‹ï¼Œä½¿ç”¨ä½™å¼¦é€€ç«å¯¹ 15 ä¸ª `epoch` è¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥è·å¾— `76.7%` ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚

**Further optimization**

ä¸ºäº†åœ¨ TensorRT ä¸Šå®ç°é«˜æ•ˆæ¨ç†ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£è¿è¡Œæ—¶ä¼˜åŒ–çš„æ›´å¤šç»†èŠ‚ã€‚TensorRT æ”¯æŒé‡åŒ–å·ç§¯å’Œæ®‹å·®åŠ æ³•çš„èåˆã€‚æ–°çš„èåˆç®—å­æœ‰ä¸¤ä¸ªè¾“å…¥ã€‚æˆ‘ä»¬ç§°å®ƒä»¬ä¸ºå·ç§¯è¾“å…¥å’Œæ®‹å·®è¾“å…¥ã€‚åœ¨è¿™é‡Œï¼Œèåˆç®—å­çš„è¾“å‡ºç²¾åº¦å¿…é¡»ä¸æ®‹å·®è¾“å…¥ç²¾åº¦ç›¸åŒ¹é…ã€‚å¦‚æœåœ¨èåˆç®—å­ä¹‹åè¿˜æœ‰å¦ä¸€ä¸ªé‡åŒ–èŠ‚ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ®‹å·®è¾“å…¥å’Œå…ƒç´ ç›¸åŠ èŠ‚ç‚¹ä¹‹é—´æ’å…¥ä¸€å¯¹QDQèŠ‚ç‚¹ï¼Œè¿™æ ·å·ç§¯èŠ‚ç‚¹ä¹‹åçš„é‡åŒ–èŠ‚ç‚¹å°±ä¼šä¸å·ç§¯èŠ‚ç‚¹èåˆï¼Œå·ç§¯èŠ‚ç‚¹å°±ä¼šå®Œå…¨é‡åŒ–ä¸º INT8 è¾“å…¥å’Œè¾“å‡ºã€‚æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨çŒ´å­è¡¥ä¸æ¥è‡ªåŠ¨åº”ç”¨è¿™ç§ä¼˜åŒ–ï¼Œè€Œéœ€è¦æ‰‹åŠ¨æ’å…¥QDQèŠ‚ç‚¹ã€‚

é¦–å…ˆä» [https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py) åˆ›å»º resnet.py çš„å‰¯æœ¬ï¼Œä¿®æ”¹æ„é€ å‡½æ•°ï¼Œæ˜¾å¼æ·»åŠ  bool ç±»å‹çš„é‡åŒ–æ ‡å¿—

```python
def resnet50(pretrained: bool = False, progress: bool = True, quantize: bool = False, **kwargs: Any) -> ResNet:
    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, quantize, **kwargs)
def _resnet(arch: str, block: Type[Union[BasicBlock, Bottleneck]], layers: List[int], pretrained: bool, progress: bool,
            quantize: bool, **kwargs: Any) -> ResNet:
    model = ResNet(block, layers, quantize, **kwargs)
class ResNet(nn.Module):
    def __init__(self,
                 block: Type[Union[BasicBlock, Bottleneck]],
                 layers: List[int],
                 quantize: bool = False,
                 num_classes: int = 1000,
                 zero_init_residual: bool = False,
                 groups: int = 1,
                 width_per_group: int = 64,
                 replace_stride_with_dilation: Optional[List[bool]] = None,
                 norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:
        super(ResNet, self).__init__()
        self._quantize = quantize
```

å½“ `self._quantize` æ ‡å¿—è®¾ç½®ä¸º `True` æ—¶ï¼Œ `quant_nn.QuantConv2d` å°†æ›¿æ¢æ‰€æœ‰ `nn.Conv2d`ã€‚

```python
def conv3x3(in_planes: int,
            out_planes: int,
            stride: int = 1,
            groups: int = 1,
            dilation: int = 1,
            quantize: bool = False) -> nn.Conv2d:
    """3x3 convolution with padding"""
    if quantize:
        return quant_nn.QuantConv2d(in_planes,
                                    out_planes,
                                    kernel_size=3,
                                    stride=stride,
                                    padding=dilation,
                                    groups=groups,
                                    bias=False,
                                    dilation=dilation)
    else:
        return nn.Conv2d(in_planes,
                         out_planes,
                         kernel_size=3,
                         stride=stride,
                         padding=dilation,
                         groups=groups,
                         bias=False,
                         dilation=dilation)
  def conv1x1(in_planes: int, out_planes: int, stride: int = 1, quantize: bool = False) -> nn.Conv2d:
      """1x1 convolution"""
      if quantize:
          return quant_nn.QuantConv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)
      else:
          return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)
```

åœ¨ `BasicBlock` å’Œ `Bottleneck` ä¸­éƒ½å¯ä»¥æ‰¾åˆ°æ®‹å·® conv addã€‚æˆ‘ä»¬é¦–å…ˆéœ€è¦åœ¨ `__init__` å‡½æ•°ä¸­å£°æ˜é‡åŒ–èŠ‚ç‚¹ã€‚

```python
def __init__(self,
             inplanes: int,
             planes: int,
             stride: int = 1,
             downsample: Optional[nn.Module] = None,
             groups: int = 1,
             base_width: int = 64,
             dilation: int = 1,
             norm_layer: Optional[Callable[..., nn.Module]] = None,
             quantize: bool = False) -> None:
    # other code...
    self._quantize = quantize
    if self._quantize:
        self.residual_quantizer = quant_nn.TensorQuantizer(quant_nn.QuantConv2d.default_quant_desc_input)
```

æœ€åï¼Œæˆ‘ä»¬éœ€è¦å¯¹ `BasicBlock` å’Œ `Bottleneck` ä¸­çš„`forward`å‡½æ•°è¿›è¡Œä¿®æ”¹ï¼Œåœ¨æ­¤å¤„æ’å…¥é¢å¤–çš„QDQèŠ‚ç‚¹ã€‚

```python
def forward(self, x: Tensor) -> Tensor:
    # other code...
    if self._quantize:
        out += self.residual_quantizer(identity)
    else:
        out += identity
    out = self.relu(out)

    return out
```

é‡åŒ–åçš„æœ€ç»ˆ resnet ä»£ç è§ [https://github.com/NVIDIA/TensorRT/blob/master/tools/pytorch-quantization/examples/torchvision/models/classification/resnet.py](https://github.com/NVIDIA/TensorRT/blob/master/tools/pytorch-quantization/examples/torchvision/models/classification/resnet.py)

### Creating Custom Quantized Modules

æä¾›äº†ä»¥ä¸‹å‡ ä¸ªé‡åŒ–æ¨¡å—ï¼š

* QuantConv1d, QuantConv2d, QuantConv3d, QuantConvTranspose1d, QuantConvTranspose2d, QuantConvTranspose3d
* QuantLinear
* QuantAvgPool1d, QuantAvgPool2d, QuantAvgPool3d, QuantMaxPool1d, QuantMaxPool2d, QuantMaxPool3d

è¦é‡åŒ–ä¸€ä¸ªæ¨¡å—ï¼Œæˆ‘ä»¬éœ€è¦é‡åŒ–è¾“å…¥å’Œæƒé‡ã€‚ä»¥ä¸‹æ˜¯ 3 ç§ä¸»è¦ç”¨ä¾‹ï¼š

1. ä¸ºåªæœ‰è¾“å…¥çš„æ¨¡å—åˆ›å»ºé‡åŒ–åŒ…è£…å™¨
2. ä¸ºå…·æœ‰è¾“å…¥å’Œæƒé‡çš„æ¨¡å—åˆ›å»ºé‡åŒ–åŒ…è£…å™¨ã€‚
3. ç›´æ¥å°† `TensorQuantizer` æ¨¡å—æ·»åŠ åˆ°æ¨¡å‹ä¸­æŸä¸ªç®—å­çš„è¾“å…¥ç«¯ã€‚

å¦‚æœéœ€è¦ç”¨é‡åŒ–ç‰ˆæœ¬è‡ªåŠ¨æ›¿æ¢åŸå§‹æ¨¡å—ï¼ˆå›¾ä¸­çš„èŠ‚ç‚¹ï¼‰ï¼Œå‰ä¸¤ç§æ–¹æ³•éå¸¸æœ‰ç”¨ã€‚å¦‚æœéœ€è¦åœ¨éå¸¸ç‰¹å®šçš„ä½ç½®æ‰‹åŠ¨å°†é‡åŒ–æ·»åŠ åˆ°æ¨¡å‹ä¸­ï¼Œç¬¬ä¸‰ç§æ–¹æ³•å¯èƒ½ä¼šéå¸¸æœ‰ç”¨ï¼ˆæ›´å¤šæ‰‹åŠ¨æ“ä½œï¼Œæ›´å¤šæ§åˆ¶ï¼‰ã€‚

ä¸‹é¢æˆ‘ä»¬é€šè¿‡ç¤ºä¾‹æ¥äº†è§£æ¯ç§ç”¨ä¾‹ã€‚

#### Quantizing Modules With Only Inputs

ä¸€ä¸ªåˆé€‚çš„ä¾‹å­æ˜¯é‡åŒ– `pooling` æ¨¡å—.

æˆ‘ä»¬éœ€è¦æä¾›ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒä»¥åŸå§‹æ¨¡å—ä¸ºè¾“å…¥ï¼Œå¹¶åœ¨å…¶å‘¨å›´æ·»åŠ  `TensorQuantizer` æ¨¡å—ï¼Œä»¥ä¾¿å¯¹å…¶è¾“å…¥è¿›è¡Œé‡åŒ–ï¼Œç„¶åå†å°†ç»“æœè¾“å…¥åˆ°åŸå§‹æ¨¡å—ã€‚

* é€šè¿‡`pooling.MaxPool2d`å’Œ`_utils.QuantInputMixin`æ¥åˆ›å»ºå°è£…å™¨ã€‚

```python
class QuantMaxPool2d(pooling.MaxPool2d, _utils.QuantInputMixin):
```

* `__init__.py` å‡½æ•°å°†è°ƒç”¨åŸå§‹æ¨¡å—çš„ `init`å‡½æ•°ï¼Œå¹¶æä¾›ç›¸åº”çš„å‚æ•°ã€‚åªæœ‰ä¸€ä¸ªä½¿ç”¨ `**kwargs` çš„é™„åŠ å‚æ•°åŒ…å«é‡åŒ–é…ç½®ä¿¡æ¯ã€‚`QuantInputMixin` å·¥å…·åŒ…å« `pop_quant_desc_in_kwargs` æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»è¾“å…¥ä¸­æå–é‡åŒ–é…ç½®ä¿¡æ¯ï¼Œå¦‚æœè¾“å…¥ä¸ºç©ºï¼Œåˆ™è¿”å›é»˜è®¤å€¼ã€‚æœ€åè°ƒç”¨ `init_quantizer` æ–¹æ³•ï¼Œåˆå§‹åŒ– `TensorQuantizer` æ¨¡å—ï¼Œè¯¥æ¨¡å—ä¼šå°†è¾“å…¥å€¼è¿›è¡Œé‡åŒ–ã€‚

```python
def __init__(self, kernel_size, stride=None, padding=0, dilation=1,
             return_indices=False, ceil_mode=False, **kwargs):
    super(QuantMaxPool2d, self).__init__(kernel_size, stride, padding, dilation,
                                         return_indices, ceil_mode)
    quant_desc_input = _utils.pop_quant_desc_in_kwargs(self.__class__, input_only=True, **kwargs)
    self.init_quantizer(quant_desc_input)
```

* åˆå§‹åŒ–å®Œæˆåï¼Œæˆ‘ä»¬éœ€è¦åœ¨å°è£…æ¨¡å—ä¸­å®šä¹‰`forward`å‡½æ•°ï¼Œè¯¥å‡½æ•°å°†ä½¿ç”¨ `_input_quantizer` å¯¹è¾“å…¥è¿›è¡Œé‡åŒ–ï¼Œè€Œ `_input_quantizer` å·²åœ¨ `__init__` å‡½æ•°ä¸­åˆå§‹åŒ–ï¼Œå¹¶ä½¿ç”¨`super`å‡½æ•°å°†è¾“å…¥è½¬å‘åˆ°åŸºç±»ä¸­ã€‚

```python
def forward(self, input):
    quant_input = self._input_quantizer(input)
    return super(QuantMaxPool2d, self).forward(quant_input)
```

* æœ€åï¼Œæˆ‘ä»¬éœ€è¦ä¸º `_input_quantizer` å®šä¹‰ä¸€ä¸ª `getter`æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨ `module.input_quantizer.disable()` æ¥ç¦ç”¨æŸä¸ªæ¨¡å—çš„é‡åŒ–åŠŸèƒ½ï¼Œè¿™å¯¹å¯¹æ¯”å®éªŒä¸åŒå±‚çš„é‡åŒ–é…ç½®å°†å¾ˆæœ‰å¸®åŠ©ã€‚

```python
@property
def input_quantizer(self):
    return self._input_quantizer
```

ä¸€ä¸ªå®Œæ•´çš„é‡åŒ–`pooling`æ¨¡å—å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
class QuantMaxPool2d(pooling.MaxPool2d, _utils.QuantInputMixin):
    """Quantized 2D maxpool"""
    def __init__(self, kernel_size, stride=None, padding=0, dilation=1,
                return_indices=False, ceil_mode=False, **kwargs):
        super(QuantMaxPool2d, self).__init__(kernel_size, stride, padding, dilation,
                                            return_indices, ceil_mode)
        # æå–é‡åŒ–æè¿°ç¬¦
        quant_desc_input = _utils.pop_quant_desc_in_kwargs(self.__class__, input_only=True, **kwargs)
        self.init_quantizer(quant_desc_input)

    def forward(self, input):
        quant_input = self._input_quantizer(input)
        return super(QuantMaxPool2d, self).forward(quant_input)

    @property
    def input_quantizer(self):
        return self._input_quantizer
```

#### Quantizing Modules With Weights and Inputs

æˆ‘ä»¬å°†ä¸¾ä¾‹è¯´æ˜å¦‚ä½•é‡åŒ– `torch.nn.Linear` æ¨¡å—ã€‚ä¸ä¹‹å‰çš„`pooling`æ¨¡å—é‡åŒ–ç¤ºä¾‹ç›¸æ¯”ï¼Œå”¯ä¸€çš„å˜åŒ–å°±æ˜¯æˆ‘ä»¬éœ€è¦åœ¨ `Linear` æ¨¡å—ä¸­å¯¹æƒé‡è¿›è¡Œé‡åŒ–ã€‚

* é‡åŒ–`linear`æ¨¡å—çš„æ­¥éª¤å¦‚ä¸‹

```python
class QuantLinear(nn.Linear, _utils.QuantMixin):
```

* åœ¨ `__init__` å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ `pop_quant_desc_in_kwargs` å‡½æ•°æå–è¾“å…¥å’Œæƒé‡çš„é‡åŒ–æè¿°ç¬¦ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›é‡åŒ–æè¿°ç¬¦åˆå§‹åŒ–è¾“å…¥å’Œæƒé‡çš„ `TensorQuantizer` æ¨¡å—ã€‚

```python
def __init__(self, in_features, out_features, bias=True, **kwargs):
        super(QuantLinear, self).__init__(in_features, out_features, bias)
        quant_desc_input, quant_desc_weight = _utils.pop_quant_desc_in_kwargs(self.__class__, **kwargs)

        self.init_quantizer(quant_desc_input, quant_desc_weight)
```

* é€šè¿‡ `_input_quantizer` å’Œ `_weight_quantizer` åˆ†åˆ«ä¼ é€’è¾“å…¥å’Œæƒé‡ã€‚è¿™ä¸€æ­¥å°†å®é™…çš„è¾“å…¥/æƒé‡çš„`TensorQuantizer` æ·»åŠ åˆ°æ¨¡å—ä¸­ï¼Œå¹¶æœ€ç»ˆæ·»åŠ åˆ°æ¨¡å‹ä¸­ã€‚

```python
def forward(self, input):
    quant_input = self._input_quantizer(input)
    quant_weight = self._weight_quantizer(self.weight)

    output = F.linear(quant_input, quant_weight, bias=self.bias)

    return output
```

* ä¸è¾“å…¥/æƒé‡ç›¸å…³çš„ `TensorQuantizer` æ¨¡å—æ·»åŠ äº† `getter` æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨ `module_obj.weight_quantizer.disable()` æ¥ç¦ç”¨é‡åŒ–æœºåˆ¶ã€‚

```python
@property
def input_quantizer(self):
    return self._input_quantizer

@property
def weight_quantizer(self):
    return self._weight_quantizer
```

* é‡åŒ–çš„`linear`æ¨¡å—å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
class QuantLinear(nn.Linear, _utils.QuantMixin):

    def __init__(self, in_features, out_features, bias=True, **kwargs):
        super(QuantLinear, self).__init__(in_features, out_features, bias)
        quant_desc_input, quant_desc_weight = _utils.pop_quant_desc_in_kwargs(self.__class__, **kwargs)

        self.init_quantizer(quant_desc_input, quant_desc_weight)

    def forward(self, input):
        quant_input = self._input_quantizer(input)
        quant_weight = self._weight_quantizer(self.weight)

        output = F.linear(quant_input, quant_weight, bias=self.bias)

        return output

    @property
    def input_quantizer(self):
        return self._input_quantizer

    @property
    def weight_quantizer(self):
        return self._weight_quantizer
```

#### Directly Quantizing Inputs In Graph

å¦‚ä¸Šæ‰€è¿°ï¼Œä¹Ÿå¯ä»¥ä¸åˆ›å»ºå°è£…å™¨ï¼Œç›´æ¥é‡åŒ–è¾“å…¥ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼š

```python
test_input = torch.randn(1, 5, 5, 5, dtype=torch.double)

quantizer = TensorQuantizer(quant_nn.QuantLinear.default_quant_desc_input)

quant_input = quantizer(test_input)

out = F.adaptive_avg_pool2d(quant_input, 3)
```

å‡è®¾å›¾ä¸­æœ‰ä¸€ä¸ª `F.adaptive_avg_pool2d` æ“ä½œï¼Œæˆ‘ä»¬æƒ³å¯¹è¿™ä¸ªæ“ä½œè¿›è¡Œé‡åŒ–ã€‚åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `TensorQuantizer(quant_nn.QuantLinear.default_quant_desc_input)` å®šä¹‰äº†ä¸€ä¸ªé‡åŒ–å™¨ï¼Œç„¶åç”¨å®ƒæ¥é‡åŒ–è¾“å…¥ï¼Œå¹¶å°†é‡åŒ–åçš„ç»“æœè¾“å…¥åˆ° `F.adaptive_avg_pool2d` è¿ç®—ä¸­ã€‚è¯·æ³¨æ„ï¼Œè¿™ä¸ªé‡åŒ–å™¨ä¸æˆ‘ä»¬ä¹‹å‰é‡åŒ–`pytorch`æ¨¡å—æ—¶ä½¿ç”¨çš„é‡åŒ–å™¨ç›¸åŒã€‚
