# ğŸ¥° ONNX Model hub

## ONNX Model Hub

ONNX Model Hub æ˜¯ä¸€ç§ç®€å•å¿«æ·çš„æ–¹æ³•ï¼Œå¯è®©ä½ ä» `ONNX Model Zoo` å¼€å§‹ä½¿ç”¨æœ€å…ˆè¿›çš„é¢„è®­ç»ƒ ONNX æ¨¡å‹ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜èƒ½è®©ç ”ç©¶äººå‘˜å’Œæ¨¡å‹å¼€å‘äººå‘˜æœ‰æœºä¼šä¸æ›´å¹¿æ³›çš„ç¤¾åŒºåˆ†äº«ä»–ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

### Install

ONNX Model hub åœ¨ ONNX 1.11.0 ä¹‹åå¯ç”¨ã€‚

### Basic usage

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºä¸€äº›åŸºæœ¬åŠŸèƒ½ã€‚

```python
from onnx import hub
```

#### Downloading a model by name:

åŠ è½½å‡½æ•°å°†é»˜è®¤åœ¨æ¨¡å‹åº“ä¸­æœç´¢åç§°åŒ¹é…çš„æœ€æ–°æ¨¡å‹ï¼Œå°†è¯¥æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜ä¸­ï¼Œå¹¶å°†æ¨¡å‹åŠ è½½åˆ° `ModelProto` å¯¹è±¡ä¸­ï¼Œä¾› `ONNX runtime`ä½¿ç”¨ã€‚

```python
model = hub.load("resnet50")
```

#### Downloading from custom repositories:

å¯ä»¥æä¾› repo å‚æ•°ä»æŒ‡å®šçš„ONNX hubä¸­ä¸‹è½½ï¼š

```python
model = hub.load("resnet50", repo="onnx/models:771185265efbdc049fb223bd68ab1aeb1aecde76")
```

#### Listing and inspecting Models:

ä¹Ÿæä¾›äº†ç”¨äºæŸ¥è¯¢Model Zooçš„ APIï¼Œä»¥äº†è§£æ›´å¤šæœ‰å…³å¯ç”¨æ¨¡å‹çš„ä¿¡æ¯ã€‚è¿™ä¸ä¼šä¸‹è½½æ¨¡å‹ï¼Œè€Œåªæ˜¯è¿”å›ä¸ç»™å®šå‚æ•°ç›¸åŒ¹é…çš„æ¨¡å‹ä¿¡æ¯

```python
# List all models in the onnx/models:main repo
all_models = hub.list_models()

# List all versions/opsets of a specific model
mnist_models = hub.list_models(model="mnist")

# List all models matching a given "tag"
vision_models = hub.list_models(tags=["vision"])
```

æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ `get_model_info` å‡½æ•°åœ¨ä¸‹è½½å‰æ£€æŸ¥æ¨¡å‹çš„å…ƒæ•°æ®ï¼š

```python
print(hub.get_model_info(model="mnist", opset=8))
```

æ‰“å°ç»“æœå¦‚ä¸‹ï¼š

```sh
ModelInfo(
    model=MNIST,
    opset=8,
    path=vision/classification/mnist/model/mnist-8.onnx,
    metadata={
     'model_sha': '2f06e72de813a8635c9bc0397ac447a601bdbfa7df4bebc278723b958831c9bf',
     'model_bytes': 26454,
     'tags': ['vision', 'classification', 'mnist'],
     'io_ports': {
        'inputs': [{'name': 'Input3', 'shape': [1, 1, 28, 28], 'type': 'tensor(float)'}],
        'outputs': [{'name': 'Plus214_Output_0', 'shape': [1, 10], 'type': 'tensor(float)'}]},
     'model_with_data_path': 'vision/classification/mnist/model/mnist-8.tar.gz',
     'model_with_data_sha': '1dd098b0fe8bc750585eefc02013c37be1a1cae2bdba0191ccdb8e8518b3a882',
     'model_with_data_bytes': 25962}
)
```

### Local Caching

ONNX hubä¼šå°†ä¸‹è½½çš„æ¨¡å‹ç¼“å­˜åˆ°ä¸€ä¸ªå¯é…ç½®çš„æœ¬åœ°ä½ç½®ï¼Œä»¥ä¾¿åç»­è°ƒç”¨ hub.load æ—¶æ— éœ€è¿æ¥ç½‘ç»œã€‚

#### Default cache location

hubå®¢æˆ·ç«¯æŒ‰ä»¥ä¸‹é¡ºåºæŸ¥æ‰¾é»˜è®¤ç¼“å­˜ä½ç½®ï¼š

1. `$ONNX_HOME/hub` å¦‚æœç¯å¢ƒå˜é‡ `ONNX_HOME` è¢«å®šä¹‰
2. `$XDG_CACHE_HOME/hub` å¦‚æœç¯å¢ƒå˜é‡ `XDG_CACHE_HOME` è¢«å®šä¹‰
3. `~/.cache/onnx/hub` å…¶ä¸­`~` æ˜¯ç”¨æˆ·çš„å®¶ç›®å½•

#### Setting the cache location

ä½¿ç”¨å¦‚ä¸‹æ–¹æ³•æ‰‹åŠ¨è®¾ç½®ç¼“å­˜ä½ç½®:

```python
hub.set_dir("my/cache/directory")
```

æ­¤å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ£€æŸ¥ç¼“å­˜ä½ç½®ï¼š

```python
print(hub.get_dir())
```

#### Additional cache details

è¦æ¸…é™¤æ¨¡å‹ç¼“å­˜ï¼Œåªéœ€ä½¿ç”¨ `shutil` æˆ– `os` ç­‰ `python` å·¥å…·åˆ é™¤ç¼“å­˜ç›®å½•å³å¯ã€‚æ­¤å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ `force_reload` é€‰é¡¹è¦†ç›–ç¼“å­˜æ¨¡å‹ï¼š

```python
model = hub.load("resnet50", force_reload=True)
```

### Architecture

ONNX hubç”±å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆã€‚å®¢æˆ·ç«¯ä»£ç ç›®å‰åŒ…å«åœ¨ onnx è½¯ä»¶åŒ…ä¸­ï¼Œå¯ä»¥åœ¨ github ä»“åº“ï¼ˆå¦‚ ONNX Model Zoo ä¸­çš„ä»“åº“ï¼‰ä¸­ä»¥æ‰˜ç®¡ ONNX\_HUB\_MANIFEST.json çš„å½¢å¼æŒ‡å‘æœåŠ¡å™¨ã€‚è¯¥æ¸…å•æ–‡ä»¶æ˜¯ä¸€ä¸ª JSON æ–‡æ¡£ï¼Œå…¶ä¸­åˆ—å‡ºäº†æ‰€æœ‰æ¨¡å‹åŠå…¶å…ƒæ•°æ®ï¼Œå…¶è®¾è®¡ä¸ç¼–ç¨‹è¯­è¨€æ— å…³ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªæ ¼å¼è‰¯å¥½çš„æ¨¡å‹æ¸…å•æ¡ç›®ç¤ºä¾‹ï¼š

```json
{
 "model": "BERT-Squad",
 "model_path": "text/machine_comprehension/bert-squad/model/bertsquad-8.onnx",
 "onnx_version": "1.3",
 "opset_version": 8,
 "metadata": {
     "model_sha": "cad65b9807a5e0393e4f84331f9a0c5c844d9cc736e39781a80f9c48ca39447c",
     "model_bytes": 435882893,
     "tags": ["text", "machine comprehension", "bert-squad"],
     "io_ports": {
         "inputs": [
             {
                 "name": "unique_ids_raw_output___9:0",
                 "shape": ["unk__475"],
                 "type": "tensor(int64)"
             },
             {
                 "name": "segment_ids:0",
                 "shape": ["unk__476", 256],
                 "type": "tensor(int64)"
             },
             {
                 "name": "input_mask:0",
                 "shape": ["unk__477", 256],
                 "type": "tensor(int64)"
             },
             {
                 "name": "input_ids:0",
                 "shape": ["unk__478", 256],
                 "type": "tensor(int64)"
             }
         ],
         "outputs": [
             {
                 "name": "unstack:1",
                 "shape": ["unk__479", 256],
                 "type": "tensor(float)"
             },
             {
                 "name": "unstack:0",
                 "shape": ["unk__480", 256],
                 "type": "tensor(float)"
             },
             {
                 "name": "unique_ids:0",
                 "shape": ["unk__481"],
                 "type": "tensor(int64)"
             }
         ]
     },
     "model_with_data_path": "text/machine_comprehension/bert-squad/model/bertsquad-8.tar.gz",
     "model_with_data_sha": "c8c6c7e0ab9e1333b86e8415a9d990b2570f9374f80be1c1cb72f182d266f666",
     "model_with_data_bytes": 403400046
 }
}
```

* `model`: ç”¨äºæŸ¥è¯¢çš„æ¨¡å‹åç§°
* `model_path`: å­˜å‚¨åœ¨ Git LFS ä¸­çš„æ¨¡å‹çš„ç›¸å¯¹è·¯å¾„ã€‚
* `onnx_version`: ONNX æ¨¡å‹çš„ç‰ˆæœ¬
* `opset_version`: opset çš„ç‰ˆæœ¬ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå®¢æˆ·ç«¯å°†ä¸‹è½½æœ€æ–°çš„ opsetã€‚
* `metadata/model_sha`: Optional æ¨¡å‹shaæ ¡éªŒç ï¼Œæé«˜ä¸‹è½½å®‰å…¨æ€§
* `metadata/tags`: Optional å¸®åŠ©ç”¨æˆ·æŒ‰ç‰¹å®šç±»å‹æŸ¥æ‰¾æ¨¡å‹

`metadata`ä¸­çš„æ‰€æœ‰å…¶ä»–å­—æ®µå¯¹å®¢æˆ·ç«¯æ¥è¯´éƒ½æ˜¯å¯é€‰çš„ï¼Œä½†å´èƒ½ä¸ºç”¨æˆ·æä¾›é‡è¦çš„è¯¦ç»†ä¿¡æ¯ã€‚
