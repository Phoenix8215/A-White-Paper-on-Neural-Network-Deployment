---
description: >-
  âš ï¸This post is based on the official MMDeploy tutorial, with some minor
  modifications for clarity and context.
---

# ğŸ¥³ 0x00è‡ªå®šä¹‰ç®—å­

### åˆ›å»ºPytorchæ¨¡å‹

ç”¨ä¸‹é¢çš„ä»£ç æ¥åˆ›å»ºä¸€ä¸ªç»å…¸çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹ SRCNN

```python
import os
import cv2
import numpy as np
import requests
import torch
import torch.onnx
from torch import nn

class SuperResolutionNet(nn.Module):
    def __init__(self, upscale_factor):
        super().__init__()
        self.upscale_factor = upscale_factor
        self.img_upsampler = nn.Upsample(
            scale_factor=self.upscale_factor,
            mode='bicubic',
            align_corners=False)

        self.conv1 = nn.Conv2d(3,64,kernel_size=9,padding=4)
        self.conv2 = nn.Conv2d(64,32,kernel_size=1,padding=0)
        self.conv3 = nn.Conv2d(32,3,kernel_size=5,padding=2)

        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.img_upsampler(x)
        out = self.relu(self.conv1(x))
        out = self.relu(self.conv2(out))
        out = self.conv3(out)
        return out
        
# Download checkpoint and test image
urls = ['https://download.openmmlab.com/mmediting/restorers/srcnn/srcnn_x4k915_1x16_1000k_div2k_20200608-4186f232.pth',
    'https://raw.githubusercontent.com/open-mmlab/mmediting/master/tests/data/face/000001.png']
names = ['srcnn.pth', 'face.png']
for url, name in zip(urls, names):
    if not os.path.exists(name):
        open(name, 'wb').write(requests.get(url).content)

def init_torch_model():
    torch_model = SuperResolutionNet(upscale_factor=3)
    
    state_dict = torch.load('srcnn.pth')['state_dict']
    
    # Adapt the checkpoint
    for old_key in list(state_dict.keys()):
        new_key = '.'.join(old_key.split('.')[1:])
        state_dict[new_key] = state_dict.pop(old_key)

    torch_model.load_state_dict(state_dict)
    torch_model.eval()
    return torch_model

model = init_torch_model()
input_img = cv2.imread('face.png').astype(np.float32)

# HWC to NCHW
input_img = np.transpose(input_img, [2, 0, 1])
input_img = np.expand_dims(input_img, 0)

# Inference
torch_output = model(torch.from_numpy(input_img)).detach().numpy()

# NCHW to HWC
torch_output = np.squeeze(torch_output, 0)
torch_output = np.clip(torch_output, 0, 255)
torch_output = np.transpose(torch_output, [1, 2, 0]).astype(np.uint8)

# Show image
cv2.imwrite("face_torch.png", torch_output)
```

SRCNN å…ˆæŠŠå›¾åƒä¸Šé‡‡æ ·åˆ°å¯¹åº”åˆ†è¾¨ç‡ï¼Œå†ç”¨ 3 ä¸ªå·ç§¯å±‚å¤„ç†å›¾åƒã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬è·³è¿‡è®­ç»ƒç½‘ç»œçš„æ­¥éª¤ï¼Œç›´æ¥ä¸‹è½½æ¨¡å‹æƒé‡ï¼ˆç”±äº MMEditing ä¸­ SRCNN çš„æƒé‡ç»“æ„å’Œæˆ‘ä»¬å®šä¹‰çš„æ¨¡å‹ä¸å¤ªä¸€æ ·ï¼Œæˆ‘ä»¬ä¿®æ”¹äº†æƒé‡å­—å…¸çš„ key æ¥é€‚é…æˆ‘ä»¬å®šä¹‰çš„æ¨¡å‹ï¼‰ï¼ŒåŒæ—¶ä¸‹è½½å¥½è¾“å…¥å›¾ç‰‡ã€‚<mark style="color:red;">ä¸ºäº†è®©æ¨¡å‹è¾“å‡ºæˆæ­£ç¡®çš„å›¾ç‰‡æ ¼å¼ï¼Œæˆ‘ä»¬æŠŠæ¨¡å‹çš„è¾“å‡ºè½¬æ¢æˆ HWC æ ¼å¼ï¼Œå¹¶ä¿è¯æ¯ä¸€é€šé“çš„é¢œè‰²å€¼éƒ½åœ¨ 0\~255 ä¹‹é—´ã€‚</mark>å¦‚æœè„šæœ¬æ­£å¸¸è¿è¡Œçš„è¯ï¼Œä¸€å¹…è¶…åˆ†è¾¨ç‡çš„äººè„¸ç…§ç‰‡ä¼šä¿å­˜åœ¨ `â€œface_torch.pngâ€` ä¸­ã€‚

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (6) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

åœ¨ PyTorch æ¨¡å‹æµ‹è¯•æ­£ç¡®åï¼Œæˆ‘ä»¬æ¥æ­£å¼å¼€å§‹éƒ¨ç½²è¿™ä¸ªæ¨¡å‹ã€‚æˆ‘ä»¬ä¸‹ä¸€æ­¥çš„ä»»åŠ¡æ˜¯æŠŠ PyTorch æ¨¡å‹è½¬æ¢æˆç”¨ä¸­é—´è¡¨ç¤º ONNX æè¿°çš„æ¨¡å‹ã€‚

> å‡è®¾ `state_dict` ä¸­çš„é”®å¦‚ä¸‹ï¼š
>
> ```python
> {
>     'module.conv1.weight': tensor(...),
>     'module.conv1.bias': tensor(...),
>     'module.fc1.weight': tensor(...),
>     'module.fc1.bias': tensor(...),
> }
> ```
>
> ç»è¿‡
>
> ```python
> # Adapt the checkpoint
>     for old_key in list(state_dict.keys()):
>         new_key = '.'.join(old_key.split('.')[1:])
>         state_dict[new_key] = state_dict.pop(old_key)
> ```
>
> è¿™æ®µä»£ç åï¼Œ`state_dict` ä¼šå˜æˆï¼š
>
> ```python
> {
>     'conv1.weight': tensor(...),
>     'conv1.bias': tensor(...),
>     'fc1.weight': tensor(...),
>     'fc1.bias': tensor(...),
> }
> ```
>
> é”®åä¸­çš„ `'module.'` å‰ç¼€è¢«ç§»é™¤äº†ã€‚

#### **æ„é€ å‡½æ•°**

```python
torch.nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)
```

**å‚æ•°è§£é‡Šï¼š**

1. **`size`**ï¼ˆ`tuple` or `int`, optionalï¼‰ï¼š
   * è¿™ä¸ªå‚æ•°æŒ‡å®šè¾“å‡ºå¼ é‡çš„ç›®æ ‡å°ºå¯¸ã€‚å¯ä»¥ä¼ å…¥ä¸€ä¸ªæ•´æ•°ï¼ˆå¯¹æ‰€æœ‰ç»´åº¦è¿›è¡Œç›¸åŒçš„ä¸Šé‡‡æ ·ï¼‰æˆ–ä¸€ä¸ªå…ƒç»„ï¼Œå…ƒç»„çš„é•¿åº¦åº”ç­‰äºè¾“å…¥å¼ é‡çš„ç©ºé—´ç»´åº¦æ•°ã€‚ä¾‹å¦‚ï¼Œå¯¹äºå›¾åƒæ•°æ®ï¼Œå…ƒç»„é€šå¸¸æ˜¯ `(H_out, W_out)`ã€‚
   * å¦‚æœæŒ‡å®šäº† `size`ï¼Œå°±ä¼šå¼ºåˆ¶å°†è¾“å‡ºå¼ é‡çš„å°ºå¯¸è°ƒæ•´ä¸ºè¯¥å€¼ã€‚
2. **`scale_factor`**ï¼ˆ`float` or `tuple` of `float`, optionalï¼‰ï¼š
   * è¡¨ç¤ºä¸Šé‡‡æ ·çš„å€ç‡ï¼Œå³è¾“å…¥å¼ é‡åœ¨æ¯ä¸ªç»´åº¦ä¸Šæ‰©å¤§å¤šå°‘å€ã€‚å¦‚æœä¼ å…¥ä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œå®ƒå°†ä½œç”¨äºæ¯ä¸ªç»´åº¦ã€‚å¦‚æœä¼ å…¥ä¸€ä¸ªå…ƒç»„ï¼Œåˆ™æ¯ä¸ªå…ƒç´ åˆ†åˆ«å¯¹åº”æ¯ä¸ªç©ºé—´ç»´åº¦çš„ç¼©æ”¾ç³»æ•°ã€‚
   * é€šå¸¸ä¼šæŒ‡å®š `scale_factor` æ¥è¡¨ç¤ºæ•´ä½“çš„æ”¾å¤§å€æ•°ã€‚ä¾‹å¦‚ï¼Œ`scale_factor=2` ä¼šè®©è¾“å…¥å¼ é‡çš„æ¯ä¸ªç©ºé—´ç»´åº¦æ”¾å¤§ä¸¤å€ã€‚
3. **`mode`**ï¼ˆ`str`, optional, default=`'nearest'`ï¼‰ï¼š
   * ç”¨äºæŒ‡å®šä¸Šé‡‡æ ·æ—¶ä½¿ç”¨çš„æ’å€¼æ–¹æ³•ã€‚PyTorch æä¾›äº†ä»¥ä¸‹å‡ ç§æ’å€¼æ–¹å¼ï¼š
     * `'nearest'`ï¼šæœ€è¿‘é‚»æ’å€¼ã€‚
     * `'linear'`ï¼šçº¿æ€§æ’å€¼ï¼ˆé€‚ç”¨äº 3D å¼ é‡ï¼‰ã€‚
     * `'bilinear'`ï¼šåŒçº¿æ€§æ’å€¼ï¼ˆé€‚ç”¨äº 4D å¼ é‡ï¼Œå¦‚å›¾åƒæ•°æ®ï¼‰ã€‚
     * `'bicubic'`ï¼šåŒä¸‰æ¬¡æ’å€¼ï¼ˆä»…é€‚ç”¨äº 4D å¼ é‡ï¼‰ã€‚
     * `'trilinear'`ï¼šä¸‰çº¿æ€§æ’å€¼ï¼ˆé€‚ç”¨äº 5D å¼ é‡ï¼Œå¦‚ 3D ä½“ç§¯æ•°æ®ï¼‰ã€‚
     * `'area'`ï¼šåŒºåŸŸæ’å€¼ï¼Œæ ¹æ®è¾“å…¥å¤§å°å’Œè¾“å‡ºå¤§å°æ‰§è¡Œå¹³å‡æ± åŒ–ã€‚
4. **`align_corners`**ï¼ˆ`bool`, optional, default=`None`ï¼‰ï¼š
   * è¯¥å‚æ•°ç”¨äºæ§åˆ¶å½“æ’å€¼æ—¶å¦‚ä½•å¯¹é½è§’ç‚¹ã€‚å¯¹äº `bilinear`ã€`trilinear` å’Œ `bicubic` æ’å€¼æ–¹å¼ï¼Œå®ƒæ§åˆ¶æ’å€¼çš„è¡Œä¸ºã€‚
   * å¦‚æœ `align_corners=True`ï¼Œè¾“å…¥å¼ é‡çš„è§’åƒç´ ä¼šä¸è¾“å‡ºå¼ é‡çš„è§’åƒç´ å¯¹é½ï¼Œé¿å…è¾¹ç•Œåƒç´ çš„å¹³æ»‘æ•ˆæœã€‚
   * å¦‚æœ `align_corners=False`ï¼Œè¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„è§’åƒç´ ä¸å¯¹é½ï¼Œé»˜è®¤ä¼šä½¿å¾—æ’å€¼çš„æ•ˆæœæ›´åŠ å¹³æ»‘ã€‚é€šå¸¸æ¨èå°†å…¶è®¾ä¸º `False`ã€‚
   * å¯¹äº `nearest` æ’å€¼ï¼Œè¯¥å‚æ•°æ²¡æœ‰ä½œç”¨ã€‚
5. **`recompute_scale_factor`**ï¼ˆ`bool`, optional, default=`None`ï¼‰ï¼š
   * æ§åˆ¶æ˜¯å¦åœ¨è®¡ç®—è¾“å‡ºå¤§å°æ—¶é‡æ–°è®¡ç®—ç¼©æ”¾å› å­ï¼ˆscale factorï¼‰ã€‚é€šå¸¸ï¼ŒPyTorchä¼šå°† `scale_factor` ç›´æ¥ç”¨äºå¤§å°è®¡ç®—ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æœéœ€è¦æ›´å‡†ç¡®çš„è¾“å‡ºå°ºå¯¸ï¼Œå¯ä»¥è®¾ç½® `recompute_scale_factor=True`ã€‚

**æ³¨æ„ï¼š**

* `size` å’Œ `scale_factor` ä¸èƒ½åŒæ—¶æŒ‡å®šï¼›å¿…é¡»äºŒé€‰ä¸€ã€‚
* `mode` æŒ‡å®šæ’å€¼æ–¹æ³•ï¼Œé»˜è®¤æ˜¯æœ€è¿‘é‚»æ’å€¼ï¼Œæ’å€¼æ–¹å¼ä¼šå½±å“åˆ°ç”Ÿæˆçš„å¼ é‡çš„å¹³æ»‘åº¦ä¸ç»†èŠ‚æ¢å¤ã€‚

#### **ä¸Šé‡‡æ ·çš„å·¥ä½œåŸç†**

ä¸Šé‡‡æ ·çš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡æ’å€¼æˆ–å¤åˆ¶æ¥æ‰©å¤§è¾“å…¥å¼ é‡çš„ç©ºé—´å°ºå¯¸ã€‚æœ€å¸¸è§çš„æ’å€¼æ–¹æ³•æœ‰ï¼š

* **æœ€è¿‘é‚»æ’å€¼**ï¼ˆ`nearest`ï¼‰ï¼šç®€å•åœ°å°†æœ€è¿‘çš„åƒç´ å€¼å¤åˆ¶åˆ°æ›´å¤§çš„ç©ºé—´ä¸­ï¼Œä¸ä¼šäº§ç”Ÿå¹³æ»‘è¿‡æ¸¡ã€‚é€Ÿåº¦è¾ƒå¿«ï¼Œé€šå¸¸ç”¨äºå¿«é€Ÿä¸Šé‡‡æ ·ã€‚
* **åŒçº¿æ€§æ’å€¼**ï¼ˆ`bilinear`ï¼‰ï¼šåŸºäºç›¸é‚»åƒç´ çš„çº¿æ€§å…³ç³»æ’å€¼ï¼Œç”Ÿæˆå¹³æ»‘çš„è¿‡æ¸¡æ•ˆæœã€‚é€šå¸¸åœ¨å¤„ç†å›¾åƒæ—¶ä½¿ç”¨ï¼Œèƒ½å¤Ÿæä¾›æ›´å¹³æ»‘çš„ä¸Šé‡‡æ ·æ•ˆæœã€‚
* **åŒä¸‰æ¬¡æ’å€¼**ï¼ˆ`bicubic`ï¼‰ï¼šè€ƒè™‘æ›´å¤§èŒƒå›´çš„åƒç´ è¿›è¡Œæ’å€¼ï¼Œç”Ÿæˆæ›´ç»†è…»çš„ä¸Šé‡‡æ ·æ•ˆæœï¼Œä»£ä»·æ˜¯è®¡ç®—å¤æ‚åº¦ç¨é«˜ã€‚
* **ä¸‰çº¿æ€§æ’å€¼**ï¼ˆ`trilinear`ï¼‰ï¼šç”¨äº5ç»´æ•°æ®ï¼ˆå¦‚3Dä½“ç§¯æ•°æ®ï¼‰çš„æ’å€¼æ–¹å¼ã€‚

#### **`align_corners` çš„è§£é‡Šä¸ä½¿ç”¨**

`align_corners` æ§åˆ¶æ’å€¼æ—¶è§’ç‚¹çš„å¯¹é½æ–¹å¼ï¼Œå®ƒä¸»è¦å½±å“åˆ°åŒçº¿æ€§ã€ä¸‰çº¿æ€§å’ŒåŒä¸‰æ¬¡æ’å€¼ã€‚è¯¥å‚æ•°çš„ä¸»è¦å½±å“ä½“ç°åœ¨è¾“å‡ºç»“æœçš„å¹³æ»‘ç¨‹åº¦ä¸Šã€‚

*   **`align_corners=True`**ï¼šä¼šå°†è¾“å…¥å¼ é‡çš„è§’ç‚¹åƒç´ å¯¹é½åˆ°è¾“å‡ºå¼ é‡çš„è§’ç‚¹ä½ç½®ï¼Œè¿™å¯èƒ½ä¼šé€ æˆæ’å€¼ç»“æœåœ¨è¾¹ç¼˜çš„åƒç´ å€¼å˜åŒ–è¾ƒå¤§ã€‚

    ç¤ºä¾‹ï¼š

    ```python
    upsample_bilinear = nn.Upsample(size=(50, 50), mode='bilinear', align_corners=True)
    ```
* **`align_corners=False`**ï¼ˆé»˜è®¤ï¼‰ï¼šè¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„è§’ç‚¹ä¸å¯¹é½ã€‚è¿™ä¸ªé€‰é¡¹é€šå¸¸èƒ½æä¾›æ›´å¹³æ»‘çš„æ’å€¼æ•ˆæœï¼Œå¹¶ä¸”PyTorchæ¨èåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä½¿ç”¨ `align_corners=False`ã€‚

### è½¬æ¢æˆONNXæ¨¡å‹

è®©æˆ‘ä»¬ç”¨ä¸‹é¢çš„ä»£ç æ¥æŠŠ PyTorch çš„æ¨¡å‹è½¬æ¢æˆ ONNX æ ¼å¼çš„æ¨¡å‹ï¼š

```python
x = torch.randn(1, 3, 256, 256)

with torch.no_grad():
    torch.onnx.export(
        model,
        x,
        "srcnn.onnx",
        opset_version=11,
        input_names=['input'],
        output_names=['output'])
```

å…¶ä¸­ï¼Œ**torch.onnx.export** æ˜¯ PyTorch è‡ªå¸¦çš„æŠŠæ¨¡å‹è½¬æ¢æˆ ONNX æ ¼å¼çš„å‡½æ•°ã€‚è®©æˆ‘ä»¬å…ˆçœ‹ä¸€ä¸‹å‰ä¸‰ä¸ªå¿…é€‰å‚æ•°ï¼šå‰ä¸‰ä¸ªå‚æ•°åˆ†åˆ«æ˜¯è¦è½¬æ¢çš„æ¨¡å‹ã€æ¨¡å‹çš„ä»»æ„ä¸€ç»„è¾“å…¥ã€å¯¼å‡ºçš„ ONNX æ–‡ä»¶çš„æ–‡ä»¶åã€‚è½¬æ¢æ¨¡å‹æ—¶ï¼Œéœ€è¦åŸæ¨¡å‹å’Œè¾“å‡ºæ–‡ä»¶åæ˜¯å¾ˆå®¹æ˜“ç†è§£çš„ï¼Œä½†ä¸ºä»€ä¹ˆéœ€è¦ä¸ºæ¨¡å‹æä¾›ä¸€ç»„è¾“å…¥å‘¢ï¼Ÿè¿™å°±æ¶‰åŠåˆ° ONNX è½¬æ¢çš„åŸç†äº†ã€‚<mark style="color:red;">ä» PyTorch çš„æ¨¡å‹åˆ° ONNX çš„æ¨¡å‹ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸€ç§è¯­è¨€ä¸Šçš„ç¿»è¯‘ã€‚ç›´è§‰ä¸Šçš„æƒ³æ³•æ˜¯åƒç¼–è¯‘å™¨ä¸€æ ·å½»åº•è§£æåŸæ¨¡å‹çš„ä»£ç ï¼Œè®°å½•æ‰€æœ‰æ§åˆ¶æµã€‚ä½†å‰é¢ä¹Ÿè®²åˆ°ï¼Œæˆ‘ä»¬é€šå¸¸åªç”¨ ONNX è®°å½•ä¸è€ƒè™‘æ§åˆ¶æµçš„é™æ€å›¾ã€‚å› æ­¤ï¼ŒPyTorch æä¾›äº†ä¸€ç§å«åšè¿½è¸ªï¼ˆtraceï¼‰çš„æ¨¡å‹è½¬æ¢æ–¹æ³•ï¼šç»™å®šä¸€ç»„è¾“å…¥ï¼Œå†å®é™…æ‰§è¡Œä¸€éæ¨¡å‹ï¼Œå³æŠŠè¿™ç»„è¾“å…¥å¯¹åº”çš„è®¡ç®—å›¾è®°å½•ä¸‹æ¥ï¼Œä¿å­˜ä¸º ONNX æ ¼å¼ã€‚</mark>export å‡½æ•°ç”¨çš„å°±æ˜¯è¿½è¸ªå¯¼å‡ºæ–¹æ³•ï¼Œéœ€è¦ç»™ä»»æ„ä¸€ç»„è¾“å…¥ï¼Œè®©æ¨¡å‹è·‘èµ·æ¥ã€‚æˆ‘ä»¬çš„æµ‹è¯•å›¾ç‰‡æ˜¯ä¸‰é€šé“ï¼Œ256x256å¤§å°çš„ï¼Œè¿™é‡Œä¹Ÿæ„é€ ä¸€ä¸ªåŒæ ·å½¢çŠ¶çš„éšæœºå¼ é‡ã€‚

å‰©ä¸‹çš„å‚æ•°ä¸­ï¼Œopset\_version è¡¨ç¤º ONNX ç®—å­é›†çš„ç‰ˆæœ¬ã€‚æ·±åº¦å­¦ä¹ çš„å‘å±•ä¼šä¸æ–­è¯ç”Ÿæ–°ç®—å­ï¼Œä¸ºäº†æ”¯æŒè¿™äº›æ–°å¢çš„ç®—å­ï¼ŒONNXä¼šç»å¸¸å‘å¸ƒæ–°çš„ç®—å­é›†ï¼Œç›®å‰å·²ç»æ›´æ–°15ä¸ªç‰ˆæœ¬ã€‚æˆ‘ä»¬ä»¤ opset\_version = 11ï¼Œå³ä½¿ç”¨ç¬¬11ä¸ª ONNX ç®—å­é›†ï¼Œæ˜¯å› ä¸º SRCNN ä¸­çš„ bicubic ï¼ˆåŒä¸‰æ¬¡æ’å€¼ï¼‰åœ¨ opset11 ä¸­æ‰å¾—åˆ°æ”¯æŒã€‚å‰©ä¸‹çš„ä¸¤ä¸ªå‚æ•° input\_names, output\_names æ˜¯è¾“å…¥ã€è¾“å‡º tensor çš„åç§°ï¼Œæˆ‘ä»¬ç¨åä¼šç”¨åˆ°è¿™äº›åç§°ã€‚

å¦‚æœä¸Šè¿°ä»£ç è¿è¡ŒæˆåŠŸï¼Œç›®å½•ä¸‹ä¼šæ–°å¢ä¸€ä¸ª"srcnn.onnx"çš„ ONNX æ¨¡å‹æ–‡ä»¶ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„è„šæœ¬æ¥éªŒè¯ä¸€ä¸‹æ¨¡å‹æ–‡ä»¶æ˜¯å¦æ­£ç¡®ã€‚

```python
import onnx

onnx_model = onnx.load("srcnn.onnx")
try:
    onnx.checker.check_model(onnx_model)
except Exception:
    print("Model incorrect")
else:
    print("Model correct")
```

å…¶ä¸­ï¼Œ**onnx.load** å‡½æ•°ç”¨äºè¯»å–ä¸€ä¸ª ONNX æ¨¡å‹ã€‚<mark style="color:red;">**onnx.checker.check\_model**</mark> <mark style="color:red;"></mark><mark style="color:red;">ç”¨äºæ£€æŸ¥æ¨¡å‹æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœæœ‰é”™è¯¯çš„è¯è¯¥å‡½æ•°ä¼šç›´æ¥æŠ¥é”™ã€‚</mark>æˆ‘ä»¬çš„æ¨¡å‹æ˜¯æ­£ç¡®çš„ï¼Œæ§åˆ¶å°ä¸­åº”è¯¥ä¼šæ‰“å°å‡º"Model correct"ã€‚

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€çœ‹ ONNX æ¨¡å‹å…·ä½“çš„ç»“æ„æ˜¯æ€ä¹ˆæ ·çš„ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **Netron** ï¼ˆå¼€æºçš„æ¨¡å‹å¯è§†åŒ–å·¥å…·ï¼‰æ¥å¯è§†åŒ– ONNX æ¨¡å‹ã€‚æŠŠ srcnn.onnx æ–‡ä»¶ä»æœ¬åœ°çš„æ–‡ä»¶ç³»ç»Ÿæ‹–å…¥ç½‘ç«™ï¼Œå³å¯çœ‹åˆ°å¦‚ä¸‹çš„å¯è§†åŒ–ç»“æœï¼š

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

<mark style="color:red;">ç‚¹å‡» input æˆ–è€… outputï¼Œå¯ä»¥æŸ¥çœ‹ ONNX æ¨¡å‹çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„ç‰ˆæœ¬ä¿¡æ¯ï¼Œä»¥åŠæ¨¡å‹è¾“å…¥ã€è¾“å‡ºçš„åç§°å’Œæ•°æ®ç±»å‹ã€‚</mark>

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (2) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

<mark style="color:red;">ç‚¹å‡»æŸä¸€ä¸ªç®—å­èŠ‚ç‚¹ï¼Œå¯ä»¥çœ‹åˆ°ç®—å­çš„å…·ä½“ä¿¡æ¯ã€‚æ¯”å¦‚ç‚¹å‡»ç¬¬ä¸€ä¸ª Conv å¯ä»¥çœ‹åˆ°ï¼š</mark>

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (3) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº† SRCNN çš„ ONNX æ¨¡å‹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æœ€åè¯¥å¦‚ä½•æŠŠè¿™ä¸ªæ¨¡å‹è¿è¡Œèµ·æ¥ã€‚

### **æ¨ç†å¼•æ“ â€”â€” ONNX Runtime**

**ONNX Runtime** æ˜¯ç”±å¾®è½¯ç»´æŠ¤çš„ä¸€ä¸ªè·¨å¹³å°æœºå™¨å­¦ä¹ æ¨ç†åŠ é€Ÿå™¨ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬å‰é¢æåˆ°çš„â€æ¨ç†å¼•æ“â€œã€‚ONNX Runtime æ˜¯ç›´æ¥å¯¹æ¥ ONNX çš„ï¼Œå³ ONNX Runtime å¯ä»¥ç›´æ¥è¯»å–å¹¶è¿è¡Œ .onnx æ–‡ä»¶, è€Œä¸éœ€è¦å†æŠŠ .onnx æ ¼å¼çš„æ–‡ä»¶è½¬æ¢æˆå…¶ä»–æ ¼å¼çš„æ–‡ä»¶ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äº `PyTorch - ONNX - ONNX Runtime` è¿™æ¡éƒ¨ç½²æµæ°´çº¿ï¼Œåªè¦åœ¨ç›®æ ‡è®¾å¤‡ä¸­å¾—åˆ° .onnx æ–‡ä»¶ï¼Œå¹¶åœ¨ `ONNX Runtime` ä¸Šè¿è¡Œæ¨¡å‹ï¼Œæ¨¡å‹éƒ¨ç½²å°±ç®—å¤§åŠŸå‘Šæˆäº†ã€‚

<mark style="color:red;">é€šè¿‡åˆšåˆšçš„æ“ä½œï¼Œæˆ‘ä»¬æŠŠ PyTorch ç¼–å†™çš„æ¨¡å‹è½¬æ¢æˆäº† ONNX æ¨¡å‹ï¼Œå¹¶é€šè¿‡å¯è§†åŒ–æ£€æŸ¥äº†æ¨¡å‹çš„æ­£ç¡®æ€§ã€‚æœ€åï¼Œè®©æˆ‘ä»¬ç”¨ ONNX Runtime è¿è¡Œä¸€ä¸‹æ¨¡å‹ï¼Œå®Œæˆæ¨¡å‹éƒ¨ç½²çš„æœ€åä¸€æ­¥ã€‚</mark>

ONNX Runtime æä¾›äº† Python æ¥å£ã€‚æ¥ç€åˆšæ‰çš„è„šæœ¬ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ å¦‚ä¸‹ä»£ç è¿è¡Œæ¨¡å‹ï¼š

```python
import onnxruntime

ort_session = onnxruntime.InferenceSession("srcnn.onnx")
ort_inputs = {'input': input_img}
ort_output = ort_session.run(['output'], ort_inputs)[0]

ort_output = np.squeeze(ort_output, 0)
ort_output = np.clip(ort_output, 0, 255)
ort_output = np.transpose(ort_output, [1, 2, 0]).astype(np.uint8)
cv2.imwrite("face_ort.png", ort_output)
```

è¿™æ®µä»£ç ä¸­ï¼Œé™¤å»åå¤„ç†æ“ä½œå¤–ï¼Œå’Œ ONNX Runtime ç›¸å…³çš„ä»£ç åªæœ‰ä¸‰è¡Œã€‚è®©æˆ‘ä»¬ç®€å•è§£æä¸€ä¸‹è¿™ä¸‰è¡Œä»£ç ã€‚**onnxruntime.InferenceSession** ç”¨äºè·å–ä¸€ä¸ª ONNX Runtime æ¨ç†å™¨ï¼Œå…¶å‚æ•°æ˜¯ç”¨äºæ¨ç†çš„ ONNX æ¨¡å‹æ–‡ä»¶ã€‚<mark style="color:red;">**æ¨ç†å™¨çš„ run æ–¹æ³•ç”¨äºæ¨¡å‹æ¨ç†ï¼Œå…¶ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºè¾“å‡ºå¼ é‡åçš„åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¸ºè¾“å…¥å€¼çš„å­—å…¸ã€‚å…¶ä¸­è¾“å…¥å€¼å­—å…¸çš„ key ä¸ºå¼ é‡åï¼Œvalue ä¸º numpy ç±»å‹çš„å¼ é‡å€¼ã€‚è¾“å…¥è¾“å‡ºå¼ é‡çš„åç§°éœ€è¦å’Œ torch.onnx.export ä¸­è®¾ç½®çš„è¾“å…¥è¾“å‡ºåå¯¹åº”ã€‚**</mark>

å¦‚æœä»£ç æ­£å¸¸è¿è¡Œçš„è¯ï¼Œå¦ä¸€å¹…è¶…åˆ†è¾¨ç‡ç…§ç‰‡ä¼šä¿å­˜åœ¨`"face_ort.png"`ä¸­ã€‚è¿™å¹…å›¾ç‰‡å’Œåˆšåˆšå¾—åˆ°çš„`"face_torch.png"`æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚è¿™è¯´æ˜ ONNX Runtime æˆåŠŸè¿è¡Œäº† SRCNN æ¨¡å‹ï¼Œæ¨¡å‹éƒ¨ç½²å®Œæˆäº†ï¼ä»¥åæœ‰ç”¨æˆ·æƒ³å®ç°è¶…åˆ†è¾¨ç‡çš„æ“ä½œï¼Œæˆ‘ä»¬åªéœ€è¦æä¾›ä¸€ä¸ª "srcnn.onnx" æ–‡ä»¶ï¼Œå¹¶å¸®åŠ©ç”¨æˆ·é…ç½®å¥½ ONNX Runtime çš„ Python ç¯å¢ƒï¼Œç”¨å‡ è¡Œä»£ç å°±å¯ä»¥è¿è¡Œæ¨¡å‹äº†ã€‚æˆ–è€…è¿˜æœ‰æ›´ç®€ä¾¿çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ ONNX Runtime ç¼–è¯‘å‡ºä¸€ä¸ªå¯ä»¥ç›´æ¥æ‰§è¡Œæ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚æˆ‘ä»¬åªéœ€è¦ç»™ç”¨æˆ·æä¾› ONNX æ¨¡å‹æ–‡ä»¶ï¼Œå¹¶è®©ç”¨æˆ·åœ¨åº”ç”¨ç¨‹åºé€‰æ‹©è¦æ‰§è¡Œçš„ ONNX æ¨¡å‹æ–‡ä»¶åå°±å¯ä»¥è¿è¡Œæ¨¡å‹äº†ã€‚

### **æ¨¡å‹éƒ¨ç½²ä¸­å¸¸è§çš„éš¾é¢˜**

* **æ¨¡å‹çš„åŠ¨æ€åŒ–ã€‚**å‡ºäºæ€§èƒ½çš„è€ƒè™‘ï¼Œå„æ¨ç†æ¡†æ¶éƒ½é»˜è®¤æ¨¡å‹çš„è¾“å…¥å½¢çŠ¶ã€è¾“å‡ºå½¢çŠ¶ã€ç»“æ„æ˜¯é™æ€çš„ã€‚è€Œä¸ºäº†è®©æ¨¡å‹çš„æ³›ç”¨æ€§æ›´å¼ºï¼Œéƒ¨ç½²æ—¶éœ€è¦åœ¨å°½å¯èƒ½ä¸å½±å“åŸæœ‰é€»è¾‘çš„å‰æä¸‹ï¼Œè®©æ¨¡å‹çš„è¾“å…¥è¾“å‡ºæˆ–æ˜¯ç»“æ„åŠ¨æ€åŒ–ã€‚
* **æ–°ç®—å­çš„å®ç°ã€‚**æ·±åº¦å­¦ä¹ æŠ€æœ¯æ—¥æ–°æœˆå¼‚ï¼Œæå‡ºæ–°ç®—å­çš„é€Ÿåº¦å¾€å¾€å¿«äº ONNX ç»´æŠ¤è€…æ”¯æŒçš„é€Ÿåº¦ã€‚ä¸ºäº†éƒ¨ç½²æœ€æ–°çš„æ¨¡å‹ï¼Œéƒ¨ç½²å·¥ç¨‹å¸ˆå¾€å¾€éœ€è¦è‡ªå·±åœ¨ ONNX å’Œæ¨ç†å¼•æ“ä¸­æ”¯æŒæ–°ç®—å­ã€‚
* **ä¸­é—´è¡¨ç¤ºä¸æ¨ç†å¼•æ“çš„å…¼å®¹é—®é¢˜ã€‚**ç”±äºå„æ¨ç†å¼•æ“çš„å®ç°ä¸åŒï¼Œå¯¹ ONNX éš¾ä»¥å½¢æˆç»Ÿä¸€çš„æ”¯æŒã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒçš„æ¨ç†å¼•æ“ä¸­æœ‰åŒæ ·çš„è¿è¡Œæ•ˆæœï¼Œéƒ¨ç½²å·¥ç¨‹å¸ˆå¾€å¾€å¾—ä¸ºæŸä¸ªæ¨ç†å¼•æ“å®šåˆ¶æ¨¡å‹ä»£ç ï¼Œè¿™ä¸ºæ¨¡å‹éƒ¨ç½²å¼•å…¥äº†è®¸å¤šå·¥ä½œé‡ã€‚

### **é—®é¢˜ï¼šå®ç°åŠ¨æ€æ”¾å¤§çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹**

åœ¨åŸæ¥çš„ SRCNN ä¸­ï¼Œå›¾ç‰‡çš„æ”¾å¤§æ¯”ä¾‹æ˜¯å†™æ­»åœ¨æ¨¡å‹é‡Œçš„ï¼š

```python
class SuperResolutionNet(nn.Module):
    def __init__(self, upscale_factor):
        super().__init__()
        self.upscale_factor = upscale_factor
        self.img_upsampler = nn.Upsample(
            scale_factor=self.upscale_factor,
            mode='bicubic',
            align_corners=False)

...

def init_torch_model():
    torch_model = SuperResolutionNet(upscale_factor=3)
```

æˆ‘ä»¬ä½¿ç”¨ upscale\_factor æ¥æ§åˆ¶æ¨¡å‹çš„æ”¾å¤§æ¯”ä¾‹ã€‚åˆå§‹åŒ–æ¨¡å‹çš„æ—¶å€™ï¼Œæˆ‘ä»¬é»˜è®¤ä»¤ upscale\_factor ä¸º 3ï¼Œç”Ÿæˆäº†ä¸€ä¸ªæ”¾å¤§ 3 å€çš„ PyTorch æ¨¡å‹ã€‚è¿™ä¸ª PyTorch æ¨¡å‹æœ€ç»ˆè¢«è½¬æ¢æˆäº† ONNX æ ¼å¼çš„æ¨¡å‹ã€‚å¦‚æœæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ”¾å¤§ 4 å€çš„æ¨¡å‹ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆä¸€éæ¨¡å‹ï¼Œå†åšä¸€æ¬¡åˆ° ONNX çš„è½¬æ¢ã€‚

ç°åœ¨ï¼Œå‡è®¾æˆ‘ä»¬è¦åšä¸€ä¸ªè¶…åˆ†è¾¨ç‡çš„åº”ç”¨ã€‚æˆ‘ä»¬çš„ç”¨æˆ·å¸Œæœ›å›¾ç‰‡çš„æ”¾å¤§å€æ•°èƒ½å¤Ÿè‡ªç”±è®¾ç½®ã€‚è€Œæˆ‘ä»¬äº¤ç»™ç”¨æˆ·çš„ï¼Œåªæœ‰ä¸€ä¸ª .onnx æ–‡ä»¶å’Œè¿è¡Œè¶…åˆ†è¾¨ç‡æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚æˆ‘ä»¬åœ¨ä¸ä¿®æ”¹ .onnx æ–‡ä»¶çš„å‰æä¸‹æ”¹å˜æ”¾å¤§å€æ•°ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»ä¿®æ”¹åŸæ¥çš„æ¨¡å‹ï¼Œä»¤æ¨¡å‹çš„æ”¾å¤§å€æ•°å˜æˆæ¨ç†æ—¶çš„è¾“å…¥ã€‚åœ¨ä¸Šé¢ Python è„šæœ¬çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬åšä¸€äº›ä¿®æ”¹ï¼Œå¾—åˆ°è¿™æ ·çš„è„šæœ¬ï¼š

```python
import torch
from torch import nn
from torch.nn.functional import interpolate
import torch.onnx
import cv2
import numpy as np


class SuperResolutionNet(nn.Module):

    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)
        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)
        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)

        self.relu = nn.ReLU()

    def forward(self, x, upscale_factor):
        x = interpolate(x,
                        scale_factor=upscale_factor,
                        mode='bicubic',
                        align_corners=False)
        out = self.relu(self.conv1(x))
        out = self.relu(self.conv2(out))
        out = self.conv3(out)
        return out


def init_torch_model():
    torch_model = SuperResolutionNet()

    state_dict = torch.load('srcnn.pth')['state_dict']

    # Adapt the checkpoint
    for old_key in list(state_dict.keys()):
        new_key = '.'.join(old_key.split('.')[1:])
        state_dict[new_key] = state_dict.pop(old_key)

    torch_model.load_state_dict(state_dict)
    torch_model.eval()
    return torch_model


model = init_torch_model()

input_img = cv2.imread('face.png').astype(np.float32)

# HWC to NCHW
input_img = np.transpose(input_img, [2, 0, 1])
input_img = np.expand_dims(input_img, 0)

# Inference
torch_output = model(torch.from_numpy(input_img), 3).detach().numpy()

# NCHW to HWC
torch_output = np.squeeze(torch_output, 0)
torch_output = np.clip(torch_output, 0, 255)
torch_output = np.transpose(torch_output, [1, 2, 0]).astype(np.uint8)

# Show image
cv2.imwrite("face_torch_2.png", torch_output)
```

SuperResolutionNet æœªä¿®æ”¹ä¹‹å‰ï¼Œnn.Upsample åœ¨åˆå§‹åŒ–é˜¶æ®µå›ºåŒ–äº†æ”¾å¤§å€æ•°ï¼Œè€Œ PyTorch çš„ interpolate æ’å€¼ç®—å­å¯ä»¥åœ¨è¿è¡Œé˜¶æ®µé€‰æ‹©æ”¾å¤§å€æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æ–°è„šæœ¬ä¸­ä½¿ç”¨ interpolate ä»£æ›¿ nn.Upsampleï¼Œä»è€Œè®©æ¨¡å‹æ”¯æŒåŠ¨æ€æ”¾å¤§å€æ•°çš„è¶…åˆ†ã€‚åœ¨ç¬¬ 55 è¡Œä½¿ç”¨æ¨¡å‹æ¨ç†æ—¶ï¼Œæˆ‘ä»¬æŠŠæ”¾å¤§å€æ•°è®¾ç½®ä¸º 3ã€‚æœ€åï¼Œå›¾ç‰‡ä¿å­˜åœ¨æ–‡ä»¶ "face\_torch\_2.png" ä¸­ã€‚ä¸€åˆ‡æ­£å¸¸çš„è¯ï¼Œ"face\_torch\_2.png" å’Œ "face\_torch.png" çš„å†…å®¹ä¸€æ¨¡ä¸€æ ·ã€‚

é€šè¿‡ç®€å•çš„ä¿®æ”¹ï¼ŒPyTorch æ¨¡å‹å·²ç»æ”¯æŒäº†åŠ¨æ€åˆ†è¾¨ç‡ã€‚ç°åœ¨æˆ‘ä»¬æ¥å°è¯•ä¸€ä¸‹å¯¼å‡ºæ¨¡å‹ï¼š

```python
x = torch.randn(1, 3, 256, 256)

with torch.no_grad():
    torch.onnx.export(model, (x, 3),
                      "srcnn2.onnx",
                      opset_version=11,
                      input_names=['input', 'factor'],
                      output_names=['output'])
```

è¿è¡Œè¿™äº›è„šæœ¬æ—¶ï¼Œä¼šæŠ¥ä¸€é•¿ä¸²é”™è¯¯ã€‚æ²¡åŠæ³•ï¼Œæˆ‘ä»¬ç¢°åˆ°äº†æ¨¡å‹éƒ¨ç½²ä¸­çš„å…¼å®¹æ€§é—®é¢˜ã€‚

```bash
    return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)
TypeError: upsample_bicubic2d() received an invalid combination of arguments - got (Tensor, NoneType, bool, list), but expected one of:
 * (Tensor input, tuple of ints output_size, bool align_corners, tuple of floats scale_factors)
      didn't match because some of the arguments have invalid types: (Tensor, NoneType, bool, list of [Tensor, Tensor])
 * (Tensor input, tuple of ints output_size, bool align_corners, float scales_h, float scales_w, *, Tensor out)
```

### **è§£å†³æ–¹æ³•ï¼šè‡ªå®šä¹‰ç®—å­**

ç›´æ¥ä½¿ç”¨ PyTorch æ¨¡å‹çš„è¯ï¼Œæˆ‘ä»¬ä¿®æ”¹å‡ è¡Œä»£ç å°±èƒ½å®ç°æ¨¡å‹è¾“å…¥çš„åŠ¨æ€åŒ–ã€‚ä½†åœ¨æ¨¡å‹éƒ¨ç½²ä¸­ï¼Œæˆ‘ä»¬è¦èŠ±æ•°å€çš„æ—¶é—´æ¥è®¾æ³•è§£å†³è¿™ä¸€é—®é¢˜ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬é¡ºç€è§£å†³é—®é¢˜çš„æ€è·¯ï¼Œä½“éªŒä¸€ä¸‹æ¨¡å‹éƒ¨ç½²çš„å›°éš¾ï¼Œå¹¶å­¦ä¹ ä½¿ç”¨è‡ªå®šä¹‰ç®—å­çš„æ–¹å¼ï¼Œè§£å†³è¶…åˆ†è¾¨ç‡æ¨¡å‹çš„åŠ¨æ€åŒ–é—®é¢˜ã€‚

<mark style="color:red;">åˆšåˆšçš„æŠ¥é”™æ˜¯å› ä¸º PyTorch æ¨¡å‹åœ¨å¯¼å‡ºåˆ° ONNX æ¨¡å‹æ—¶ï¼Œæ¨¡å‹çš„è¾“å…¥å‚æ•°çš„ç±»å‹å¿…é¡»å…¨éƒ¨æ˜¯ torch.Tensorã€‚è€Œå®é™…ä¸Šæˆ‘ä»¬ä¼ å…¥çš„ç¬¬äºŒä¸ªå‚æ•°" 3 "æ˜¯ä¸€ä¸ªæ•´å½¢å˜é‡ã€‚è¿™ä¸ç¬¦åˆ PyTorch è½¬ ONNX çš„è§„å®šã€‚</mark>æˆ‘ä»¬å¿…é¡»è¦ä¿®æ”¹ä¸€ä¸‹åŸæ¥çš„æ¨¡å‹çš„è¾“å…¥ã€‚ä¸ºäº†ä¿è¯è¾“å…¥çš„æ‰€æœ‰å‚æ•°éƒ½æ˜¯ torch.Tensor ç±»å‹çš„ï¼Œæˆ‘ä»¬åšå¦‚ä¸‹ä¿®æ”¹ï¼š

```python
...

class SuperResolutionNet(nn.Module):

    def forward(self, x, upscale_factor):
        x = interpolate(x,
                        scale_factor=upscale_factor.item(),
                        mode='bicubic',
                        align_corners=False)
        
...

# Inference
# Note that the second input is torch.tensor(3)
torch_output = model(torch.from_numpy(input_img), torch.tensor(3)).detach().numpy()

...

with torch.no_grad():
    torch.onnx.export(model, (x, torch.tensor(3)),
                      "srcnn2.onnx",
                      opset_version=11,
                      input_names=['input', 'factor'],
                      output_names=['output'])
```

<mark style="color:red;">ç”±äº PyTorch ä¸­ interpolate çš„ scale\_factor å‚æ•°å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å€¼ï¼Œæˆ‘ä»¬ä½¿ç”¨ torch.Tensor.item() æ¥æŠŠåªæœ‰ä¸€ä¸ªå…ƒç´ çš„ torch.Tensor è½¬æ¢æˆæ•°å€¼ã€‚</mark>ä¹‹åï¼Œåœ¨æ¨¡å‹æ¨ç†æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ torch.tensor(3) ä»£æ›¿ 3ï¼Œä»¥ä½¿å¾—æˆ‘ä»¬çš„æ‰€æœ‰è¾“å…¥éƒ½æ»¡è¶³è¦æ±‚ã€‚ç°åœ¨è¿è¡Œè„šæœ¬çš„è¯ï¼Œæ— è®ºæ˜¯ç›´æ¥è¿è¡Œæ¨¡å‹ï¼Œè¿˜æ˜¯å¯¼å‡º ONNX æ¨¡å‹ï¼Œéƒ½ä¸ä¼šæŠ¥é”™äº†ã€‚

ä½†æ˜¯ï¼Œå¯¼å‡º ONNX æ—¶å´æŠ¥äº†ä¸€æ¡ TraceWarning çš„è­¦å‘Šã€‚è¿™æ¡è­¦å‘Šè¯´æœ‰ä¸€äº›é‡å¯èƒ½ä¼šè¿½è¸ªå¤±è´¥ã€‚

```bash
TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  scale_factor=upscale_factor.item(),
============ Diagnostic Run torch.onnx.export version 2.0.0+nv23.05 ============
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================
```

è¿™æ˜¯æ€ä¹ˆå›äº‹å‘¢ï¼Ÿè®©æˆ‘ä»¬æŠŠç”Ÿæˆçš„ srcnn2.onnx ç”¨ Netron å¯è§†åŒ–ä¸€ä¸‹ï¼š

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (2) (1) (1) (1) (1) (1).png" alt="" width="375"><figcaption></figcaption></figure>

å¯ä»¥å‘ç°ï¼Œè™½ç„¶æˆ‘ä»¬æŠŠæ¨¡å‹æ¨ç†çš„è¾“å…¥è®¾ç½®ä¸ºäº†ä¸¤ä¸ªï¼Œä½† ONNX æ¨¡å‹è¿˜æ˜¯é•¿å¾—å’ŒåŸæ¥ä¸€æ¨¡ä¸€æ ·ï¼Œåªæœ‰ä¸€ä¸ªå« " input " çš„è¾“å…¥ã€‚<mark style="color:red;">è¿™æ˜¯ç”±äºæˆ‘ä»¬ä½¿ç”¨äº† torch.Tensor.item() æŠŠæ•°æ®ä» Tensor é‡Œå–å‡ºæ¥ï¼Œè€Œå¯¼å‡º ONNX æ¨¡å‹æ—¶è¿™ä¸ªæ“ä½œæ˜¯æ— æ³•è¢«è®°å½•çš„ï¼Œåªå¥½æŠ¥äº†ä¸€æ¡ TraceWarningã€‚</mark>è¿™å¯¼è‡´ interpolate æ’å€¼å‡½æ•°çš„æ”¾å¤§å€æ•°è¿˜æ˜¯è¢«è®¾ç½®æˆäº†" 3 "è¿™ä¸ªå›ºå®šå€¼ï¼Œæˆ‘ä»¬å¯¼å‡ºçš„" srcnn2.onnx "å’Œæœ€å¼€å§‹çš„" srcnn.onnx "å®Œå…¨ç›¸åŒã€‚

ç›´æ¥ä¿®æ”¹åŸæ¥çš„æ¨¡å‹ä¼¼ä¹è¡Œä¸é€šï¼Œæˆ‘ä»¬å¾—ä» PyTorch è½¬ ONNX çš„åŸç†å…¥æ‰‹ï¼Œå¼ºè¡Œä»¤ ONNX æ¨¡å‹æ˜ç™½æˆ‘ä»¬çš„æƒ³æ³•äº†ã€‚

ä»”ç»†è§‚å¯Ÿ Netron ä¸Šå¯è§†åŒ–å‡ºçš„ ONNX æ¨¡å‹ï¼Œå¯ä»¥å‘ç°åœ¨ PyTorch ä¸­æ— è®ºæ˜¯ä½¿ç”¨æœ€æ—©çš„ nn.Upsampleï¼Œè¿˜æ˜¯åæ¥çš„ interpolateï¼ŒPyTorch é‡Œçš„æ’å€¼æ“ä½œæœ€åéƒ½ä¼šè½¬æ¢æˆ ONNX å®šä¹‰çš„ Resize æ“ä½œã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€è°“ PyTorch è½¬ ONNXï¼Œå®é™…ä¸Šå°±æ˜¯æŠŠæ¯ä¸ª PyTorch çš„æ“ä½œæ˜ å°„æˆäº† ONNX å®šä¹‰çš„ç®—å­ã€‚

ç‚¹å‡»è¯¥ç®—å­ï¼Œå¯ä»¥çœ‹åˆ°å®ƒçš„è¯¦ç»†å‚æ•°å¦‚ä¸‹ï¼š

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (3) (1) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

å…¶ä¸­ï¼Œå±•å¼€ scalesï¼Œå¯ä»¥çœ‹åˆ° scales æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º 4 çš„ä¸€ç»´å¼ é‡ï¼Œå…¶å†…å®¹ä¸º \[1, 1, 3, 3], è¡¨ç¤º Resize  æ“ä½œæ¯ä¸€ä¸ªç»´åº¦çš„ç¼©æ”¾ç³»æ•°ï¼›å…¶ç±»å‹ä¸º Initializerï¼Œè¡¨ç¤ºè¿™ä¸ªå€¼æ˜¯æ ¹æ®å¸¸é‡ç›´æ¥åˆå§‹åŒ–å‡ºæ¥çš„ã€‚<mark style="color:red;">å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿè‡ªå·±ç”Ÿæˆä¸€ä¸ª ONNX çš„ Resize ç®—å­ï¼Œè®© scales æˆä¸ºä¸€ä¸ªå¯å˜é‡è€Œä¸æ˜¯å¸¸é‡ï¼Œå°±åƒå®ƒä¸Šé¢çš„ X ä¸€æ ·ï¼Œé‚£è¿™ä¸ªè¶…åˆ†è¾¨ç‡æ¨¡å‹å°±èƒ½åŠ¨æ€ç¼©æ”¾äº†ã€‚</mark>

<mark style="color:red;">ç°æœ‰å®ç°æ’å€¼çš„ PyTorch ç®—å­æœ‰ä¸€å¥—è§„å®šå¥½çš„æ˜ å°„åˆ° ONNX Resize ç®—å­çš„æ–¹æ³•ï¼Œè¿™äº›æ˜ å°„å‡ºçš„ Resize ç®—å­çš„ scales åªèƒ½æ˜¯å¸¸é‡ï¼Œæ— æ³•æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚ã€‚æˆ‘ä»¬å¾—è‡ªå·±å®šä¹‰ä¸€ä¸ªå®ç°æ’å€¼çš„ PyTorch ç®—å­ï¼Œç„¶åè®©å®ƒæ˜ å°„åˆ°ä¸€ä¸ªæˆ‘ä»¬æœŸæœ›çš„ ONNX Resize ç®—å­ä¸Šã€‚</mark>

ä¸‹é¢çš„è„šæœ¬å®šä¹‰äº†ä¸€ä¸ª PyTorch æ’å€¼ç®—å­ï¼Œå¹¶åœ¨æ¨¡å‹é‡Œä½¿ç”¨äº†å®ƒã€‚æˆ‘ä»¬å…ˆé€šè¿‡è¿è¡Œæ¨¡å‹æ¥éªŒè¯è¯¥ç®—å­çš„æ­£ç¡®æ€§ï¼š

```python
import torch
from torch import nn
from torch.nn.functional import interpolate
import torch.onnx
import cv2
import numpy as np


class NewInterpolate(torch.autograd.Function):

    @staticmethod
    def symbolic(g, input, scales):
        return g.op("Resize",
                    input,
                    g.op("Constant",
                         value_t=torch.tensor([], dtype=torch.float32)),
                    scales,
                    coordinate_transformation_mode_s="pytorch_half_pixel",
                    cubic_coeff_a_f=-0.75,
                    mode_s='cubic',
                    nearest_mode_s="floor")

    @staticmethod
    def forward(ctx, input, scales):
        scales = scales.tolist()[-2:]
        return interpolate(input,
                           scale_factor=scales,
                           mode='bicubic',
                           align_corners=False)


class StrangeSuperResolutionNet(nn.Module):

    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)
        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)
        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)

        self.relu = nn.ReLU()

    def forward(self, x, upscale_factor):
        x = NewInterpolate.apply(x, upscale_factor)
        out = self.relu(self.conv1(x))
        out = self.relu(self.conv2(out))
        out = self.conv3(out)
        return out


def init_torch_model():
    torch_model = StrangeSuperResolutionNet()

    state_dict = torch.load('srcnn.pth')['state_dict']

    # Adapt the checkpoint
    for old_key in list(state_dict.keys()):
        new_key = '.'.join(old_key.split('.')[1:])
        state_dict[new_key] = state_dict.pop(old_key)

    torch_model.load_state_dict(state_dict)
    torch_model.eval()
    return torch_model


model = init_torch_model()
factor = torch.tensor([1, 1, 3, 3], dtype=torch.float)

input_img = cv2.imread('face.png').astype(np.float32)

# HWC to NCHW
input_img = np.transpose(input_img, [2, 0, 1])
input_img = np.expand_dims(input_img, 0)

# Inference
torch_output = model(torch.from_numpy(input_img), factor).detach().numpy()

# NCHW to HWC
torch_output = np.squeeze(torch_output, 0)
torch_output = np.clip(torch_output, 0, 255)
torch_output = np.transpose(torch_output, [1, 2, 0]).astype(np.uint8)

# Show image
cv2.imwrite("face_torch_3.png", torch_output)
```

æ¨¡å‹è¿è¡Œæ­£å¸¸çš„è¯ï¼Œä¸€å¹…æ”¾å¤§3å€çš„è¶…åˆ†è¾¨ç‡å›¾ç‰‡ä¼šä¿å­˜åœ¨"face\_torch\_3.png"ä¸­ï¼Œå…¶å†…å®¹å’Œ"face\_torch.png"å®Œå…¨ç›¸åŒã€‚

åœ¨åˆšåˆšé‚£ä¸ªè„šæœ¬ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰ PyTorch æ’å€¼ç®—å­çš„ä»£ç å¦‚ä¸‹ï¼š

```python
class NewInterpolate(torch.autograd.Function):

    @staticmethod
    def symbolic(g, input, scales):
        return g.op("Resize",
                    input,
                    g.op("Constant",
                         value_t=torch.tensor([], dtype=torch.float32)),
                    scales,
                    coordinate_transformation_mode_s="pytorch_half_pixel",
                    cubic_coeff_a_f=-0.75,
                    mode_s='cubic',
                    nearest_mode_s="floor")

    @staticmethod
    def forward(ctx, input, scales):
        scales = scales.tolist()[-2:]
        return interpolate(input,
                           scale_factor=scales,
                           mode='bicubic',
                           align_corners=False)
```

åœ¨å…·ä½“ä»‹ç»è¿™ä¸ªç®—å­çš„å®ç°å‰ï¼Œè®©æˆ‘ä»¬å…ˆç†æ¸…ä¸€ä¸‹æ€è·¯ã€‚<mark style="color:red;">æˆ‘ä»¬å¸Œæœ›æ–°çš„æ’å€¼ç®—å­æœ‰ä¸¤ä¸ªè¾“å…¥ï¼Œä¸€ä¸ªæ˜¯è¢«ç”¨äºæ“ä½œçš„å›¾åƒï¼Œä¸€ä¸ªæ˜¯å›¾åƒçš„æ”¾ç¼©æ¯”ä¾‹ã€‚</mark>å‰é¢è®²åˆ°ï¼Œä¸ºäº†å¯¹æ¥ ONNX ä¸­ Resize ç®—å­çš„ scales å‚æ•°ï¼Œè¿™ä¸ªæ”¾ç¼©æ¯”ä¾‹æ˜¯ä¸€ä¸ª \[1, 1, x, x] çš„å¼ é‡ï¼Œå…¶ä¸­ x ä¸ºæ”¾å¤§å€æ•°ã€‚åœ¨ä¹‹å‰æ”¾å¤§3å€çš„æ¨¡å‹ä¸­ï¼Œè¿™ä¸ªå‚æ•°è¢«å›ºå®šæˆäº†\[1, 1, 3, 3]ã€‚å› æ­¤ï¼Œåœ¨æ’å€¼ç®—å­ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹çš„ç¬¬äºŒä¸ªè¾“å…¥æ˜¯ä¸€ä¸ª \[1, 1, w, h] çš„å¼ é‡ï¼Œå…¶ä¸­ w å’Œ h åˆ†åˆ«æ˜¯å›¾ç‰‡å®½å’Œé«˜çš„æ”¾å¤§å€æ•°ã€‚

ææ¸…æ¥šäº†æ’å€¼ç®—å­çš„è¾“å…¥ï¼Œå†çœ‹ä¸€çœ‹ç®—å­çš„å…·ä½“å®ç°ã€‚<mark style="color:red;">ç®—å­çš„æ¨ç†è¡Œä¸ºç”±ç®—å­çš„ foward æ–¹æ³•å†³å®šã€‚è¯¥æ–¹æ³•çš„ç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡»ä¸º ctxï¼Œåé¢çš„å‚æ•°ä¸ºç®—å­çš„è‡ªå®šä¹‰è¾“å…¥</mark>ï¼Œæˆ‘ä»¬è®¾ç½®ä¸¤ä¸ªè¾“å…¥ï¼Œåˆ†åˆ«ä¸ºè¢«æ“ä½œçš„å›¾åƒå’Œæ”¾ç¼©æ¯”ä¾‹ã€‚ä¸ºä¿è¯æ¨ç†æ­£ç¡®ï¼Œéœ€è¦æŠŠ \[1, 1, w, h] æ ¼å¼çš„è¾“å…¥å¯¹æ¥åˆ°åŸæ¥çš„ interpolate å‡½æ•°ä¸Šã€‚æˆ‘ä»¬çš„åšæ³•æ˜¯æˆªå–è¾“å…¥å¼ é‡çš„åä¸¤ä¸ªå…ƒç´ ï¼ŒæŠŠè¿™ä¸¤ä¸ªå…ƒç´ ä»¥ list çš„æ ¼å¼ä¼ å…¥ interpolate çš„ scale\_factor å‚æ•°ã€‚

æ¥ä¸‹æ¥ï¼Œ<mark style="color:red;">æˆ‘ä»¬è¦å†³å®šæ–°ç®—å­æ˜ å°„åˆ° ONNX ç®—å­çš„æ–¹æ³•ã€‚æ˜ å°„åˆ° ONNX çš„æ–¹æ³•ç”±ä¸€ä¸ªç®—å­çš„ symbolic æ–¹æ³•å†³å®šã€‚symbolic æ–¹æ³•ç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡»æ˜¯g</mark>ï¼Œä¹‹åçš„å‚æ•°æ˜¯ç®—å­çš„è‡ªå®šä¹‰è¾“å…¥ï¼Œå’Œ forward å‡½æ•°ä¸€æ ·ã€‚<mark style="color:red;">ONNX ç®—å­çš„å…·ä½“å®šä¹‰ç”± g.op å®ç°ã€‚g.op çš„æ¯ä¸ªå‚æ•°éƒ½å¯ä»¥æ˜ å°„åˆ° ONNX ä¸­çš„ç®—å­å±æ€§</mark>ï¼š

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (4) (1) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

å¯¹äºå…¶ä»–å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç…§ç€ç°åœ¨çš„ Resize ç®—å­å¡«ã€‚è€Œè¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ç°åœ¨å¸Œæœ› scales å‚æ•°æ˜¯ç”±è¾“å…¥åŠ¨æ€å†³å®šçš„ã€‚å› æ­¤ï¼Œåœ¨å¡«å…¥ ONNX çš„ scales æ—¶ï¼Œæˆ‘ä»¬è¦æŠŠ symbolic æ–¹æ³•çš„è¾“å…¥å‚æ•°ä¸­çš„ scales å¡«å…¥ã€‚

#### g.opæµ…æ

`g.op` ç”¨äºå°† PyTorch çš„æ“ä½œç¬¦æ˜ å°„åˆ° ONNX çš„æ“ä½œç¬¦ã€‚

`g.op` çš„åŸºæœ¬ç”¨æ³•

```python
g.op(op_name, *inputs, **attrs)
```

**å…³é”®å‚æ•°è¯¦è§£ï¼š**

1. **`op_name`**ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼š
   * è¿™æ˜¯ ONNX æ“ä½œç¬¦çš„åç§°ã€‚ä¾‹å¦‚ï¼Œå¯¹äºå·ç§¯æ“ä½œï¼ŒONNX ä½¿ç”¨çš„æ˜¯ `"Conv"`ï¼›å¯¹äºä¸Šé‡‡æ ·ï¼Œä½¿ç”¨çš„æ˜¯ `"Resize"`ã€‚
2. **`*inputs`**ï¼ˆå¼ é‡ï¼‰ï¼š
   * è¿™äº›æ˜¯æ“ä½œç¬¦çš„è¾“å…¥ï¼Œå¯ä»¥æ˜¯å¼ é‡æˆ–å…¶ä»– ONNX æ“ä½œç¬¦çš„è¾“å‡ºã€‚
   * å¦‚æœæ“ä½œç¬¦æœ‰å¤šä¸ªè¾“å…¥ï¼Œå¯ä»¥ä¾æ¬¡ä¼ é€’å¤šä¸ªè¾“å…¥å¼ é‡ã€‚
3. **`**attrs`**ï¼ˆå…³é”®å­—å‚æ•°ï¼‰ï¼š
   * è¿™äº›æ˜¯æ“ä½œç¬¦çš„å±æ€§ã€‚æ¯ä¸ª ONNX æ“ä½œç¬¦éƒ½æœ‰ä¸åŒçš„å±æ€§ï¼Œè¿™äº›å±æ€§æ§åˆ¶æ“ä½œç¬¦çš„å…·ä½“è¡Œä¸ºã€‚å±æ€§çš„ç±»å‹å¯ä»¥æ˜¯æ•´æ•°ã€æµ®ç‚¹æ•°ã€å­—ç¬¦ä¸²ã€å¼ é‡æˆ–åˆ—è¡¨ã€‚

**1. ç®€å•çš„æ“ä½œç¬¦**

å‡è®¾æˆ‘ä»¬è¦å°† PyTorch ä¸­çš„ `Add` æ“ä½œå¯¼å‡ºä¸º ONNX ä¸­çš„ `Add` æ“ä½œç¬¦ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®šä¹‰ï¼š

```python
def symbolic(g, input1, input2):
    return g.op("Add", input1, input2)
```

è¿™ä¸ªå‡½æ•°å°† PyTorch çš„ä¸¤ä¸ªè¾“å…¥å¼ é‡ `input1` å’Œ `input2` æ˜ å°„ä¸º ONNX çš„ `Add` æ“ä½œç¬¦ã€‚è¿™é‡Œæ²¡æœ‰ç‰¹æ®Šçš„å±æ€§ã€‚

**2. å¸¦å±æ€§çš„æ“ä½œç¬¦**

æœ‰äº›æ“ä½œç¬¦é™¤äº†è¾“å…¥å¤–ï¼Œè¿˜éœ€è¦å®šä¹‰ä¸€äº›å±æ€§ã€‚ä¾‹å¦‚ï¼Œå·ç§¯ï¼ˆ`Conv`ï¼‰æ“ä½œç¬¦æœ‰å·ç§¯æ ¸çš„å¤§å°ã€æ­¥é•¿ã€å¡«å……ç­‰å±æ€§ï¼š

```python
def symbolic(g, input, weight, bias=None):
    return g.op("Conv", input, weight,
                bias if bias is not None else g.constant(0),
                kernel_shape_i=(3, 3),  # å·ç§¯æ ¸å¤§å°
                strides_i=(1, 1),       # æ­¥é•¿
                pads_i=(1, 1, 1, 1))    # å¡«å……
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`g.op("Conv", ...)` å®šä¹‰äº†ä¸€ä¸ªå·ç§¯æ“ä½œï¼š

* `input` æ˜¯è¾“å…¥å¼ é‡ã€‚
* `weight` æ˜¯å·ç§¯æ ¸æƒé‡ã€‚
* `bias` æ˜¯å¯é€‰çš„ï¼Œå¦‚æœæ²¡æœ‰æä¾›åˆ™ä½¿ç”¨å¸¸æ•° 0ã€‚
* **å±æ€§éƒ¨åˆ†**ï¼š
  * `kernel_shape_i`ï¼šå·ç§¯æ ¸çš„å¤§å°ï¼Œè¿™é‡Œæ˜¯ `3x3`ã€‚
  * `strides_i`ï¼šæ­¥é•¿ï¼Œè¿™é‡Œæ˜¯ `(1, 1)`ã€‚
  * `pads_i`ï¼šå¡«å……å¤§å°ï¼Œè¿™é‡ŒæŒ‡å®šäº†å››ä¸ªç»´åº¦çš„å¡«å……é‡ `(1, 1, 1, 1)`ã€‚

æ³¨æ„ï¼š

* å±æ€§åç§°åé¢çš„ `_i`ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªæ•´å‹çš„å±æ€§ã€‚PyTorch ä¸­ä¼šæ ¹æ®ç±»å‹å¯¹å±æ€§è¿›è¡Œä¸åŒçš„åç¼€æ ‡è®°ï¼š
  * `_i`ï¼šæ•´å‹ï¼ˆintegerï¼‰
  * `_f`ï¼šæµ®ç‚¹å‹ï¼ˆfloatï¼‰
  * `_s`ï¼šå­—ç¬¦ä¸²ï¼ˆstringï¼‰
  * `_t`ï¼šå¼ é‡ï¼ˆtensorï¼‰

**3. å¸¦å¸¸é‡è¾“å…¥çš„æ“ä½œç¬¦**

å¦‚æœæ“ä½œç¬¦éœ€è¦å¸¸é‡è¾“å…¥ï¼Œæ¯”å¦‚ `Resize` æ“ä½œä¸­çš„ `roi` æ˜¯å¸¸é‡ï¼Œå¯ä»¥é€šè¿‡ `g.op("Constant", ...)` æ¥å®šä¹‰å¸¸é‡è¾“å…¥ï¼š

```python
def symbolic(g, input, scales):
    roi = g.op("Constant", value_t=torch.tensor([], dtype=torch.float32))  # å®šä¹‰ä¸€ä¸ªç©ºçš„ roi å¸¸é‡
    return g.op("Resize", input, roi, scales, mode_s="nearest")
```

åœ¨è¿™é‡Œï¼Œ`roi` è¢«å®šä¹‰ä¸ºä¸€ä¸ªå¸¸é‡ï¼Œå¹¶ä½œä¸º `Resize` æ“ä½œçš„ç¬¬äºŒä¸ªè¾“å…¥ã€‚`g.op("Constant", ...)` è¡¨ç¤ºä¸€ä¸ªå¸¸é‡èŠ‚ç‚¹ï¼Œ`value_t` æ˜¯å¼ é‡å¸¸é‡çš„å€¼ã€‚



æ¥ç€ï¼Œè®©æˆ‘ä»¬æŠŠæ–°æ¨¡å‹å¯¼å‡ºæˆ ONNX æ¨¡å‹ï¼š

```python
x = torch.randn(1, 3, 256, 256)
factor = torch.tensor([1, 1, 3, 3], dtype=torch.float)

with torch.no_grad():
    torch.onnx.export(model, (x, factor),
                      "srcnn3.onnx",
                      opset_version=11,
                      input_names=['input', 'factor'],
                      output_names=['output'])
```

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (5) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

å¯ä»¥çœ‹åˆ°ï¼Œæ­£å¦‚æˆ‘ä»¬æ‰€æœŸæœ›çš„ï¼Œå¯¼å‡ºçš„ ONNX æ¨¡å‹æœ‰äº†ä¸¤ä¸ªè¾“å…¥ï¼ç¬¬äºŒä¸ªè¾“å…¥è¡¨ç¤ºå›¾åƒçš„æ”¾ç¼©æ¯”ä¾‹ã€‚

ä¹‹å‰åœ¨éªŒè¯ PyTorch æ¨¡å‹å’Œå¯¼å‡º ONNX æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å®½é«˜çš„ç¼©æ”¾æ¯”ä¾‹è®¾ç½®æˆäº† 3x3ã€‚ç°åœ¨ï¼Œåœ¨ç”¨ ONNX Runtime æ¨ç†æ—¶ï¼Œæˆ‘ä»¬å°è¯•ä½¿ç”¨ 4x4 çš„ç¼©æ”¾æ¯”ä¾‹ï¼š

```python
import onnxruntime

input_factor = np.array([1, 1, 4, 4], dtype=np.float32)
ort_session = onnxruntime.InferenceSession("srcnn3.onnx")
ort_inputs = {'input': input_img, 'factor': input_factor}
ort_output = ort_session.run(None, ort_inputs)[0]

ort_output = np.squeeze(ort_output, 0)
ort_output = np.clip(ort_output, 0, 255)
ort_output = np.transpose(ort_output, [1, 2, 0]).astype(np.uint8)
cv2.imwrite("face_ort_3.png", ort_output)
```

è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªè¾¹é•¿æ”¾å¤§4å€çš„è¶…åˆ†è¾¨ç‡å›¾ç‰‡ "face\_ort\_3.png"ã€‚åŠ¨æ€çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹ç”ŸæˆæˆåŠŸäº†ï¼åªè¦ä¿®æ”¹ input\_factorï¼Œæˆ‘ä»¬å°±å¯ä»¥è‡ªç”±åœ°æ§åˆ¶å›¾ç‰‡çš„ç¼©æ”¾æ¯”ä¾‹ã€‚

> äº‹å®ä¸Šï¼Œæˆ‘ä»¬ä¸ä»…å¯ä»¥åœ¨ç°æœ‰çš„ ONNX ç®—å­çš„åŸºç¡€ä¸Šè¿›è¡Œæ”¹é€ ï¼Œè¿˜å¯ä»¥å®šä¹‰æ–°çš„ ONNX ç®—å­ä»¥æ‹“å±• ONNX çš„è¡¨è¾¾èƒ½åŠ›ã€‚
