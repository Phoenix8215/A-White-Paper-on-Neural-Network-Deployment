# ğŸ˜ ç”¨pythonæ“ä½œONNX

æ¥ä¸‹æ¥çš„ç« èŠ‚å°†é‡ç‚¹ä»‹ç»å¦‚ä½•ä½¿ç”¨_onnx_æä¾›çš„[Python API](https://onnx.ai/onnx/api/index.html#l-python-onnx-api)æ„å»º ONNX è®¡ç®—å›¾ã€‚

### ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼šçº¿æ€§å›å½’

çº¿æ€§å›å½’æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€ç®€å•çš„æ¨¡å‹ï¼Œå…¶è¡¨è¾¾å¼å¦‚ä¸‹.æˆ‘ä»¬å¯ä»¥å°†å…¶è§†ä¸ºä¸‰ä¸ªå˜é‡çš„å‡½æ•° åˆ†è§£ä¸º`y = Add(MatMul(X, A), B`)ã€‚è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦ç”¨ ONNX è¿ç®—ç¬¦è¡¨ç¤ºçš„å†…å®¹ã€‚é¦–å…ˆæ˜¯ç”¨[ONNX](https://onnx.ai/onnx/operators/index.html#l-onnx-operators) è¿ç®—ç¬¦å®ç°å‡½æ•°ã€‚ ONNX æ˜¯å¼ºç±»å‹çš„ã€‚å¿…é¡»ä¸ºå‡½æ•°çš„è¾“å…¥å’Œè¾“å‡ºå®šä¹‰å½¢çŠ¶å’Œç±»å‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨[make å‡½æ•°](https://onnx.ai/onnx/api/helper.html#l-onnx-make-function)ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å››ä¸ªå‡½æ•°æ¥æ„å»ºè®¡ç®—å›¾ï¼š

* `make_tensor_value_info`ï¼šå£°æ˜å˜é‡ï¼ˆè¾“å…¥æˆ–è¾“å‡ºï¼‰çš„å½¢çŠ¶å’Œç±»å‹
* `make_node`ï¼šåˆ›å»ºä¸€ä¸ªç”±æ“ä½œç¬¦ç±»å‹(ç®—å­åç§°)ã€è¾“å…¥å’Œè¾“å‡ºå®šä¹‰çš„èŠ‚ç‚¹
* `make_graph`ï¼šåˆ©ç”¨å‰ä¸¤ä¸ªå‡½æ•°åˆ›å»ºçš„å¯¹è±¡åˆ›å»º ONNX è®¡ç®—å›¾
* `make_model`ï¼šåˆå¹¶è®¡ç®—å›¾å’Œé¢å¤–çš„å…ƒæ•°æ®

åœ¨åˆ›å»ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºå›¾ä¸­æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥å’Œè¾“å‡ºå‘½åã€‚å›¾çš„è¾“å…¥å’Œè¾“å‡ºç”± onnx å¯¹è±¡å®šä¹‰ï¼Œå­—ç¬¦ä¸²ç”¨äºæŒ‡ä»£ä¸­é—´ç»“æœã€‚çœ‹èµ·æ¥å°±æ˜¯è¿™æ ·ã€‚

```
# imports

from onnx import TensorProto
from onnx.helper import (
    make_model, make_node, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

# inputs

# 'X' is the name, TensorProto.FLOAT the type, [None, None] the shape
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])

# outputs, the shape is left undefined

Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

# nodes

# It creates a node defined by the operator type MatMul,
# 'X', 'A' are the inputs of the node, 'XA' the output.
node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])

# from nodes to graph
# the graph is built from the list of nodes, the list of inputs,
# the list of outputs and a name.

graph = make_graph([node1, node2],  # nodes
                    'lr',  # a name
                    [X, A, B],  # inputs
                    [Y])  # outputs

# onnx graph
# there is no metadata in this case.

onnx_model = make_model(graph)

# Let's check the model is consistent,
# this function is described in section
# Checker and Shape Inference.
check_model(onnx_model)

# the work is done, let's display it...
print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 21
}
```



ç©ºå½¢çŠ¶`ï¼ˆæ— `ï¼‰è¡¨ç¤ºä»»ä½•å½¢çŠ¶ï¼Œå®šä¹‰ä¸º`[æ— ï¼Œ æ— ]`çš„å½¢çŠ¶è¡¨ç¤ºè¯¥å¯¹è±¡æ˜¯ä¸€ä¸ªä¸¤ç»´å¼ é‡ï¼Œæ²¡æœ‰ä»»ä½•è¿›ä¸€æ­¥çš„ç²¾åº¦ã€‚ é€šè¿‡æŸ¥çœ‹å›¾ä¸­æ¯ä¸ªå¯¹è±¡çš„å­—æ®µï¼Œä¹Ÿå¯ä»¥æ£€æŸ¥ ONNX å›¾ã€‚

```
from onnx import TensorProto
from onnx.helper import (
    make_model, make_node, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

def shape2tuple(shape):
    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)

# the list of inputs
print('** inputs **')
print(onnx_model.graph.input)

# in a more nicely format
print('** inputs **')
for obj in onnx_model.graph.input:
    print("name=%r dtype=%r shape=%r" % (
        obj.name, obj.type.tensor_type.elem_type,
        shape2tuple(obj.type.tensor_type.shape)))

# the list of outputs
print('** outputs **')
print(onnx_model.graph.output)

# in a more nicely format
print('** outputs **')
for obj in onnx_model.graph.output:
    print("name=%r dtype=%r shape=%r" % (
        obj.name, obj.type.tensor_type.elem_type,
        shape2tuple(obj.type.tensor_type.shape)))

# the list of nodes
print('** nodes **')
print(onnx_model.graph.node)

# in a more nicely format
print('** nodes **')
for node in onnx_model.graph.node:
    print("name=%r type=%r input=%r output=%r" % (
        node.name, node.op_type, node.input, node.output))
```

```
** inputs **
[name: "X"
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
, name: "A"
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
, name: "B"
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
]
** inputs **
name='X' dtype=1 shape=(0, 0)
name='A' dtype=1 shape=(0, 0)
name='B' dtype=1 shape=(0, 0)
** outputs **
[name: "Y"
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
    }
  }
}
]
** outputs **
name='Y' dtype=1 shape=(0,)
** nodes **
[input: "X"
input: "A"
output: "XA"
op_type: "MatMul"
, input: "XA"
input: "B"
output: "Y"
op_type: "Add"
]
** nodes **
name='' type='MatMul' input=['X', 'A'] output=['XA']
name='' type='Add' input=['XA', 'B'] output=['Y']
```

å¼ é‡ç±»å‹æ˜¯æ•´æ•°ï¼ˆ= 1ï¼‰ã€‚è¾…åŠ©å‡½æ•°[`onnx.helper.tensor_dtype_too_np_dtype()`](https://onnx.ai/onnx/api/helper.html#onnx.helper.tensor\_dtype\_to\_np\_dtype)ä¼šç»™å‡ºä¸ numpy å¯¹åº”çš„ç±»å‹ã€‚

```
from onnx import TensorProto
from onnx.helper import tensor_dtype_to_np_dtype, tensor_dtype_to_string

np_dtype = tensor_dtype_to_np_dtype(TensorProto.FLOAT)
print(f"The converted numpy dtype for {tensor_dtype_to_string(TensorProto.FLOAT)} is {np_dtype}.")
```

```
The converted numpy dtype for TensorProto.FLOAT is float32.
```

### [åºåˆ—åŒ–](broken-reference)\#

ONNX å»ºç«‹åœ¨ protobuf çš„åŸºç¡€ä¹‹ä¸Šã€‚å®ƒä¸ºæè¿°æœºå™¨å­¦ä¹ æ¨¡å‹æ·»åŠ äº†å¿…è¦çš„å®šä¹‰ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒONNX æ˜¯ç”¨æ¥åºåˆ—åŒ–æˆ–ååºåˆ—åŒ–æ¨¡å‹çš„ã€‚ç¬¬äºŒéƒ¨åˆ†ä»‹ç»äº†æ•°æ®çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–ï¼Œå¦‚å¼ é‡ã€ç¨€ç–å¼ é‡......

#### å‹å·[åºåˆ—åŒ–](broken-reference)\#

ONNX åŸºäº protobufã€‚å®ƒæœ€å¤§é™åº¦åœ°å‡å°‘äº†åœ¨ç£ç›˜ä¸Šä¿å­˜å›¾å½¢æ‰€éœ€çš„ç©ºé—´ã€‚onnx ä¸­çš„æ¯ä¸ªå¯¹è±¡ï¼ˆå‚è§[Protos](https://onnx.ai/onnx/api/classes.html#l-onnx-classes)ï¼‰éƒ½å¯ä»¥é€šè¿‡`SerializeToString` æ–¹æ³•åºåˆ—åŒ–ã€‚æ•´ä¸ªæ¨¡å‹éƒ½æ˜¯å¦‚æ­¤ã€‚

```
from onnx import TensorProto
from onnx.helper import (
    make_model, make_node, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

def shape2tuple(shape):
    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)

# The serialization
with open("linear_regression.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

# display
print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 21
}
```

å›¾å½¢å¯é€šè¿‡å‡½æ•°`åŠ è½½`æ¢å¤ï¼š

```
from onnx import load

with open("linear_regression.onnx", "rb") as f:
    onnx_model = load(f)

# display
print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 21
}
```

çœ‹èµ·æ¥å®Œå…¨ä¸€æ ·ã€‚ä»»ä½•æ¨¡å‹éƒ½å¯ä»¥ç”¨è¿™ç§æ–¹å¼åºåˆ—åŒ–ï¼Œé™¤éå®ƒä»¬çš„å¤§å°è¶…è¿‡ 2 Gbã€‚æ¥ä¸‹æ¥çš„ç« èŠ‚å°†ä»‹ç»å¦‚ä½•å…‹æœè¿™ä¸€é™åˆ¶ã€‚

#### æ•°æ®[åºåˆ—åŒ–](broken-reference)\#

å¼ é‡çš„åºåˆ—åŒ–è¿‡ç¨‹é€šå¸¸å¦‚ä¸‹ï¼š

```
import numpy
from onnx.numpy_helper import from_array

numpy_tensor = numpy.array([0, 1, 4, 5, 3], dtype=numpy.float32)
print(type(numpy_tensor))

onnx_tensor = from_array(numpy_tensor)
print(type(onnx_tensor))

serialized_tensor = onnx_tensor.SerializeToString()
print(type(serialized_tensor))

with open("saved_tensor.pb", "wb") as f:
    f.write(serialized_tensor)
```

```
<class 'numpy.ndarray'>
<class 'onnx.onnx_ml_pb2.TensorProto'>
<class 'bytes'>
```

è¿˜æœ‰ååºåˆ—åŒ–ï¼š

```
from onnx import TensorProto
from onnx.numpy_helper import to_array

with open("saved_tensor.pb", "rb") as f:
    serialized_tensor = f.read()
print(type(serialized_tensor))

onnx_tensor = TensorProto()
onnx_tensor.ParseFromString(serialized_tensor)
print(type(onnx_tensor))

numpy_tensor = to_array(onnx_tensor)
print(numpy_tensor)
```

```
<class 'bytes'>
<class 'onnx.onnx_ml_pb2.TensorProto'>
[0. 1. 4. 5. 3.]
```

åŒæ ·çš„æ¨¡å¼å¯ç”¨äºä½†ä¸é™äº[TensorProto](https://onnx.ai/onnx/api/classes.html#l-tensorproto)ï¼š

```
import onnx
import pprint
pprint.pprint([p for p in dir(onnx)
               if p.endswith('Proto') and p[0] != '_'])
```

```
['AttributeProto',
 'FunctionProto',
 'GraphProto',
 'MapProto',
 'ModelProto',
 'NodeProto',
 'OperatorProto',
 'OperatorSetIdProto',
 'OperatorSetProto',
 'OptionalProto',
 'SequenceProto',
 'SparseTensorProto',
 'StringStringEntryProto',
 'TensorProto',
 'TensorShapeProto',
 'TrainingInfoProto',
 'TypeProto',
 'ValueInfoProto']
```

ä½¿ç”¨å‡½æ•°_load\_tensor\_from\_string_å¯ä»¥ç®€åŒ–è¿™æ®µä»£ç ï¼ˆè¯·å‚é˜…åŠ [è½½ Proto](https://onnx.ai/onnx/api/serialization.html#l-onnx-load-data)ï¼‰ã€‚

```
from onnx import load_tensor_from_string

with open("saved_tensor.pb", "rb") as f:
    serialized = f.read()
proto = load_tensor_from_string(serialized)
print(type(proto))
```

```
<class 'onnx.onnx_ml_pb2.TensorProto'>
```

### åˆå§‹åŒ–å™¨ï¼Œ[é»˜è®¤å€¼](broken-reference)\#

ä¹‹å‰çš„æ¨¡å‹å‡å®šçº¿æ€§å›å½’çš„ç³»æ•°ä¹Ÿæ˜¯æ¨¡å‹çš„è¾“å…¥ã€‚è¿™ä¸æ˜¯å¾ˆæ–¹ä¾¿ã€‚ä¸ºäº†éµå¾ª onnx è¯­ä¹‰ï¼Œå®ƒä»¬åº”è¯¥ä½œä¸ºå¸¸é‡æˆ–**åˆå§‹åŒ–å™¨**æˆä¸ºæ¨¡å‹æœ¬èº«çš„ä¸€éƒ¨åˆ†ã€‚ä¸‹ä¸€ä¸ªç¤ºä¾‹ä¿®æ”¹äº†ä¸Šä¸€ä¸ªç¤ºä¾‹ï¼Œå°†è¾“å…¥`A`å’Œ`B`å˜ä¸ºåˆå§‹åŒ–å™¨ã€‚è½¯ä»¶åŒ…å®ç°äº†ä¸¤ä¸ªå‡½æ•°ï¼Œå¯ä»¥å°† numpy è½¬æ¢ä¸º onnxï¼Œä¹Ÿå¯ä»¥åè¿‡æ¥è½¬æ¢ï¼ˆå‚è§[æ•°ç»„](https://onnx.ai/onnx/api/numpy\_helper.html#l-numpy-helper-onnx-array)ï¼‰ã€‚

* `onnx.numpy_helper.to_array`ï¼šä» onnx è½¬æ¢åˆ° numpy
* `onnx.numpy_helper.from_array`: ä» numpy è½¬æ¢åˆ° onnx

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

# initializers
value = numpy.array([0.5, -0.6], dtype=numpy.float32)
A = numpy_helper.from_array(value, name='A')

value = numpy.array([0.4], dtype=numpy.float32)
C = numpy_helper.from_array(value, name='C')

# the part which does not change
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['AX'])
node2 = make_node('Add', ['AX', 'C'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X], [Y], [A, C])
onnx_model = make_model(graph)
check_model(onnx_model)

print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "X"
    input: "A"
    output: "AX"
    op_type: "MatMul"
  }
  node {
    input: "AX"
    input: "C"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  initializer {
    dims: 2
    data_type: 1
    name: "A"
    raw_data: "\000\000\000?\232\231\031\277"
  }
  initializer {
    dims: 1
    data_type: 1
    name: "C"
    raw_data: "\315\314\314>"
  }
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 21
}
```



åŒæ ·ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ onnx ç»“æ„æ¥æŸ¥çœ‹åˆå§‹åŒ–å™¨çš„å¤–è§‚ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

# initializers
value = numpy.array([0.5, -0.6], dtype=numpy.float32)
A = numpy_helper.from_array(value, name='A')

value = numpy.array([0.4], dtype=numpy.float32)
C = numpy_helper.from_array(value, name='C')

# the part which does not change
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['AX'])
node2 = make_node('Add', ['AX', 'C'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X], [Y], [A, C])
onnx_model = make_model(graph)
check_model(onnx_model)

print('** initializer **')
for init in onnx_model.graph.initializer:
    print(init)
```

```
** initializer **
dims: 2
data_type: 1
name: "A"
raw_data: "\000\000\000?\232\231\031\277"

dims: 1
data_type: 1
name: "C"
raw_data: "\315\314\314>"
```

ç±»å‹å®šä¹‰ä¸ºæ•´æ•°ï¼Œå«ä¹‰ç›¸åŒã€‚ åœ¨ç¬¬äºŒä¸ªç¤ºä¾‹ä¸­ï¼Œåªå‰©ä¸‹ä¸€ä¸ªè¾“å…¥ç«¯ã€‚ è¾“å…¥ç«¯`A`å’Œ`B`è¢«åˆ é™¤ã€‚å®ƒä»¬å¯ä»¥ä¿ç•™ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒä»¬æ˜¯å¯é€‰çš„ï¼šæ¯ä¸ªä¸è¾“å…¥å€¼åŒåçš„ initiliazer éƒ½è¢«è§†ä¸ºé»˜è®¤å€¼ã€‚å¦‚æœæ²¡æœ‰è¾“å…¥å€¼ï¼Œå®ƒå°±ä¼šå–ä»£è¾“å…¥å€¼ã€‚

### [å±æ€§](broken-reference)\#

æœ‰äº›è¿ç®—ç¬¦éœ€è¦å±æ€§ï¼Œå¦‚[åè½¬](https://onnx.ai/onnx/operators/onnx\_\_Transpose.html#l-onnx-doc-transpose)è¿ç®—ç¬¦ã€‚ è®©æˆ‘ä»¬ä¸ºè¡¨è¾¾å¼ç»˜åˆ¶å›¾è¡¨ æˆ–`y = Add(MatMul(X, Transpose(A))+ B`)ã€‚Transpose éœ€è¦ä¸€ä¸ªå®šä¹‰åæ ‡è½´æ’åˆ—çš„å±æ€§ï¼š`perm=[1, 0]`ã€‚å®ƒåœ¨å‡½æ•°`make_node` ä¸­ä½œä¸ºå‘½åå±æ€§æ·»åŠ ã€‚

```
from onnx import TensorProto
from onnx.helper import (
    make_model, make_node, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

# unchanged
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

# added
node_transpose = make_node('Transpose', ['A'], ['tA'], perm=[1, 0])

# unchanged except A is replaced by tA
node1 = make_node('MatMul', ['X', 'tA'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])

# node_transpose is added to the list
graph = make_graph([node_transpose, node1, node2],
                   'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)

# the work is done, let's display it...
print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "A"
    output: "tA"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 1
      ints: 0
      type: INTS
    }
  }
  node {
    input: "X"
    input: "tA"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 21
}
```



_make_å‡½æ•°çš„æ•´ä¸ªåˆ—è¡¨å¦‚ä¸‹ã€‚å…¶ä¸­è®¸å¤šå‡½æ•°å°†åœ¨[make å‡½æ•°](https://onnx.ai/onnx/api/helper.html#l-onnx-make-function)ä¸€èŠ‚ä¸­ä»‹ç»ã€‚

```
import onnx
import pprint
pprint.pprint([k for k in dir(onnx.helper)
               if k.startswith('make')])
```

```
['make_attribute',
 'make_attribute_ref',
 'make_empty_tensor_value_info',
 'make_function',
 'make_graph',
 'make_map',
 'make_map_type_proto',
 'make_model',
 'make_model_gen_version',
 'make_node',
 'make_operatorsetid',
 'make_opsetid',
 'make_optional',
 'make_optional_type_proto',
 'make_sequence',
 'make_sequence_type_proto',
 'make_sparse_tensor',
 'make_sparse_tensor_type_proto',
 'make_sparse_tensor_value_info',
 'make_tensor',
 'make_tensor_sequence_value_info',
 'make_tensor_type_proto',
 'make_tensor_value_info',
 'make_training_info',
 'make_value_info']
```

### Opset å’Œ[å…ƒ](broken-reference)æ•°æ®\#

è®©æˆ‘ä»¬åŠ è½½ä¹‹å‰åˆ›å»ºçš„ ONNX æ–‡ä»¶ï¼Œçœ‹çœ‹å®ƒæœ‰å“ªäº›å…ƒæ•°æ®ã€‚

```
from onnx import load

with open("linear_regression.onnx", "rb") as f:
    onnx_model = load(f)

for field in ['doc_string', 'domain', 'functions',
              'ir_version', 'metadata_props', 'model_version',
              'opset_import', 'producer_name', 'producer_version',
              'training_info']:
    print(field, getattr(onnx_model, field))
```

```
doc_string 
domain 
functions []
ir_version 10
metadata_props []
model_version 0
opset_import [version: 21
]
producer_name 
producer_version 
training_info []
```

å…¶ä¸­å¤§éƒ¨åˆ†æ˜¯ç©ºçš„ï¼Œå› ä¸ºåœ¨åˆ›å»º ONNX å›¾å½¢æ—¶æ²¡æœ‰å¡«å……ã€‚å…¶ä¸­ä¸¤ä¸ªæœ‰æ•°å€¼ï¼š

```
from onnx import load

with open("linear_regression.onnx", "rb") as f:
    onnx_model = load(f)

print("ir_version:", onnx_model.ir_version)
for opset in onnx_model.opset_import:
    print("opset domain=%r version=%r" % (opset.domain, opset.version))
```

```
ir_version: 10
opset domain='' version=21
```

`IR`å®šä¹‰äº† ONNX è¯­è¨€çš„ç‰ˆæœ¬ã€‚ Opset å®šä¹‰äº†æ‰€ç”¨è¿ç®—ç¬¦çš„ç‰ˆæœ¬ã€‚ åœ¨æ²¡æœ‰ä»»ä½•ç²¾ç¡®åº¦çš„æƒ…å†µä¸‹ï¼ŒONNX ä½¿ç”¨å®‰è£…åŒ…ä¸­çš„æœ€æ–°ç‰ˆæœ¬ã€‚ ä¹Ÿå¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ªç‰ˆæœ¬ã€‚

```
from onnx import load

with open("linear_regression.onnx", "rb") as f:
    onnx_model = load(f)

del onnx_model.opset_import[:]
opset = onnx_model.opset_import.add()
opset.domain = ''
opset.version = 14

for opset in onnx_model.opset_import:
    print("opset domain=%r version=%r" % (opset.domain, opset.version))
```

```
opset domain='' version=14
```

åªè¦æ‰€æœ‰æ“ä½œç¬¦éƒ½æŒ‰ç…§ ONNX è§„å®šçš„æ–¹å¼å®šä¹‰ï¼Œå°±å¯ä»¥ä½¿ç”¨ä»»ä½•æ“ä½œé›†ã€‚æ“ä½œç¬¦_Reshape_çš„ç¬¬ 5 ç‰ˆå°†å½¢çŠ¶å®šä¹‰ä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯ç¬¬ 1 ç‰ˆä¸­çš„å±æ€§ã€‚æ“ä½œé›†è¯´æ˜äº†åœ¨æè¿°å›¾å½¢æ—¶æ‰€éµå¾ªçš„è§„èŒƒã€‚

å…¶ä»–å…ƒæ•°æ®å¯ç”¨äºå­˜å‚¨ä»»ä½•ä¿¡æ¯ï¼Œå¦‚æœ‰å…³æ¨¡å‹ç”Ÿæˆæ–¹å¼çš„ä¿¡æ¯ã€ç”¨ç‰ˆæœ¬å·åŒºåˆ†æ¨¡å‹çš„æ–¹æ³•ç­‰ã€‚

```
from onnx import load, helper

with open("linear_regression.onnx", "rb") as f:
    onnx_model = load(f)

onnx_model.model_version = 15
onnx_model.producer_name = "something"
onnx_model.producer_version = "some other thing"
onnx_model.doc_string = "documentation about this model"
prop = onnx_model.metadata_props

data = dict(key1="value1", key2="value2")
helper.set_model_props(onnx_model, data)

print(onnx_model)
```

```
ir_version: 10
producer_name: "something"
producer_version: "some other thing"
model_version: 15
doc_string: "documentation about this model"
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  version: 21
}
metadata_props {
  key: "key1"
  value: "value1"
}
metadata_props {
  key: "key2"
  value: "value2"
}
```

å­—æ®µ`training_info`å¯ç”¨äºå­˜å‚¨å…¶ä»–å›¾è¡¨ã€‚ è¯·å‚è§[training\_tool\_test.py](https://github.com/onnx/onnx/blob/main/onnx/test/training\_tool\_test.py)ï¼Œäº†è§£å…¶å·¥ä½œåŸç†ã€‚

### å­å›¾è°±ï¼šæµ‹è¯•å’Œ[å¾ªç¯](broken-reference)\#

å®ƒä»¬é€šå¸¸è¢«å½’ä¸ºä¸€ç±»ï¼Œç§°ä¸º_æ§åˆ¶æµ_ã€‚ é€šå¸¸æœ€å¥½é¿å…ä½¿ç”¨å®ƒä»¬ï¼Œå› ä¸ºå®ƒä»¬çš„æ•ˆç‡ä¸é«˜ï¼Œè€ŒçŸ©é˜µæ“ä½œçš„é€Ÿåº¦å’Œä¼˜åŒ–ç¨‹åº¦è¦é«˜å¾—å¤šã€‚

#### å¦‚æœ[#](broken-reference)

æµ‹è¯•å¯ä»¥ä½¿ç”¨æ“ä½œç¬¦[If](https://onnx.ai/onnx/operators/onnx\_\_If.html#l-onnx-doc-if) æ¥å®ç°ï¼Œå®ƒæ ¹æ®ä¸€ä¸ªå¸ƒå°”å€¼æ‰§è¡Œä¸€ä¸ªå­å›¾æˆ–å¦ä¸€ä¸ªå­å›¾ã€‚è¿™ç§æ–¹æ³•å¹¶ä¸å¸¸ç”¨ï¼Œå› ä¸ºå‡½æ•°é€šå¸¸éœ€è¦æ‰¹é‡æ¯”è¾ƒå¤šä¸ªç»“æœã€‚ ä¸‹é¢çš„ç¤ºä¾‹æ ¹æ®ç¬¦å·è®¡ç®—çŸ©é˜µä¸­æ‰€æœ‰æµ®ç‚¹æ•°çš„å’Œï¼Œè¿”å› 1 æˆ–-1ã€‚

```
import numpy
import onnx
from onnx.helper import (
    make_node, make_graph, make_model, make_tensor_value_info)
from onnx.numpy_helper import from_array
from onnx.checker import check_model
from onnxruntime import InferenceSession

# initializers
value = numpy.array([0], dtype=numpy.float32)
zero = from_array(value, name='zero')

# Same as before, X is the input, Y is the output.
X = make_tensor_value_info('X', onnx.TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', onnx.TensorProto.FLOAT, [None])

# The node building the condition. The first one
# sum over all axes.
rsum = make_node('ReduceSum', ['X'], ['rsum'])
# The second compares the result to 0.
cond = make_node('Greater', ['rsum', 'zero'], ['cond'])

# Builds the graph is the condition is True.
# Input for then
then_out = make_tensor_value_info(
    'then_out', onnx.TensorProto.FLOAT, None)
# The constant to return.
then_cst = from_array(numpy.array([1]).astype(numpy.float32))

# The only node.
then_const_node = make_node(
    'Constant', inputs=[],
    outputs=['then_out'],
    value=then_cst, name='cst1')

# And the graph wrapping these elements.
then_body = make_graph(
    [then_const_node], 'then_body', [], [then_out])

# Same process for the else branch.
else_out = make_tensor_value_info(
    'else_out', onnx.TensorProto.FLOAT, [5])
else_cst = from_array(numpy.array([-1]).astype(numpy.float32))

else_const_node = make_node(
    'Constant', inputs=[],
    outputs=['else_out'],
    value=else_cst, name='cst2')

else_body = make_graph(
    [else_const_node], 'else_body',
    [], [else_out])

# Finally the node If taking both graphs as attributes.
if_node = onnx.helper.make_node(
    'If', ['cond'], ['Y'],
    then_branch=then_body,
    else_branch=else_body)

# The final graph.
graph = make_graph([rsum, cond, if_node], 'if', [X], [Y], [zero])
onnx_model = make_model(graph)
check_model(onnx_model)

# Let's freeze the opset.
del onnx_model.opset_import[:]
opset = onnx_model.opset_import.add()
opset.domain = ''
opset.version = 15
onnx_model.ir_version = 8

# Save.
with open("onnx_if_sign.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

# Let's see the output.
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])

x = numpy.ones((3, 2), dtype=numpy.float32)
res = sess.run(None, {'X': x})

# It works.
print("result", res)
print()

# Some display.
print(onnx_model)
```

```
result [array([1.], dtype=float32)]

ir_version: 8
graph {
  node {
    input: "X"
    output: "rsum"
    op_type: "ReduceSum"
  }
  node {
    input: "rsum"
    input: "zero"
    output: "cond"
    op_type: "Greater"
  }
  node {
    input: "cond"
    output: "Y"
    op_type: "If"
    attribute {
      name: "else_branch"
      g {
        node {
          output: "else_out"
          name: "cst2"
          op_type: "Constant"
          attribute {
            name: "value"
            t {
              dims: 1
              data_type: 1
              raw_data: "\000\000\200\277"
            }
            type: TENSOR
          }
        }
        name: "else_body"
        output {
          name: "else_out"
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                  dim_value: 5
                }
              }
            }
          }
        }
      }
      type: GRAPH
    }
    attribute {
      name: "then_branch"
      g {
        node {
          output: "then_out"
          name: "cst1"
          op_type: "Constant"
          attribute {
            name: "value"
            t {
              dims: 1
              data_type: 1
              raw_data: "\000\000\200?"
            }
            type: TENSOR
          }
        }
        name: "then_body"
        output {
          name: "then_out"
          type {
            tensor_type {
              elem_type: 1
            }
          }
        }
      }
      type: GRAPH
    }
  }
  name: "if"
  initializer {
    dims: 1
    data_type: 1
    name: "zero"
    raw_data: "\000\000\000\000"
  }
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  domain: ""
  version: 15
}
```

æœ‰äº†ä¸‹é¢çš„å›¾ç‰‡ï¼Œæ•´ä¸ªè¿‡ç¨‹å°±æ›´ç›´è§‚äº†ã€‚



else å’Œ then åˆ†æ”¯éƒ½éå¸¸ç®€å•ï¼Œç”šè‡³å¯ä»¥ç”¨_Where_èŠ‚ç‚¹ä»£æ›¿_If_èŠ‚ç‚¹ï¼Œè¿™æ ·é€Ÿåº¦ä¼šæ›´å¿«ã€‚å½“ä¸¤ä¸ªåˆ†æ”¯éƒ½æ¯”è¾ƒå¤§ï¼Œè·³è¿‡å…¶ä¸­ä¸€ä¸ªåˆ†æ”¯ä¼šæ›´æœ‰æ•ˆæ—¶ï¼Œæƒ…å†µå°±å˜å¾—æœ‰è¶£äº†ã€‚

#### [æ‰«æ](broken-reference)\#

åœ¨é˜…è¯»è¯´æ˜æ—¶ï¼Œ[Scan](https://onnx.ai/onnx/operators/onnx\_\_Scan.html#l-onnx-doc-scan)ä¼¼ä¹ç›¸å½“å¤æ‚ã€‚ å¾ªç¯å¼ é‡çš„ä¸€ä¸ªç»´åº¦å¹¶å°†ç»“æœå­˜å‚¨åœ¨é¢„å…ˆåˆ†é…çš„å¼ é‡ä¸­æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚

ä¸‹é¢çš„ç¤ºä¾‹ä¸ºå›å½’é—®é¢˜å®ç°äº†ç»å…¸çš„è¿‘é‚»è®¡ç®—ã€‚ç¬¬ä¸€æ­¥æ˜¯è®¡ç®—è¾“å…¥ç‰¹å¾_X_å’Œè®­ç»ƒé›†_W_ ä¹‹é—´çš„æˆå¯¹è·ç¦»ï¼š .æ¥ä¸‹æ¥çš„è¿ç®—ç¬¦[TopK](https://onnx.ai/onnx/operators/onnx\_\_TopK.html#l-onnx-doc-topk)å¯ä»¥æå–_k ä¸ª_æœ€è¿‘çš„é‚»å±…ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor, make_graph,
    make_tensor_value_info)
from onnx.checker import check_model

# subgraph
initializers = []
nodes = []
inputs = []
outputs = []

value = make_tensor_value_info('next_in', 1, [None, 4])
inputs.append(value)
value = make_tensor_value_info('next', 1, [None])
inputs.append(value)

value = make_tensor_value_info('next_out', 1, [None, None])
outputs.append(value)
value = make_tensor_value_info('scan_out', 1, [None])
outputs.append(value)

node = make_node(
    'Identity', ['next_in'], ['next_out'],
    name='cdistd_17_Identity', domain='')
nodes.append(node)

node = make_node(
    'Sub', ['next_in', 'next'], ['cdistdf_17_C0'],
    name='cdistdf_17_Sub', domain='')
nodes.append(node)

node = make_node(
    'ReduceSumSquare', ['cdistdf_17_C0'], ['cdistdf_17_reduced0'],
    name='cdistdf_17_ReduceSumSquare', axes=[1], keepdims=0, domain='')
nodes.append(node)

node = make_node(
    'Identity', ['cdistdf_17_reduced0'],
    ['scan_out'], name='cdistdf_17_Identity', domain='')
nodes.append(node)

graph = make_graph(nodes, 'OnnxIdentity',
                   inputs, outputs, initializers)

# main graph

initializers = []
nodes = []
inputs = []
outputs = []

opsets = {'': 15, 'ai.onnx.ml': 15}
target_opset = 15  # subgraphs

# initializers
list_value = [23.29599822460675, -120.86516699239603, -144.70495899914215, -260.08772982740413,
              154.65272105889147, -122.23295157108991, 247.45232560871727, -182.83789715805776,
              -132.92727431421793, 147.48710175784703, 88.27761768038069, -14.87785569894749,
              111.71487894705504, 301.0518319089629, -29.64235742280055, -113.78493504731911,
              -204.41218591022718, 112.26561056133608, 66.04032954135549,
              -229.5428380626701, -33.549262642481615, -140.95737409864623, -87.8145187836131,
              -90.61397011283958, 57.185488100413366, 56.864151796743855, 77.09054590340892,
              -187.72501631246712, -42.779503579806025, -21.642642730674076, -44.58517761667535,
              78.56025104939847, -23.92423223842056, 234.9166231927213, -73.73512816431007,
              -10.150864499514297, -70.37105466673813, 65.5755688281476, 108.68676290979731, -78.36748960443065]
value = numpy.array(list_value, dtype=numpy.float64).reshape((2, 20))
tensor = numpy_helper.from_array(
    value, name='knny_ArrayFeatureExtractorcst')
initializers.append(tensor)

list_value = [1.1394007205963135, -0.6848101019859314, -1.234825849533081, 0.4023416340351105,
              0.17742614448070526, 0.46278226375579834, -0.4017809331417084, -1.630198359489441,
              -0.5096521973609924, 0.7774903774261475, -0.4380742907524109, -1.2527953386306763,
              -1.0485529899597168, 1.950775384902954, -1.420017957687378, -1.7062702178955078,
              1.8675580024719238, -0.15135720372200012, -0.9772778749465942, 0.9500884413719177,
              -2.5529897212982178, -0.7421650290489197, 0.653618574142456, 0.8644362092018127,
              1.5327792167663574, 0.37816253304481506, 1.4693588018417358, 0.154947429895401,
              -0.6724604368209839, -1.7262825965881348, -0.35955315828323364, -0.8131462931632996,
              -0.8707971572875977, 0.056165341287851334, -0.5788496732711792, -0.3115525245666504,
              1.2302906513214111, -0.302302747964859, 1.202379822731018, -0.38732680678367615,
              2.269754648208618, -0.18718385696411133, -1.4543657302856445, 0.04575851559638977,
              -0.9072983860969543, 0.12898291647434235, 0.05194539576768875, 0.7290905714035034,
              1.4940791130065918, -0.8540957570075989, -0.2051582634449005, 0.3130677044391632,
              1.764052391052246, 2.2408931255340576, 0.40015721321105957, 0.978738009929657,
              0.06651721894741058, -0.3627411723136902, 0.30247190594673157, -0.6343221068382263,
              -0.5108051300048828, 0.4283318817615509, -1.18063223361969, -0.02818222902715206,
              -1.6138978004455566, 0.38690251111984253, -0.21274028718471527, -0.8954665660858154,
              0.7610377073287964, 0.3336743414402008, 0.12167501449584961, 0.44386324286460876,
              -0.10321885347366333, 1.4542734622955322, 0.4105985164642334, 0.14404356479644775,
              -0.8877857327461243, 0.15634897351264954, -1.980796456336975, -0.34791216254234314]
value = numpy.array(list_value, dtype=numpy.float32).reshape((20, 4))
tensor = numpy_helper.from_array(value, name='Sc_Scancst')
initializers.append(tensor)

value = numpy.array([2], dtype=numpy.int64)
tensor = numpy_helper.from_array(value, name='To_TopKcst')
initializers.append(tensor)

value = numpy.array([2, -1, 2], dtype=numpy.int64)
tensor = numpy_helper.from_array(value, name='knny_Reshapecst')
initializers.append(tensor)

# inputs
value = make_tensor_value_info('input', 1, [None, 4])
inputs.append(value)

# outputs
value = make_tensor_value_info('variable', 1, [None, 2])
outputs.append(value)

# nodes

node = make_node(
    'Scan', ['input', 'Sc_Scancst'], ['UU032UU', 'UU033UU'],
    name='Sc_Scan', body=graph, num_scan_inputs=1, domain='')
nodes.append(node)

node = make_node(
    'Transpose', ['UU033UU'], ['Tr_transposed0'],
    name='Tr_Transpose', perm=[1, 0], domain='')
nodes.append(node)

node = make_node(
    'Sqrt', ['Tr_transposed0'], ['Sq_Y0'],
    name='Sq_Sqrt', domain='')
nodes.append(node)

node = make_node(
    'TopK', ['Sq_Y0', 'To_TopKcst'], ['To_Values0', 'To_Indices1'],
    name='To_TopK', largest=0, sorted=1, domain='')
nodes.append(node)

node = make_node(
    'Flatten', ['To_Indices1'], ['knny_output0'],
    name='knny_Flatten', domain='')
nodes.append(node)

node = make_node(
    'ArrayFeatureExtractor',
    ['knny_ArrayFeatureExtractorcst', 'knny_output0'], ['knny_Z0'],
    name='knny_ArrayFeatureExtractor', domain='ai.onnx.ml')
nodes.append(node)

node = make_node(
    'Reshape', ['knny_Z0', 'knny_Reshapecst'], ['knny_reshaped0'],
    name='knny_Reshape', allowzero=0, domain='')
nodes.append(node)

node = make_node(
    'Transpose', ['knny_reshaped0'], ['knny_transposed0'],
    name='knny_Transpose', perm=[1, 0, 2], domain='')
nodes.append(node)

node = make_node(
    'Cast', ['knny_transposed0'], ['Ca_output0'],
    name='Ca_Cast', to=TensorProto.FLOAT, domain='')
nodes.append(node)

node = make_node(
    'ReduceMean', ['Ca_output0'], ['variable'],
    name='Re_ReduceMean', axes=[2], keepdims=0, domain='')
nodes.append(node)

# graph
graph = make_graph(nodes, 'KNN regressor', inputs, outputs, initializers)

# model
onnx_model = make_model(graph)
onnx_model.ir_version = 8
onnx_model.producer_name = 'skl2onnx'
onnx_model.producer_version = ''
onnx_model.domain = 'ai.onnx'
onnx_model.model_version = 0
onnx_model.doc_string = ''
set_model_props(onnx_model, {})

# opsets
del onnx_model.opset_import[:]
for dom, value in opsets.items():
    op_set = onnx_model.opset_import.add()
    op_set.domain = dom
    op_set.version = value

check_model(onnx_model)
with open("knnr.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

print(onnx_model)
```

```
ir_version: 8
producer_name: "skl2onnx"
producer_version: ""
domain: "ai.onnx"
model_version: 0
doc_string: ""
graph {
  node {
    input: "input"
    input: "Sc_Scancst"
    output: "UU032UU"
    output: "UU033UU"
    name: "Sc_Scan"
    op_type: "Scan"
    attribute {
      name: "body"
      g {
        node {
          input: "next_in"
          output: "next_out"
          name: "cdistd_17_Identity"
          op_type: "Identity"
          domain: ""
        }
        node {
          input: "next_in"
          input: "next"
          output: "cdistdf_17_C0"
          name: "cdistdf_17_Sub"
          op_type: "Sub"
          domain: ""
        }
        node {
          input: "cdistdf_17_C0"
          output: "cdistdf_17_reduced0"
          name: "cdistdf_17_ReduceSumSquare"
          op_type: "ReduceSumSquare"
          attribute {
            name: "axes"
            ints: 1
            type: INTS
          }
          attribute {
            name: "keepdims"
            i: 0
            type: INT
          }
          domain: ""
        }
        node {
          input: "cdistdf_17_reduced0"
          output: "scan_out"
          name: "cdistdf_17_Identity"
          op_type: "Identity"
          domain: ""
        }
        name: "OnnxIdentity"
        input {
          name: "next_in"
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
                dim {
                  dim_value: 4
                }
              }
            }
          }
        }
        input {
          name: "next"
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
              }
            }
          }
        }
        output {
          name: "next_out"
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
                dim {
                }
              }
            }
          }
        }
        output {
          name: "scan_out"
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                }
              }
            }
          }
        }
      }
      type: GRAPH
    }
    attribute {
      name: "num_scan_inputs"
      i: 1
      type: INT
    }
    domain: ""
  }
  node {
    input: "UU033UU"
    output: "Tr_transposed0"
    name: "Tr_Transpose"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 1
      ints: 0
      type: INTS
    }
    domain: ""
  }
  node {
    input: "Tr_transposed0"
    output: "Sq_Y0"
    name: "Sq_Sqrt"
    op_type: "Sqrt"
    domain: ""
  }
  node {
    input: "Sq_Y0"
    input: "To_TopKcst"
    output: "To_Values0"
    output: "To_Indices1"
    name: "To_TopK"
    op_type: "TopK"
    attribute {
      name: "largest"
      i: 0
      type: INT
    }
    attribute {
      name: "sorted"
      i: 1
      type: INT
    }
    domain: ""
  }
  node {
    input: "To_Indices1"
    output: "knny_output0"
    name: "knny_Flatten"
    op_type: "Flatten"
    domain: ""
  }
  node {
    input: "knny_ArrayFeatureExtractorcst"
    input: "knny_output0"
    output: "knny_Z0"
    name: "knny_ArrayFeatureExtractor"
    op_type: "ArrayFeatureExtractor"
    domain: "ai.onnx.ml"
  }
  node {
    input: "knny_Z0"
    input: "knny_Reshapecst"
    output: "knny_reshaped0"
    name: "knny_Reshape"
    op_type: "Reshape"
    attribute {
      name: "allowzero"
      i: 0
      type: INT
    }
    domain: ""
  }
  node {
    input: "knny_reshaped0"
    output: "knny_transposed0"
    name: "knny_Transpose"
    op_type: "Transpose"
    attribute {
      name: "perm"
      ints: 1
      ints: 0
      ints: 2
      type: INTS
    }
    domain: ""
  }
  node {
    input: "knny_transposed0"
    output: "Ca_output0"
    name: "Ca_Cast"
    op_type: "Cast"
    attribute {
      name: "to"
      i: 1
      type: INT
    }
    domain: ""
  }
  node {
    input: "Ca_output0"
    output: "variable"
    name: "Re_ReduceMean"
    op_type: "ReduceMean"
    attribute {
      name: "axes"
      ints: 2
      type: INTS
    }
    attribute {
      name: "keepdims"
      i: 0
      type: INT
    }
    domain: ""
  }
  name: "KNN regressor"
  initializer {
    dims: 2
    dims: 20
    data_type: 11
    name: "knny_ArrayFeatureExtractorcst"
    raw_data: ",\\&\212\306K7@\333z`\345^7^\300\304\312,\006\217\026b\300Z9dWgAp\300.+F\027\343Tc@\203\330\264\255\350\216^\300\260\022\216sy\356n@\237h\263\r\320\332f\300\224\277.;\254\235`\300\336\370lV\226ob@\261\201\362|\304\021V@c,[Mv\301-\300\322\214\240\223\300\355[@)\036\262M\324\320r@nE;\211q\244=\300\021n5`<r\\\300\207\211\201\2400\215i\300H\232p\303\377\020\\@\317K[\302\224\202P@&\306\355\355^\261l\300\301/\377<N\306@\300#w\001\317\242\236a\300$fd\023!\364U\300\204\327LIK\247V\300J\211\366\022\276\227L@\262\345\254\206\234nL@f{\013\201\313ES@\234\343hU3wg\300\3370\367\305\306cE\300\336A\347;\204\2445\300f\374\242\031\347JF\300\325\2557\'\333\243S@\331\354\345{\232\3547\300\307o)\372T]m@#\005\000W\014oR\300\'\025\227\034>M$\300\310\252\022\\\277\227Q\300l_\243\036\326dP@\333kk\354\363+[@\223)\036\363\204\227S\300"
  }
  initializer {
    dims: 20
    dims: 4
    data_type: 1
    name: "Sc_Scancst"
    raw_data: "\342\327\221?\267O/\277\306\016\236\277\271\377\315>3\2575>\314\361\354>;\266\315\276W\252\320\277\221x\002\277\234\tG?FK\340\276\231[\240\277\3746\206\277\002\263\371?&\303\265\277\020g\332\277$\014\357?b\375\032\276\342.z\277\3778s?/d#\300\207\376=\277\214S\'?\261K]?\0342\304?\205\236\301>\363\023\274?\212\252\036>^&,\277\324\366\334\277Z\027\270\276[*P\277\220\354^\277\241\rf=~/\024\277\320\203\237\276*z\235?m\307\232\276\225\347\231?\263O\306\276\251C\021@ \255?\276\250(\272\277Hm;=\265Dh\277\031\024\004>\262\304T=\256\245:?\374=\277?\005\246Z\277\002\025R\276iJ\240>x\314\341?\313j\017@h\341\314>\223\216z?.:\210=6\271\271\276\231\335\232>\357b\"\277 \304\002\277QN\333>\365\036\227\277k\336\346\2744\224\316\277\026\030\306>\227\330Y\276L=e\277^\323B?]\327\252>\3000\371=\013B\343>hd\323\275\242%\272?\3709\322>(\200\023>\355Ec\277\362\031 >\275\212\375\277\213!\262\276"
  }
  initializer {
    dims: 1
    data_type: 7
    name: "To_TopKcst"
    raw_data: "\002\000\000\000\000\000\000\000"
  }
  initializer {
    dims: 3
    data_type: 7
    name: "knny_Reshapecst"
    raw_data: "\002\000\000\000\000\000\000\000\377\377\377\377\377\377\377\377\002\000\000\000\000\000\000\000"
  }
  input {
    name: "input"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
            dim_value: 4
          }
        }
      }
    }
  }
  output {
    name: "variable"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
}
opset_import {
  domain: ""
  version: 15
}
opset_import {
  domain: "ai.onnx.ml"
  version: 15
}
```

ä»å¤–è§‚ä¸Šçœ‹ï¼Œå°±åƒä¸‹é¢è¿™æ ·ï¼š



å­å›¾ç”±æ“ä½œç¬¦[æ‰«æ](https://onnx.ai/onnx/operators/onnx\_\_Scan.html#l-onnx-doc-scan)æ‰§è¡Œã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåªæœ‰ä¸€ä¸ª_æ‰«æ_è¾“å…¥ï¼Œè¿™æ„å‘³ç€è¿ç®—ç¬¦åªç”Ÿæˆä¸€ä¸ªè¾“å‡ºã€‚

```
node = make_node(
    'Scan', ['X1', 'X2'], ['Y1', 'Y2'],
    name='Sc_Scan', body=graph, num_scan_inputs=1, domain='')
```

ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶ï¼Œå­å›¾å¾—åˆ°_X1_å’Œ_X2_ çš„ç¬¬ä¸€è¡Œã€‚ç¬¬ä¸€ä¸ªè¾“å‡ºåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­å–ä»£_X1_ï¼Œç¬¬äºŒä¸ªè¾“å‡ºå­˜å‚¨åœ¨ä¸€ä¸ªå®¹å™¨ä¸­ï¼Œå½¢æˆ_Y2_ã€‚åœ¨ç¬¬äºŒæ¬¡è¿­ä»£ä¸­ï¼Œå­å›¾çš„ç¬¬äºŒä¸ªè¾“å…¥æ˜¯_X2_ çš„ç¬¬äºŒè¡Œã€‚ ä¸‹é¢æ˜¯ä¸€ä¸ªç®€çŸ­çš„æ‘˜è¦ã€‚ç»¿è‰²ä¸ºç¬¬ä¸€æ¬¡è¿­ä»£ï¼Œè“è‰²ä¸ºç¬¬äºŒæ¬¡è¿­ä»£ã€‚



### [åŠŸèƒ½](broken-reference)\#

å¦‚å‰ä¸€ç« æ‰€è¿°ï¼Œå¦‚æœå­˜åœ¨å‡½æ•°çš„ç‰¹å®šå®ç°ï¼Œå‡½æ•°å¯ä»¥ç”¨æ¥ç¼©çŸ­æ„å»ºæ¨¡å‹çš„ä»£ç ï¼Œå¹¶ä¸ºè¿è¡Œæ—¶æ›´å¿«åœ°è¿è¡Œé¢„æµ‹æä¾›æ›´å¤šå¯èƒ½æ€§ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¿è¡Œæ—¶ä»å¯ä½¿ç”¨åŸºäºç°æœ‰è¿ç®—ç¬¦çš„é»˜è®¤å®ç°ã€‚

å‡½æ•°`make_function`ç”¨äºå®šä¹‰å‡½æ•°ã€‚ å®ƒçš„å·¥ä½œåŸç†ç±»ä¼¼äºç±»å‹è¾ƒå°‘çš„å›¾å½¢ã€‚å®ƒæ›´åƒæ˜¯ä¸€ä¸ªæ¨¡æ¿ã€‚è¯¥ API å¯èƒ½ä¼šä¸æ–­å‘å±•ã€‚å®ƒä¹Ÿä¸åŒ…æ‹¬åˆå§‹åŒ–å™¨ã€‚

#### æ— [å±æ€§](broken-reference)çš„å‡½æ•°\#

è¿™æ˜¯æ›´ç®€å•çš„æƒ…å†µã€‚å‡½æ•°çš„æ¯ä¸ªè¾“å…¥éƒ½æ˜¯æ‰§è¡Œæ—¶å·²çŸ¥çš„åŠ¨æ€å¯¹è±¡ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info, make_opsetid,
    make_function)
from onnx.checker import check_model

new_domain = 'custom'
opset_imports = [make_opsetid("", 14), make_opsetid(new_domain, 1)]

# Let's define a function for a linear regression

node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])

linear_regression = make_function(
    new_domain,            # domain name
    'LinearRegression',     # function name
    ['X', 'A', 'B'],        # input names
    ['Y'],                  # output names
    [node1, node2],         # nodes
    opset_imports,          # opsets
    [])                     # attribute names

# Let's use it in a graph.

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

graph = make_graph(
    [make_node('LinearRegression', ['X', 'A', 'B'], ['Y1'], domain=new_domain),
     make_node('Abs', ['Y1'], ['Y'])],
    'example',
    [X, A, B], [Y])

onnx_model = make_model(
    graph, opset_imports=opset_imports,
    functions=[linear_regression])  # functions to add)
check_model(onnx_model)

# the work is done, let's display it...
print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "X"
    input: "A"
    input: "B"
    output: "Y1"
    op_type: "LinearRegression"
    domain: "custom"
  }
  node {
    input: "Y1"
    output: "Y"
    op_type: "Abs"
  }
  name: "example"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  domain: ""
  version: 14
}
opset_import {
  domain: "custom"
  version: 1
}
functions {
  name: "LinearRegression"
  input: "X"
  input: "A"
  input: "B"
  output: "Y"
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  opset_import {
    domain: ""
    version: 14
  }
  opset_import {
    domain: "custom"
    version: 1
  }
  domain: "custom"
}
```

#### å¸¦æœ‰[å±æ€§](broken-reference)çš„å‡½æ•°\#

ä¸‹é¢çš„å‡½æ•°ä¸å‰é¢çš„å‡½æ•°ç›¸åŒï¼Œåªæ˜¯å°†ä¸€ä¸ªè¾“å…¥å˜é‡_B_ è½¬æ¢æˆäº†ä¸€ä¸ªåä¸º_bias_ çš„å‚æ•°ã€‚ ä»£ç å‡ ä¹ç›¸åŒï¼Œåªæ˜¯ bias ç°åœ¨æ˜¯ä¸€ä¸ªå¸¸é‡ã€‚ åœ¨å‡½æ•°å®šä¹‰ä¸­ï¼Œåˆ›å»ºäº†ä¸€ä¸ªèŠ‚ç‚¹_Constant_ï¼Œç”¨äºå°†å‚æ•°ä½œä¸ºç»“æœæ’å…¥ã€‚å®ƒé€šè¿‡`ref_attr_name` å±æ€§ä¸å‚æ•°ç›¸è¿ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto, AttributeProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info, make_opsetid,
    make_function)
from onnx.checker import check_model

new_domain = 'custom'
opset_imports = [make_opsetid("", 14), make_opsetid(new_domain, 1)]

# Let's define a function for a linear regression
# The first step consists in creating a constant
# equal to the input parameter of the function.
cst = make_node('Constant',  [], ['B'])

att = AttributeProto()
att.name = "value"

# This line indicates the value comes from the argument
# named 'bias' the function is given.
att.ref_attr_name = "bias"
att.type = AttributeProto.TENSOR
cst.attribute.append(att)

node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])

linear_regression = make_function(
    new_domain,            # domain name
    'LinearRegression',     # function name
    ['X', 'A'],             # input names
    ['Y'],                  # output names
    [cst, node1, node2],    # nodes
    opset_imports,          # opsets
    ["bias"])               # attribute names

# Let's use it in a graph.

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

graph = make_graph(
    [make_node('LinearRegression', ['X', 'A'], ['Y1'], domain=new_domain,
               # bias is now an argument of the function and is defined as a tensor
               bias=make_tensor('former_B', TensorProto.FLOAT, [1], [0.67])),
     make_node('Abs', ['Y1'], ['Y'])],
    'example',
    [X, A], [Y])

onnx_model = make_model(
    graph, opset_imports=opset_imports,
    functions=[linear_regression])  # functions to add)
check_model(onnx_model)

# the work is done, let's display it...
print(onnx_model)
```

```
ir_version: 10
graph {
  node {
    input: "X"
    input: "A"
    output: "Y1"
    op_type: "LinearRegression"
    attribute {
      name: "bias"
      t {
        dims: 1
        data_type: 1
        float_data: 0.6700000166893005
        name: "former_B"
      }
      type: TENSOR
    }
    domain: "custom"
  }
  node {
    input: "Y1"
    output: "Y"
    op_type: "Abs"
  }
  name: "example"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
opset_import {
  domain: ""
  version: 14
}
opset_import {
  domain: "custom"
  version: 1
}
functions {
  name: "LinearRegression"
  input: "X"
  input: "A"
  output: "Y"
  attribute: "bias"
  node {
    output: "B"
    op_type: "Constant"
    attribute {
      name: "value"
      type: TENSOR
      ref_attr_name: "bias"
    }
  }
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  opset_import {
    domain: ""
    version: 14
  }
  opset_import {
    domain: "custom"
    version: 1
  }
  domain: "custom"
}
```

### [è§£æ](broken-reference)\#

onnx æ¨¡å—æä¾›äº†ä¸€ç§å®šä¹‰å›¾è¡¨çš„æ›´å¿«æ–¹æ³•ï¼Œè€Œä¸”æ›´æ˜“äºé˜…è¯»ã€‚å¦‚æœå›¾å½¢æ˜¯åœ¨å•ä¸ªå‡½æ•°ä¸­æ„å»ºçš„ï¼Œé‚£ä¹ˆä½¿ç”¨èµ·æ¥å°±å¾ˆå®¹æ˜“ï¼Œä½†å¦‚æœå›¾å½¢æ˜¯ç”±æœºå™¨å­¦ä¹ ç®¡é“ä¸­çš„æ¯ä¸ªéƒ¨åˆ†è½¬æ¢è€Œæˆçš„å¤šä¸ªä¸åŒå‡½æ•°æ„å»ºçš„ï¼Œé‚£ä¹ˆå°±ä¸é‚£ä¹ˆå®¹æ˜“äº†ã€‚

```
import onnx.parser
from onnx.checker import check_model

input = '''
    <
        ir_version: 8,
        opset_import: [ "" : 15]
    >
    agraph (float[I,J] X, float[I] A, float[I] B) => (float[I] Y) {
        XA = MatMul(X, A)
        Y = Add(XA, B)
    }
    '''
onnx_model = onnx.parser.parse_model(input)
check_model(onnx_model)

print(onnx_model)
```

```
ir_version: 8
graph {
node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
    domain: ""
}
node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
    domain: ""
}
name: "agraph"
input {
    name: "X"
    type {
    tensor_type {
        elem_type: 1
        shape {
        dim {
            dim_param: "I"
        }
        dim {
            dim_param: "J"
        }
        }
    }
    }
}
input {
    name: "A"
    type {
    tensor_type {
        elem_type: 1
        shape {
        dim {
            dim_param: "I"
        }
        }
    }
    }
}
input {
    name: "B"
    type {
    tensor_type {
        elem_type: 1
        shape {
        dim {
            dim_param: "I"
        }
        }
    }
    }
}
output {
    name: "Y"
    type {
    tensor_type {
        elem_type: 1
        shape {
        dim {
            dim_param: "I"
        }
        }
    }
    }
}
}
opset_import {
domain: ""
version: 15
}
```

è¿™ç§æ–¹æ³•ç”¨äºåˆ›å»ºå°å‹æ¨¡å‹ï¼Œä½†å¾ˆå°‘ç”¨äºè½¬æ¢å›¾ä¹¦é¦†ã€‚

### æ£€æŸ¥å™¨å’Œå½¢çŠ¶[æ¨ç†](broken-reference)\#

onnx æä¾›äº†ä¸€ä¸ªæ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰æ•ˆçš„å‡½æ•°ã€‚ åªè¦èƒ½æ£€æµ‹åˆ°ä¸ä¸€è‡´ï¼Œå®ƒå°±ä¼šæ£€æŸ¥è¾“å…¥ç±»å‹æˆ–å½¢çŠ¶ã€‚ ä¸‹é¢çš„ç¤ºä¾‹æ·»åŠ äº†ä¸¤ä¸ªä¸åŒç±»å‹çš„çŸ©é˜µï¼Œè¿™æ˜¯ä¸å…è®¸çš„ã€‚

```
import onnx.parser
import onnx.checker

input = '''
    <
        ir_version: 8,
        opset_import: [ "" : 15]
    >
    agraph (float[I,4] X, float[4,2] A, int[4] B) => (float[I] Y) {
        XA = MatMul(X, A)
        Y = Add(XA, B)
    }
    '''
try:
    onnx_model = onnx.parser.parse_model(input)
    onnx.checker.check_model(onnx_model)
except Exception as e:
    print(e)
```

```
b'[ParseError at position (line: 6 column: 44)]\nError context:     agraph (float[I,4] X, float[4,2] A, int[4] B) => (float[I] Y) {\nExpected character ) not found.'
```

`check_model`ä¼šç”±äºè¿™ç§ä¸ä¸€è‡´è€Œå¼•å‘é”™è¯¯ã€‚ å¯¹äºä¸»åŸŸæˆ– ML åŸŸä¸­å®šä¹‰çš„æ‰€æœ‰è¿ç®—ç¬¦éƒ½æœ‰æ•ˆï¼Œè€Œå¯¹äºä»»ä½•è§„èŒƒä¸­æœªå®šä¹‰çš„è‡ªå®šä¹‰è¿ç®—ç¬¦ï¼Œåˆ™ä¿æŒæ²‰é»˜ã€‚

å½¢çŠ¶æ¨ç†çš„ç›®çš„åªæœ‰ä¸€ä¸ªï¼šä¼°è®¡ä¸­é—´ç»“æœçš„å½¢çŠ¶å’Œç±»å‹ã€‚ å¦‚æœçŸ¥é“ï¼Œè¿è¡Œæ—¶å°±å¯ä»¥äº‹å…ˆä¼°è®¡å†…å­˜æ¶ˆè€—ï¼Œä¼˜åŒ–è®¡ç®—ã€‚å®ƒå¯ä»¥èåˆæŸäº›è¿ç®—ç¬¦ï¼Œå¯ä»¥å°±åœ°è¿›è¡Œè®¡ç®—......

```
import onnx.parser
from onnx import helper, shape_inference

input = '''
    <
        ir_version: 8,
        opset_import: [ "" : 15]
    >
    agraph (float[I,4] X, float[4,2] A, float[4] B) => (float[I] Y) {
        XA = MatMul(X, A)
        Y = Add(XA, B)
    }
    '''
onnx_model = onnx.parser.parse_model(input)
inferred_model = shape_inference.infer_shapes(onnx_model)

print(inferred_model)
```

```
ir_version: 8
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
    domain: ""
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
    domain: ""
  }
  name: "agraph"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_param: "I"
          }
          dim {
            dim_value: 4
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_value: 4
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_param: "I"
          }
        }
      }
    }
  }
  value_info {
    name: "XA"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
            dim_param: "I"
          }
          dim {
            dim_value: 2
          }
        }
      }
    }
  }
}
opset_import {
  domain: ""
  version: 15
}
```

æœ‰ä¸€ä¸ªæ–°å±æ€§`value_info`ï¼Œç”¨äºå­˜å‚¨æ¨æ–­å‡ºçš„å½¢çŠ¶ã€‚`dim_param`ä¸­çš„å­—æ¯`I` `ï¼š "I "`å¯ä»¥çœ‹ä½œä¸€ä¸ªå˜é‡ã€‚è¿™å–å†³äºè¾“å…¥ï¼Œä½†å‡½æ•°èƒ½å¤Ÿåˆ¤æ–­å‡ºå“ªäº›ä¸­é—´ç»“æœå°†å…±äº«ç›¸åŒçš„ç»´åº¦ã€‚ å½¢çŠ¶æ¨ç†å¹¶éä¸€ç›´æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼Œé‡å¡‘æ“ä½œç¬¦ã€‚å½¢çŠ¶æ¨ç†åªæœ‰åœ¨å½¢çŠ¶æ’å®šçš„æƒ…å†µä¸‹æ‰ä¼šèµ·ä½œç”¨ã€‚ å¦‚æœå½¢çŠ¶ä¸æ’å®šï¼Œåˆ™æ— æ³•è½»æ¾æ¨ç†å‡ºå½¢çŠ¶ï¼Œé™¤éä¸‹é¢çš„èŠ‚ç‚¹æœŸæœ›å¾—åˆ°ç‰¹å®šçš„å½¢çŠ¶ã€‚

### è¯„ä¼°å’Œè¿è¡Œ[æ—¶é—´](broken-reference)\#

ONNX æ ‡å‡†å…è®¸æ¡†æ¶ä»¥ ONNX æ ¼å¼å¯¼å‡ºè®­ç»ƒæœ‰ç´ çš„æ¨¡å‹ï¼Œå¹¶å…è®¸ä½¿ç”¨ä»»ä½•æ”¯æŒ_ONNX_æ ¼å¼çš„åç«¯è¿›è¡Œæ¨ç†ã€‚å®ƒå¯ç”¨äºå¤šç§å¹³å°ï¼Œå¹¶é’ˆå¯¹å¿«é€Ÿæ¨ç†è¿›è¡Œäº†ä¼˜åŒ–ã€‚_onnx_å®ç°äº†ä¸€ä¸ª Python è¿è¡Œæ—¶ï¼Œæœ‰åŠ©äºç†è§£æ¨¡å‹ã€‚ å®ƒä¸æ‰“ç®—ç”¨äºç”Ÿäº§ï¼Œæ€§èƒ½ä¹Ÿä¸æ˜¯å®ƒçš„ç›®æ ‡ã€‚

#### çº¿æ€§[å›å½’](broken-reference)è¯„ä¼°\#

å®Œæ•´çš„ API æè¿°è¯·å‚è§[onnx.reference](https://onnx.ai/onnx/api/reference.html#l-reference-implementation)ã€‚ å®ƒæ¥æ”¶ä¸€ä¸ªæ¨¡å‹ï¼ˆä¸€ä¸ª_ModelProto_ã€ä¸€ä¸ªæ–‡ä»¶å......ï¼‰ã€‚ æ–¹æ³•`run`è¿”å›å­—å…¸ä¸­æŒ‡å®šçš„ä¸€ç»„è¾“å…¥çš„è¾“å‡ºã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info)
from onnx.checker import check_model
from onnx.reference import ReferenceEvaluator

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)

sess = ReferenceEvaluator(onnx_model)

x = numpy.random.randn(4, 2).astype(numpy.float32)
a = numpy.random.randn(2, 1).astype(numpy.float32)
b = numpy.random.randn(1, 1).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

print(sess.run(None, feeds))
```

```
[array([[-1.5184462 ],
       [-1.0666499 ],
       [-0.77610564],
       [-2.116381  ]], dtype=float32)]
```

#### [èŠ‚ç‚¹](broken-reference)è¯„ä¼°\#

è¯„ä¼°å™¨è¿˜å¯ä»¥è¯„ä¼°ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹ï¼Œä»¥æ£€æŸ¥è¿ç®—ç¬¦åœ¨ç‰¹å®šè¾“å…¥æ—¶çš„è¡¨ç°ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import make_node

from onnx.reference import ReferenceEvaluator

node = make_node('EyeLike', ['X'], ['Y'])

sess = ReferenceEvaluator(node)

x = numpy.random.randn(4, 2).astype(numpy.float32)
feeds = {'X': x}

print(sess.run(None, feeds))
```

```
[array([[1., 0.],
       [0., 1.],
       [0., 0.],
       [0., 0.]], dtype=float32)]
```

ç±»ä¼¼çš„ä»£ç ä¹Ÿé€‚ç”¨äº_GraphProto_æˆ–_FunctionProto_ã€‚

#### è¯„ä¼°æ­¥éª¤[#](broken-reference)

è½¬æ¢åº“é‡‡ç”¨ç”¨æœºå™¨å­¦ä¹ æ¡†æ¶_ï¼ˆpytorch_ã€_scikit-learn_......ï¼‰è®­ç»ƒçš„ç°æœ‰æ¨¡å‹ï¼Œå¹¶å°†æ¨¡å‹è½¬æ¢ä¸º ONNX å›¾å½¢ã€‚å¤æ‚çš„æ¨¡å‹é€šå¸¸æ— æ³•ä¸€è¹´è€Œå°±ï¼ŒæŸ¥çœ‹ä¸­é—´ç»“æœå¯èƒ½æœ‰åŠ©äºæ‰¾åˆ°è½¬æ¢é”™è¯¯çš„éƒ¨åˆ†ã€‚å‚æ•°`verbose`ä¼šæ˜¾ç¤ºä¸­é—´ç»“æœä¿¡æ¯ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info)
from onnx.checker import check_model
from onnx.reference import ReferenceEvaluator

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)

for verbose in [1, 2, 3, 4]:
    print()
    print(f"------ verbose={verbose}")
    print()
    sess = ReferenceEvaluator(onnx_model, verbose=verbose)

    x = numpy.random.randn(4, 2).astype(numpy.float32)
    a = numpy.random.randn(2, 1).astype(numpy.float32)
    b = numpy.random.randn(1, 1).astype(numpy.float32)
    feeds = {'X': x, 'A': a, 'B': b}

    print(sess.run(None, feeds))
```

```
------ verbose=1

[array([[-1.5585198 ],
       [ 0.8431341 ],
       [-3.8161776 ],
       [-0.97695297]], dtype=float32)]

------ verbose=2

MatMul(X, A) -> XA
Add(XA, B) -> Y
[array([[2.7036648],
       [2.1685638],
       [1.3111192],
       [2.7933102]], dtype=float32)]

------ verbose=3

 +I X: float32:(4, 2) in [-0.8107846975326538, 0.8805762529373169]
 +I A: float32:(2, 1) in [0.04560143128037453, 1.3560810089111328]
 +I B: float32:(1, 1) in [-0.5273541212081909, -0.5273541212081909]
MatMul(X, A) -> XA
 + XA: float32:(4, 1) in [-1.0593341588974, 0.13150419294834137]
Add(XA, B) -> Y
 + Y: float32:(4, 1) in [-1.5866882801055908, -0.39584994316101074]
[array([[-1.5866883 ],
       [-1.1906545 ],
       [-0.9883075 ],
       [-0.39584994]], dtype=float32)]

------ verbose=4

 +I X: float32:(4, 2):-0.5727394223213196,0.025708714500069618,0.4316417872905731,0.6972395181655884,-0.39831840991973877...
 +I A: float32:(2, 1):[0.8323841691017151, 0.20654942095279694]
 +I B: float32:(1, 1):[-0.4035758674144745]
MatMul(X, A) -> XA
 + XA: float32:(4, 1):[-0.47142910957336426, 0.5033062100410461, -0.1982671618461609, 0.4859170913696289]
Add(XA, B) -> Y
 + Y: float32:(4, 1):[-0.8750050067901611, 0.09973034262657166, -0.601842999458313, 0.08234122395515442]
[array([[-0.875005  ],
       [ 0.09973034],
       [-0.601843  ],
       [ 0.08234122]], dtype=float32)]
```

#### è¯„ä¼°è‡ªå®šä¹‰[èŠ‚ç‚¹](broken-reference)\#

ä¸‹é¢çš„ç¤ºä¾‹ä»ç„¶å®ç°äº†çº¿æ€§å›å½’ï¼Œä½†åœ¨_A_ ä¸­åŠ å…¥äº†èº«ä»½çŸ©é˜µï¼š .

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info)
from onnx.checker import check_model
from onnx.reference import ReferenceEvaluator

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node0 = make_node('EyeLike', ['A'], ['Eye'])
node1 = make_node('Add', ['A', 'Eye'], ['A1'])
node2 = make_node('MatMul', ['X', 'A1'], ['XA1'])
node3 = make_node('Add', ['XA1', 'B'], ['Y'])
graph = make_graph([node0, node1, node2, node3], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)
with open("linear_regression.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

sess = ReferenceEvaluator(onnx_model, verbose=2)

x = numpy.random.randn(4, 2).astype(numpy.float32)
a = numpy.random.randn(2, 2).astype(numpy.float32) / 10
b = numpy.random.randn(1, 2).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

print(sess.run(None, feeds))
```

```
EyeLike(A) -> Eye
Add(A, Eye) -> A1
MatMul(X, A1) -> XA1
Add(XA1, B) -> Y
[array([[ 3.249391  , -1.8001835 ],
       [ 1.4209515 ,  1.7799548 ],
       [-0.37126446, -0.15336311],
       [ 2.164718  ,  0.11840849]], dtype=float32)]
```

å¦‚æœå°†è¿ç®—ç¬¦_EyeLike_å’Œ_Add_åˆå¹¶ä¸º_AddEyeLike_ï¼Œæ•ˆç‡ä¼šæ›´é«˜ã€‚ä¸‹ä¸€ä¸ªç¤ºä¾‹å°†è¿™ä¸¤ä¸ªè¿ç®—ç¬¦æ›¿æ¢ä¸º`"ä¼˜åŒ– "`åŸŸä¸­çš„ä¸€ä¸ªè¿ç®—ç¬¦ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info, make_opsetid)
from onnx.checker import check_model

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

node01 = make_node('AddEyeLike', ['A'], ['A1'], domain='optimized')

node2 = make_node('MatMul', ['X', 'A1'], ['XA1'])
node3 = make_node('Add', ['XA1', 'B'], ['Y'])
graph = make_graph([node01, node2, node3], 'lr', [X, A, B], [Y])

onnx_model = make_model(graph, opset_imports=[
    make_opsetid('', 18), make_opsetid('optimized', 1)
])

check_model(onnx_model)
with open("linear_regression_improved.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())
```

æˆ‘ä»¬éœ€è¦è¯„ä¼°è¿™ä¸ªæ¨¡å‹æ˜¯å¦ç­‰åŒäºç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œè¿™å°±éœ€è¦å¯¹è¿™ä¸ªç‰¹å®šèŠ‚ç‚¹è¿›è¡Œå®ç°ã€‚

```
import numpy
from onnx.reference import ReferenceEvaluator
from onnx.reference.op_run import OpRun

class AddEyeLike(OpRun):

    op_domain = "optimized"

    def _run(self, X, alpha=1.):
        assert len(X.shape) == 2
        assert X.shape[0] == X.shape[1]
        X = X.copy()
        ind = numpy.diag_indices(X.shape[0])
        X[ind] += alpha
        return (X,)

sess = ReferenceEvaluator("linear_regression_improved.onnx", verbose=2, new_ops=[AddEyeLike])

x = numpy.random.randn(4, 2).astype(numpy.float32)
a = numpy.random.randn(2, 2).astype(numpy.float32) / 10
b = numpy.random.randn(1, 2).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

print(sess.run(None, feeds))

# Let's check with the previous model.

sess0 = ReferenceEvaluator("linear_regression.onnx",)
sess1 = ReferenceEvaluator("linear_regression_improved.onnx", new_ops=[AddEyeLike])

y0 = sess0.run(None, feeds)[0]
y1 = sess1.run(None, feeds)[0]
print(y0)
print(y1)
print(f"difference: {numpy.abs(y0 - y1).max()}")
```

```
AddEyeLike(A) -> A1
MatMul(X, A1) -> XA1
Add(XA1, B) -> Y
[array([[-0.37408   , -0.56797665],
       [-0.72363484,  1.0973046 ],
       [-1.616734  , -2.5929499 ],
       [-1.7821894 , -0.81231964]], dtype=float32)]
[[-0.37408    -0.56797665]
 [-0.72363484  1.0973046 ]
 [-1.616734   -2.5929499 ]
 [-1.7821894  -0.81231964]]
[[-0.37408    -0.56797665]
 [-0.72363484  1.0973046 ]
 [-1.616734   -2.5929499 ]
 [-1.7821894  -0.81231964]]
difference: 0.0
```

é¢„æµ‹ç»“æœæ˜¯ä¸€æ ·çš„ã€‚è®©æˆ‘ä»¬åœ¨ä¸€ä¸ªè¶³å¤Ÿå¤§çš„çŸ©é˜µä¸Šæ¯”è¾ƒä¸€ä¸‹æ€§èƒ½ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚ã€‚

```
import timeit
import numpy
from onnx.reference import ReferenceEvaluator
from onnx.reference.op_run import OpRun

class AddEyeLike(OpRun):

    op_domain = "optimized"

    def _run(self, X, alpha=1.):
        assert len(X.shape) == 2
        assert X.shape[0] == X.shape[1]
        X = X.copy()
        ind = numpy.diag_indices(X.shape[0])
        X[ind] += alpha
        return (X,)

sess = ReferenceEvaluator("linear_regression_improved.onnx", verbose=2, new_ops=[AddEyeLike])

x = numpy.random.randn(4, 100).astype(numpy.float32)
a = numpy.random.randn(100, 100).astype(numpy.float32) / 10
b = numpy.random.randn(1, 100).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

sess0 = ReferenceEvaluator("linear_regression.onnx")
sess1 = ReferenceEvaluator("linear_regression_improved.onnx", new_ops=[AddEyeLike])

y0 = sess0.run(None, feeds)[0]
y1 = sess1.run(None, feeds)[0]
print(f"difference: {numpy.abs(y0 - y1).max()}")
print(f"time with EyeLike+Add: {timeit.timeit(lambda: sess0.run(None, feeds), number=1000)}")
print(f"time with AddEyeLike: {timeit.timeit(lambda: sess1.run(None, feeds), number=1000)}")
```

```
difference: 0.0
time with EyeLike+Add: 0.07655519099995445
time with AddEyeLike: 0.06604622999998355
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¼¼ä¹å€¼å¾—æ·»åŠ ä¸€ä¸ªä¼˜åŒ–èŠ‚ç‚¹ã€‚ è¿™ç§ä¼˜åŒ–é€šå¸¸è¢«ç§°ä¸º_èåˆ_ã€‚ ä¸¤ä¸ªè¿ç»­çš„è¿ç®—ç¬¦è¢«èåˆä¸ºä¸¤ä¸ªè¿ç®—ç¬¦çš„ä¼˜åŒ–ç‰ˆæœ¬ã€‚ åˆ¶ä½œé€šå¸¸ä¾èµ–äº_onnxruntime_ï¼Œä½†ç”±äºä¼˜åŒ–ä½¿ç”¨çš„æ˜¯åŸºæœ¬çš„çŸ©é˜µè¿ç®—ï¼Œå› æ­¤åœ¨ä»»ä½•å…¶ä»–è¿è¡Œæ—¶éƒ½ä¼šå¸¦æ¥ç›¸åŒçš„æ€§èƒ½æå‡ã€‚

### å®æ–½[ç»†èŠ‚](broken-reference)\#

#### Python å’Œ[ C++#](broken-reference)

onnx ä¾é  protobuf æ¥å®šä¹‰å…¶ç±»å‹ï¼Œä½ ä¼šè®¤ä¸º python å¯¹è±¡åªæ˜¯å†…éƒ¨ç»“æ„ä¸Š C æŒ‡é’ˆçš„ä¸€ä¸ªå°è£…ã€‚å› æ­¤ï¼Œæ¥æ”¶`ModelProto` ç±»å‹ python å¯¹è±¡çš„å‡½æ•°åº”è¯¥å¯ä»¥è®¿é—®å†…éƒ¨æ•°æ®ã€‚ä½†äº‹å®å¹¶éå¦‚æ­¤ã€‚æ ¹æ®[Protobuf 4 çš„ä¿®æ”¹](https://developers.google.com/protocol-buffers/docs/news/2022-05-06)ï¼Œè¿™åœ¨ç¬¬ 4 ç‰ˆä¹‹åå°±ä¸å†å¯èƒ½äº†ï¼Œå› æ­¤æ›´å®‰å…¨çš„åšæ³•æ˜¯å°†æ¨¡å‹åºåˆ—åŒ–ä¸ºå­—èŠ‚ï¼Œç„¶åå°†å…¶äº¤ç»™ C å‡½æ•°ï¼Œç„¶åå†ååºåˆ—åŒ–ã€‚ åƒ`check_model`æˆ–`shape_inference`è¿™æ ·çš„å‡½æ•°éƒ½æ˜¯å…ˆè°ƒç”¨`SerializeToString`ç„¶å`ParseFromString`ï¼Œç„¶åå†ç”¨ C ä»£ç æ£€æŸ¥æ¨¡å‹ã€‚

#### å±æ€§å’Œ[è¾“å…¥](broken-reference)\#

ä¸¤è€…ä¹‹é—´æœ‰æ˜æ˜¾çš„åŒºåˆ«ã€‚è¾“å…¥æ˜¯åŠ¨æ€çš„ï¼Œæ¯æ¬¡æ‰§è¡Œéƒ½å¯èƒ½å‘ç”Ÿå˜åŒ–ã€‚å±æ€§æ°¸è¿œä¸ä¼šæ”¹å˜ï¼Œä¼˜åŒ–å™¨å¯ä»¥æ”¹è¿›æ‰§è¡Œå›¾ï¼Œå‡è®¾å®ƒæ°¸è¿œä¸ä¼šæ”¹å˜ã€‚ å› æ­¤ï¼Œä¸å¯èƒ½å°†è¾“å…¥è½¬åŒ–ä¸ºå±æ€§ã€‚ è€Œè¿ç®—ç¬¦_Constant_æ˜¯å”¯ä¸€èƒ½å°†å±æ€§è½¬åŒ–ä¸ºè¾“å…¥çš„è¿ç®—ç¬¦ã€‚

#### å½¢çŠ¶æˆ–æ— [å½¢çŠ¶](broken-reference)\#

å¦‚æœæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªç»´åº¦åˆ›å»ºä¸€ä¸ªæœ‰æ•ˆçš„å›¾å½¢å‘¢ï¼Ÿ è¿™ç§æƒ…å†µä»ç„¶ä»¤äººè´¹è§£ã€‚

```
import numpy
from onnx import numpy_helper, TensorProto, FunctionProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info, make_opsetid,
    make_function)
from onnx.checker import check_model
from onnxruntime import InferenceSession

def create_model(shapes):
    new_domain = 'custom'
    opset_imports = [make_opsetid("", 14), make_opsetid(new_domain, 1)]

    node1 = make_node('MatMul', ['X', 'A'], ['XA'])
    node2 = make_node('Add', ['XA', 'A'], ['Y'])

    X = make_tensor_value_info('X', TensorProto.FLOAT, shapes['X'])
    A = make_tensor_value_info('A', TensorProto.FLOAT, shapes['A'])
    Y = make_tensor_value_info('Y', TensorProto.FLOAT, shapes['Y'])

    graph = make_graph([node1, node2], 'example', [X, A], [Y])

    onnx_model = make_model(graph, opset_imports=opset_imports)
    # Let models runnable by onnxruntime with a released ir_version
    onnx_model.ir_version = 8

    return onnx_model

print("----------- case 1: 2D x 2D -> 2D")
onnx_model = create_model({'X': [None, None], 'A': [None, None], 'Y': [None, None]})
check_model(onnx_model)
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])
res = sess.run(None, {
    'X': numpy.random.randn(2, 2).astype(numpy.float32),
    'A': numpy.random.randn(2, 2).astype(numpy.float32)})
print(res)

print("----------- case 2: 2D x 1D -> 1D")
onnx_model = create_model({'X': [None, None], 'A': [None], 'Y': [None]})
check_model(onnx_model)
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])
res = sess.run(None, {
    'X': numpy.random.randn(2, 2).astype(numpy.float32),
    'A': numpy.random.randn(2).astype(numpy.float32)})
print(res)

print("----------- case 3: 2D x 0D -> 0D")
onnx_model = create_model({'X': [None, None], 'A': [], 'Y': []})
check_model(onnx_model)
try:
    InferenceSession(onnx_model.SerializeToString(),
                     providers=["CPUExecutionProvider"])
except Exception as e:
    print(e)

print("----------- case 4: 2D x None -> None")
onnx_model = create_model({'X': [None, None], 'A': None, 'Y': None})
try:
    check_model(onnx_model)
except Exception as e:
    print(type(e), e)
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])
res = sess.run(None, {
    'X': numpy.random.randn(2, 2).astype(numpy.float32),
    'A': numpy.random.randn(2).astype(numpy.float32)})
print(res)
print("----------- end")
```

```
----------- case 1: 2D x 2D -> 2D
[array([[ 0.45804122,  0.4898213 ],
       [ 0.0373224 , -0.00160027]], dtype=float32)]
----------- case 2: 2D x 1D -> 1D
[array([-0.3142326 , -0.05584523], dtype=float32)]
----------- case 3: 2D x 0D -> 0D
[ONNXRuntimeError] : 1 : FAIL : Node () Op (MatMul) [ShapeInferenceError] Input tensors of wrong rank (0).
----------- case 4: 2D x None -> None
<class 'onnx.onnx_cpp2py_export.checker.ValidationError'> Field 'shape' of 'type' is required but missing.
[array([3.5581195, 1.8482882], dtype=float32)]
----------- end
```
