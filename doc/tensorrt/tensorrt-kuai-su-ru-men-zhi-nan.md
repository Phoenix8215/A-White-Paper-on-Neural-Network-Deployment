# ğŸ± TensorRTå¿«é€Ÿå…¥é—¨æŒ‡å—

### TensorRT ç”Ÿæ€ç³»ç»Ÿ

TensorRT æ˜¯ä¸€ä¸ªåºå¤§è€Œçµæ´»çš„é¡¹ç›®ã€‚å®ƒå¯ä»¥å¤„ç†å„ç§è½¬æ¢å’Œéƒ¨ç½²å·¥ä½œæµç¨‹ï¼Œå“ªç§å·¥ä½œæµç¨‹æœ€åˆé€‚å–å†³äºå…·ä½“ç”¨ä¾‹å’Œé—®é¢˜è®¾ç½®ã€‚

#### TensorRT åŸºæœ¬å·¥ä½œæµç¨‹

<figure><img src="../../.gitbook/assets/å›¾ç‰‡.png" alt=""><figcaption></figcaption></figure>

#### è½¬æ¢å’Œéƒ¨ç½²é€‰é¡¹

TensorRT ç”Ÿæ€ç³»ç»Ÿåˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š

1. ç”¨æˆ·å¯é€šè¿‡å„ç§é€”å¾„å°†å…¶æ¨¡å‹è½¬æ¢ä¸ºå·²ç»ä¼˜åŒ–å¥½çš„ TensorRT å¼•æ“ã€‚
2. ç”¨æˆ·åœ¨éƒ¨ç½²å·²ç»ä¼˜åŒ–åçš„ TensorRT å¼•æ“æ—¶ï¼Œå¯å°† TensorRT ä½œä¸ºæ¨ç† runtimeã€‚

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (1).png" alt=""><figcaption></figcaption></figure>

ä½¿ç”¨ TensorRT è½¬æ¢æ¨¡å‹æœ‰ä¸‰ä¸ªä¸»è¦é€‰é¡¹ï¼š

* ä½¿ç”¨ TF-TRT
* è‡ªåŠ¨ä»ONNXæ–‡ä»¶ä¸­å®Œæˆè½¬æ¢
* ä½¿ç”¨ TensorRT APIï¼ˆC++ æˆ– Python è¯­è¨€ï¼‰æ‰‹åŠ¨æ„å»ºç½‘ç»œ

å¯¹äº TensorFlow æ¨¡å‹çš„è½¬æ¢ï¼ŒTensorFlow é›†æˆï¼ˆTF-TRTï¼‰æä¾›äº†æ¨¡å‹è½¬æ¢å’Œé«˜çº§runtime APIï¼Œå¹¶èƒ½åœ¨ TensorRT ä¸æ”¯æŒç‰¹å®šç®—å­æ—¶è¿”å›åˆ° TensorFlow ä¸­å»å®ç°è¿è¡Œã€‚

ä½¿ç”¨ ONNX è¿›è¡Œè½¬æ¢æ˜¯ä¸€ç§æ€§èƒ½æ›´é«˜çš„æ¨¡å‹éƒ¨ç½²æ–¹å¼ã€‚TensorRT æ”¯æŒä½¿ç”¨ TensorRT API æˆ–trtexecä» ONNX æ–‡ä»¶ä¸­è¿›è¡Œè‡ªåŠ¨è½¬æ¢ã€‚ä½¿ç”¨ONNX è½¬æ¢æ„å‘³ç€æ¨¡å‹ä¸­çš„æ‰€æœ‰æ“ä½œéƒ½å¿…é¡»æœ‰ TensorRT çš„æ”¯å®ç°ï¼ˆæˆ–è€…å¿…é¡»ä¸ºä¸æ”¯æŒçš„æ“ä½œæä¾›è‡ªå®šä¹‰æ’ä»¶ï¼‰ã€‚ONNX è½¬æ¢çš„ç»“æœæ˜¯ä¸€ä¸ªå•ä¸€çš„ TensorRT å¼•æ“ï¼Œæ¯”ä½¿ç”¨ TF-TRT çš„å¼€é”€æ›´å°‘ã€‚

ä¸ºäº†å°½å¯èƒ½æé«˜æ€§èƒ½å’Œå¯å®šåˆ¶æ€§ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ TensorRT ç½‘ç»œå®šä¹‰ API æ‰‹åŠ¨æ„å»º TensorRT å¼•æ“ã€‚ç”¨ TensorRT åˆ›å»ºç½‘ç»œï¼Œåªéœ€å¯¼å‡ºæ¨¡å‹çš„æƒé‡ï¼Œç„¶åå°†æƒé‡åŠ è½½åˆ°ç½‘ç»œä¸­å³å¯ã€‚

* [ä½¿ç”¨ C++ API ä»é›¶å¼€å§‹åˆ›å»ºç½‘ç»œå®šä¹‰](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#create\_network\_c)
* [ä½¿ç”¨ Python API ä»é›¶å¼€å§‹åˆ›å»ºç½‘ç»œå®šä¹‰](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/#create\_network\_python)

#### éƒ¨ç½²

ä½¿ç”¨ TensorRT éƒ¨ç½²æ¨¡å‹æœ‰ä¸‰ç§é€‰æ‹©ï¼š

* åœ¨ TensorFlow ä¸­éƒ¨ç½²
* ä½¿ç”¨ç‹¬ç«‹çš„ TensorRT runtime API
* ä½¿ç”¨è‹±ä¼Ÿè¾¾ Triton æ¨ç†æœåŠ¡å™¨

TF-TRT è½¬æ¢æ¨¡å‹çš„ç»“æœæ˜¯ä¸€ä¸ªæ’å…¥äº† TensorRT æ“ä½œçš„ TensorFlow å›¾ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥åƒä½¿ç”¨å…¶ä»– TensorFlow æ¨¡å‹ä¸€æ ·ä½¿ç”¨ Python æ¥è¿è¡Œ TF-TRT æ¨¡å‹ã€‚

TensorRT runtime  API å¯ä»¥å®ç°æœ€ä½çš„å¼€é”€å’Œæœ€ç²¾ç»†çš„æ§åˆ¶ï¼Œä½† TensorRT æœ¬èº«ä¸æ”¯æŒçš„ç®—å­å¿…é¡»ä»¥æ’ä»¶å½¢å¼å®ç°ï¼ˆ[æ­¤å¤„](https://github.com/NVIDIA/TensorRT/tree/main/plugin)æä¾›äº†ä¸€ä¸ªé¢„ç¼–å†™æ’ä»¶åº“ï¼‰ã€‚

æœ€åï¼Œè‹±ä¼Ÿè¾¾â„¢ Tritonæ¨ç†æœåŠ¡å™¨æ˜¯ä¸€æ¬¾å¼€æºæ¨ç†æœåŠ¡è½¯ä»¶ï¼Œå¯å¸®åŠ©å›¢é˜Ÿåœ¨ä»»ä½•åŸºäºGPUæˆ–CPUçš„åŸºç¡€è®¾æ–½ï¼ˆäº‘ã€æ•°æ®ä¸­å¿ƒæˆ–è¾¹ç¼˜ï¼‰ä¸Šéƒ¨ç½²æ¥è‡ªä»»ä½•æ¡†æ¶ï¼ˆTensorFlowã€TensorRTã€PyTorchã€ONNX Runtimeæˆ–è‡ªå®šä¹‰æ¡†æ¶ï¼‰ã€æœ¬åœ°å­˜å‚¨æˆ–è°·æ­Œäº‘å¹³å°æˆ–AWS S3çš„äººå·¥æ™ºèƒ½æ¨¡å‹ã€‚å®ƒæ˜¯ä¸€ä¸ªçµæ´»çš„é¡¹ç›®ï¼Œå…·æœ‰ä¸€äº›ç‹¬ç‰¹çš„åŠŸèƒ½ï¼Œä¾‹å¦‚å¼‚æ„æ¨¡å‹å’ŒåŒä¸€æ¨¡å‹å¤šä¸ªå‰¯æœ¬çš„å¹¶å‘æ‰§è¡Œï¼ˆå¤šä¸ªæ¨¡å‹å‰¯æœ¬å¯è¿›ä¸€æ­¥å‡å°‘å»¶è¿Ÿï¼‰ä»¥åŠè´Ÿè½½å¹³è¡¡å’Œæ¨¡å‹åˆ†æã€‚ å¦‚æœå¿…é¡»é€šè¿‡ HTTP åè®®æä¾›æ¨¡å‹ï¼Œä¾‹å¦‚åœ¨äº‘æ¨ç†è§£å†³æ–¹æ¡ˆä¸­ï¼Œå®ƒæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚å¯ä»¥[åœ¨è¿™é‡Œ](https://developer.nvidia.com/nvidia-triton-inference-server)æ‰¾åˆ°è‹±ä¼Ÿè¾¾â„¢ Triton æ¨ç†æœåŠ¡å™¨ä¸»é¡µï¼Œ[åœ¨è¿™é‡Œæ‰¾åˆ°](https://github.com/triton-inference-server/server/blob/r22.01/README.md#documentation)ç›¸å…³æ–‡æ¡£ã€‚

#### é€‰æ‹©æ­£ç¡®çš„å·¥ä½œæµç¨‹

åœ¨é€‰æ‹©å¦‚ä½•è½¬æ¢å’Œéƒ¨ç½²æ¨¡å‹æ—¶ï¼Œæœ‰ä¸¤ä¸ªæœ€é‡è¦çš„å› ç´ ï¼š

1. æ¨¡å‹æ‰€é€‰ç”¨çš„æ¡†æ¶ã€‚
2. TensorRT runtimeã€‚

ä¸‹é¢çš„æµç¨‹å›¾æ¶µç›–äº†æœ¬æŒ‡å—ä¸­æ¶‰åŠçš„ä¸åŒå·¥ä½œæµç¨‹ã€‚è¯¥æµç¨‹å›¾å°†å¸®åŠ©æ‚¨æ ¹æ®è¿™ä¸¤ä¸ªå› ç´ é€‰æ‹©åˆé€‚çš„è·¯å¾„ã€‚

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (2).png" alt=""><figcaption></figcaption></figure>

### ä½¿ç”¨ ONNX çš„éƒ¨ç½²ç¤ºä¾‹

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥éƒ¨ç½²é¢„è®­ç»ƒçš„ ONNX æ¨¡å‹ä¸ºèƒŒæ™¯ï¼Œä»‹ç» TensorRT è½¬æ¢çš„äº”ä¸ªåŸºæœ¬æ­¥éª¤ã€‚

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ONNX æ ¼å¼è½¬æ¢ä¸€ä¸ªé¢„è®­ç»ƒçš„ ResNet-50 æ¨¡å‹ï¼›ONNX æ˜¯ä¸€ç§ä¸æ¡†æ¶æ— å…³çš„æ¨¡å‹æ ¼å¼ï¼Œå¯ä»å¤§å¤šæ•°ä¸»æµæ¡†æ¶ï¼ˆåŒ…æ‹¬ TensorFlow å’Œ PyTorchï¼‰å¯¼å‡ºã€‚æœ‰å…³ ONNX æ ¼å¼çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·[ç‚¹å‡»æ­¤å¤„](https://github.com/onnx/onnx/blob/main/docs/IR.md)ã€‚

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (5).png" alt=""><figcaption></figcaption></figure>

#### å¯¼å‡ºæ¨¡å‹

TensorRT æ ¹æ®æ–‡ä»¶ç±»å‹ä¸åŒæä¾›äº†ä¸¤ç§ä¸åŒçš„æ–‡ä»¶è½¬æ¢æ–¹å¼ï¼š

* TF-TRT ä½¿ç”¨ TensorFlow ä¿å­˜å¥½çš„æ¨¡å‹æ–‡ä»¶ã€‚
* ONNXparser è¦æ±‚æ¨¡å‹ä¿å­˜åœ¨ ONNX ä¸­ã€‚

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ ONNX æ¨¡å‹æ–‡ä»¶ã€‚

ä½¿ç”¨wgetä» [ONNX model zoo](https://github.com/onnx/models) ä¸‹è½½é¢„è®­ç»ƒçš„ ResNet-50 æ¨¡å‹å¹¶è§£å‹ç¼©

<pre class="language-sh"><code class="lang-sh"><strong>wget https://download.onnxruntime.ai/onnx/models/resnet50.tar.gz 
</strong>tar xzf resnet50.tar.gz
</code></pre>

è¿™å°†è§£å‹ç¼©ä¸€ä¸ªé¢„è®­ç»ƒçš„ ResNet-50.onnxæ–‡ä»¶åˆ°resnet50/model.onnx è·¯å¾„ä¸‹ã€‚

#### batchsizeçš„é€‰æ‹©

batchsizeä¼šå¯¹æ¨¡å‹çš„ä¼˜åŒ–å°†äº§ç”Ÿå¾ˆå¤§å½±å“ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œåœ¨æ¨ç†æ—¶ï¼Œå½“æˆ‘ä»¬æƒ³ä¼˜å…ˆè€ƒè™‘å»¶è¿Ÿæ—¶ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©è¾ƒå°çš„batchsizeï¼Œè€Œå½“æˆ‘ä»¬æƒ³ä¼˜å…ˆè€ƒè™‘ååé‡æ—¶ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©è¾ƒå¤§çš„batchsizeã€‚è¾ƒå¤§çš„batchsizeéœ€è¦æ›´é•¿çš„å¤„ç†æ—¶é—´ï¼Œä½†å¯ä»¥å‡å°‘æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å¤„ç†æ—¶é—´ã€‚

å¦‚æœåœ¨è¿è¡Œå‰ä¸çŸ¥é“éœ€è¦å¤šå¤§çš„batchsizeï¼ŒTensorRT å¯ä»¥åŠ¨æ€å¤„ç†batchsizeå¤§å°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå›ºå®šçš„batchsizeä¼šè®© TensorRT è¿›è¡Œé¢å¤–çš„ä¼˜åŒ–(a fixed batch size allows TensorRT to make additional optimizations.)ã€‚åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„å›ºå®šbatchsizeä¸º 64ã€‚

```
BATCH_SIZE=64
```

#### ç²¾åº¦çš„é€‰æ‹©

æ¨ç†æ‰€éœ€çš„æ•°å­—ç²¾åº¦é€šå¸¸ä½äºè®­ç»ƒæ‰€éœ€çš„ç²¾åº¦ã€‚è¾ƒä½çš„ç²¾åº¦å¯ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œé™ä½å†…å­˜æ¶ˆè€—ï¼Œè€Œä¸ä¼šç‰ºç‰²ä»»ä½•ç²¾åº¦ã€‚TensorRT æ”¯æŒ TF32ã€FP32ã€FP16 å’Œ INT8 ç²¾åº¦ã€‚FP32 æ˜¯å¤§å¤šæ•°æ¡†æ¶çš„é»˜è®¤è®­ç»ƒç²¾åº¦ï¼Œå› æ­¤æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨ FP32 è¿›è¡Œæ¨ç†

```
import numpy as np
PRECISION = np.float32
```

æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­è®¾ç½® TensorRT å¼•æ“åœ¨è¿è¡Œæ—¶æ‰€ä½¿ç”¨çš„ç²¾åº¦ã€‚

#### è½¬æ¢æ¨¡å‹

ONNX è½¬æ¢ä¸º TensorRT å¼•æ“æ˜¯æœ€é€šç”¨ã€æ€§èƒ½æœ€å¥½çš„æ–¹å¼ä¹‹ä¸€ã€‚å®ƒé€‚ç”¨äº TensorFlowã€PyTorch å’Œè®¸å¤šå…¶ä»–æ¡†æ¶ã€‚

æœ‰å‡ ç§å·¥å…·å¯ä»¥å¸®åŠ©ä½ å°† ONNX æ¨¡å‹è½¬æ¢ä¸º TensorRT å¼•æ“ã€‚ä¸€ç§å¸¸è§çš„æ–¹æ³•æ˜¯ä½¿ç”¨trtexecï¼Œå®ƒæ˜¯ TensorRT é™„å¸¦çš„ä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œå¯ä»¥å°† ONNX æ¨¡å‹è½¬æ¢ä¸º TensorRT å¼•æ“å¹¶å¯¹å…¶è¿›è¡Œå‰–æã€‚

æˆ‘ä»¬å¯ä»¥æŒ‰ä»¥ä¸‹æ–¹å¼è¿è¡Œè½¬æ¢

```
trtexec --onnx=resnet50/model.onnx --saveEngine=resnet_engine.trt
```

è¿™å°†æŠŠresnet50/model.onnxè½¬æ¢ä¸ºåä¸ºresnet\_engine.trt çš„ TensorRT å¼•æ“ã€‚æ³¨æ„ï¼š

*   è¦å‘Šè¯‰trtexecåœ¨å“ªé‡Œæ‰¾åˆ°æˆ‘ä»¬çš„ ONNX æ¨¡å‹

    ```
    --onnx=resnet50/model.onnx
    ```
*   è¦å‘Šè¯‰trtexecä¿å­˜ä¼˜åŒ–åçš„ TensorRT å¼•æ“çš„ä½ç½®

    ```
    --saveEngine=resnet_engine_intro.trt
    ```

#### éƒ¨ç½²æ¨¡å‹

æˆåŠŸåˆ›å»º TensorRT å¼•æ“åï¼Œæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ TensorRT è¿è¡Œå®ƒã€‚

TensorRT runtimeæœ‰ä¸¤ç§ç±»å‹ï¼šä¸€ç§æ˜¯ä¸ C++ å’Œ Python ç»‘å®šçš„ç‹¬ç«‹runtimeï¼Œå¦ä¸€ç§ä¸ TensorFlow é›†æˆçš„ APIã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä¸€æ‰¹éšæœºçš„ "å‡ "æ•°æ®ï¼Œå¹¶ä½¿ç”¨ONNXClassifierWrapperè¿™ä¸ªç±»åœ¨è¯¥æ‰¹æ•°æ®ä¸Šè¿è¡Œæ¨ç†ã€‚

1.  è®¾ç½®ONNXClassifierWrapper

    ```python
    from onnx_helper import ONNXClassifierWrapper 
    N_CLASSES = 1000 # Our ResNet-50 is trained on a 1000 class ImageNet task
    trt_model = ONNXClassifierWrapper("resnet_engine.trt", [BATCH_SIZE, N_CLASSES], target_dtype = PRECISION)
    ```
2.  è®¾ç½®æ¨¡å‹çš„è¾“å…¥

    ```
    BATCH_SIZE=32 
    dummy_input_batch = np.zeros((BATCH_SIZE, 224, 224, 3), dtype = PRECISION)
    ```
3.  å‘å¼•æ“è¾“å…¥ä¸€æ‰¹æ•°æ®ï¼Œç„¶åå¾—åˆ°é¢„æµ‹ç»“æœã€‚

    ```
    predictions = trt_model.predict(dummy_input_batch)
    ```

è¯·æ³¨æ„ï¼Œåœ¨è¿è¡Œç¬¬ä¸€ä¸ªbatchä¹‹å‰ï¼ŒONNXClassifierWrapperä¸ä¼šåŠ è½½å’Œåˆå§‹åŒ–å¼•æ“ï¼Œå› æ­¤è¯¥batchå¤„ç†é€šå¸¸éœ€è¦æ¯”è¾ƒé•¿çš„ä¸€æ®µæ—¶é—´ã€‚

### ä½¿ç”¨ TensorRT runtime API

åœ¨æ¨¡å‹è½¬æ¢å’Œéƒ¨ç½²æ–¹é¢ï¼Œä½¿ç”¨ TensorRT runtime APIæ˜¯æ€§èƒ½æœ€å¥½ã€æœ€å¯å®šåˆ¶çš„é€‰æ‹©ä¹‹ä¸€ï¼Œè¯¥ç¨‹åºæ¥å£æœ‰ C++ å’Œ Python ç‰ˆæœ¬ã€‚

TensorRT åŒ…å«ä¸€ä¸ªå¸¦æœ‰ C++ å’Œ Python ç»‘å®šçš„ç‹¬ç«‹è¿è¡Œæ—¶ï¼Œä¸ä½¿ç”¨ TF-TRT é›†æˆç›¸æ¯”ï¼Œå…¶æ€§èƒ½å’Œå¯å®šåˆ¶æ€§é€šå¸¸æ›´é«˜ã€‚C++ API çš„å¼€é”€è¾ƒä½ï¼Œä½† Python API ä¸ Python æ•°æ®åŠ è½½å™¨ä»¥åŠ NumPy å’Œ SciPy ç­‰åº“é…åˆè‰¯å¥½ï¼Œæ›´æ˜“äºç”¨äºåŸå‹è®¾è®¡ã€è°ƒè¯•å’Œæµ‹è¯•ã€‚

ä¸‹é¢çš„æ•™ç¨‹è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨ TensorRT C++ å’Œ Python API å¯¹å›¾åƒè¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€‚è¯¥ä»»åŠ¡ä½¿ç”¨äº†ä¸€ä¸ªä»¥ ResNet-101 ä¸ºéª¨å¹²çš„å…¨å·ç§¯æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¯æ¥å—ä»»æ„å¤§å°çš„å›¾åƒï¼Œå¹¶ä¸ºæ¯ä¸ªåƒç´ ç”Ÿæˆç›¸åº”çš„é¢„æµ‹ç»“æœã€‚

æœ¬æ•™ç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š

1. å¯¼å‡ºONNXæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨trtexecç”ŸæˆTensorRTå¼•æ“
2. ä½¿ç”¨TensorRT C++ APIè¿›è¡Œè¿è¡Œæ—¶çš„æ¨ç†
3. ä½¿ç”¨TensorRT Python APIè¿›è¡Œè¿è¡Œæ—¶çš„æ¨ç†

#### å¯¼å‡ºONNXæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨trtexecç”ŸæˆTensorRTå¼•æ“

1.  ä»[TensorRT å¼€æºè½¯ä»¶ä»“åº“](http://github.com/NVIDIA/TensorRT)ä¸‹è½½å¿«é€Ÿå…¥é—¨æ•™ç¨‹çš„æºä»£ç ã€‚

    ```sh
    git clone https://github.com/NVIDIA/TensorRT.git 
    cd TensorRT/quickstart
    ```
2. å°†[é¢„å…ˆè®­ç»ƒå¥½çš„ FCN-ResNet-101](https://pytorch.org/hub/pytorch\_vision\_fcn\_resnet101/)æ¨¡å‹è½¬æ¢ä¸º ONNXã€‚ä»¥ä¸‹æ˜¯ç›¸å…³çš„æµ‹è¯•å›¾ç‰‡

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (9).png" alt=""><figcaption></figcaption></figure>

a. å¯åŠ¨å®¹å™¨ã€‚

```bash
$ docker run --rm -it -gpus all -p 8888:8888 -v `pwd`:/workspace -w /workspace/SemanticSegmentation nvcr.io/nvidia/pytorch:20.12-py3 bash
```

b.è¿è¡Œå¯¼å‡ºè„šæœ¬ï¼Œå°†é¢„è®­ç»ƒæ¨¡å‹è½¬æ¢ä¸º ONNXã€‚

```bash
$ python export.py
```

{% hint style="info" %}
æ³¨ï¼šFCN-ResNet-101 æœ‰ä¸€ä¸ªç»´åº¦ä¸º\[batch, 3, height, width]çš„è¾“å…¥å’Œä¸€ä¸ªç»´åº¦ä¸º\[batch, 21, height, weight]çš„è¾“å‡ºï¼Œå…¶ä¸­åŒ…å«å¯¹åº”äº 21 ä¸ªç±»åˆ«æ ‡ç­¾é¢„æµ‹çš„æ¦‚ç‡å€¼ã€‚åœ¨å°†æ¨¡å‹å¯¼å‡ºåˆ° ONNX æ—¶ï¼Œæˆ‘ä»¬åœ¨è¾“å‡ºç«¯é™„åŠ äº†ä¸€ä¸ªargmaxå±‚ï¼Œä»¥ç”Ÿæˆæ¯ä¸ªåƒç´ æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«æ ‡ç­¾ã€‚
{% endhint %}

{% code title="export.py" %}
```python
import torch
import torch.nn as nn

output_onnx="fcn-resnet101.onnx"

# FC-ResNet101 pretrained model from torch-hub extended with argmax layer
class FCN_ResNet101(nn.Module):
    def __init__(self):
        super(FCN_ResNet101, self).__init__()
        self.model = torch.hub.load('pytorch/vision:v0.6.0', 'fcn_resnet101', pretrained=True)

    def forward(self, inputs):
        x = self.model(inputs)['out']
        x = x.argmax(1, keepdims=True)
        return x

model = FCN_ResNet101()
model.eval()

# Generate input tensor with random values
input_tensor = torch.rand(4, 3, 224, 224)

# Export torch model to ONNX
print("Exporting ONNX model {}".format(output_onnx))
torch.onnx.export(model, input_tensor, output_onnx,
    opset_version=12,
    do_constant_folding=True,
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch", 2: "height", 3: "width"},
                  "output": {0: "batch", 2: "height", 3: "width"}},
    verbose=True)
```
{% endcode %}

3. ä½¿ç”¨[trtexec](https://github.com/NVIDIA/TensorRT/tree/main/samples/trtexec)å·¥å…·ä» ONNX æ„å»º TensorRT å¼•æ“ã€‚

trtexecå¯ä»¥ä» ONNX æ¨¡å‹ç”Ÿæˆ TensorRT å¼•æ“ï¼Œç„¶åä½¿ç”¨ TensorRT è¿è¡Œæ—¶ API è¿›è¡Œéƒ¨ç½²ã€‚å®ƒåˆ©ç”¨[TensorRT ONNX è§£æå™¨](https://github.com/onnx/onnx-tensorrt)å°† ONNX æ¨¡å‹åŠ è½½åˆ° TensorRT ç½‘ç»œå›¾ä¸­ï¼Œå¹¶åˆ©ç”¨ TensorRT ç”Ÿæˆå™¨[API](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#build\_engine\_c)(Builder API)ç”Ÿæˆä¼˜åŒ–å¼•æ“ã€‚æ„å»ºå¼•æ“éå¸¸è€—æ—¶ï¼Œé€šå¸¸éœ€è¦ç¦»çº¿è¿è¡Œã€‚

```bash
trtexec --onnx=fcn-resnet101.onnx --fp16 --workspace=64 --minShapes=input:1x3x256x256 --optShapes=input:1x3x1026x1282 --maxShapes=input:1x3x1440x2560 --buildOnly --saveEngine=fcn-resnet101.engine
```

æ‰§è¡ŒæˆåŠŸåç”Ÿæˆä¸€ä¸ªå¼•æ“æ–‡ä»¶ã€‚

{% hint style="info" %}
â€“buildOnly ï¼š è·³è¿‡æ¨ç†æ€§èƒ½æµ‹é‡ï¼ˆé»˜è®¤æ˜¯ç¦ç”¨ï¼‰
{% endhint %}

4. å¯é€‰æ‹©ä½¿ç”¨trtexec ç”Ÿæˆéšæœºå€¼éªŒè¯ç”Ÿæˆçš„å¼•æ“ã€‚

```bash
trtexec --shapes=input:1x3x1026x1282 --loadEngine=fcn-resnet101.engine
```

å…¶ä¸­ï¼Œ--shapesä¸ºç”¨äºæ¨ç†çš„åŠ¨æ€å½¢çŠ¶è¾“å…¥è®¾ç½®è¾“å…¥å¤§å°ã€‚

å¦‚æœæˆåŠŸï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼ä¸‹é¢çš„å†…å®¹

```bash
&&&& PASSED TensorRT.trtexec # trtexec --shapes=input:1x3x1026x1282 --loadEngine=fcn-resnet101.engine
```

#### ç”¨ C++ è¿è¡Œå¼•æ“

1.  åœ¨å®¹å™¨ä¸­ç¼–è¯‘å¹¶è¿è¡Œ

    ```bash
    $ make
    $ ./bin/segmentation_tutorial
    ```

ä»¥ä¸‹æ­¥éª¤å±•ç¤ºäº†å¦‚ä½•è¿›è¡Œ[ååºåˆ—åŒ–](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#perform\_inference\_c)(Plan)ç„¶åæ¨ç†ã€‚

1.  ä»æ–‡ä»¶ååºåˆ—åŒ– TensorRT å¼•æ“ã€‚æ–‡ä»¶å†…å®¹è¢«è¯»å…¥ç¼“å†²åŒºï¼Œå¹¶åœ¨å†…å­˜ä¸­è¿›è¡Œååºåˆ—åŒ–ã€‚

    ```cpp
    std::vector<char> engineData(fsize); 
    engineFile.read(engineData.data(), fsize); 
    std::unique_ptr<nvinfer1::IRuntime> runtime{nvinfer1::createInferRuntime(sample::gLogger.getTRTLogger())}; 
    std::unique_ptr<nvinfer1::ICudaEngine> mEngine(runtime->deserializeCudaEngine(engineData.data(), fsize, nullptr));
    ```
2.  TensorRT æ‰§è¡Œä¸Šä¸‹æ–‡åŒ…å«äº†ä¸€äº›æ‰§è¡ŒçŠ¶æ€(ä¾‹å¦‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ‰€éœ€è¦çš„æ¿€æ´»å±‚çš„å¼ é‡å€¼),ç”±äºå»ºç«‹åˆ†å‰²æ¨¡å‹æ—¶å¯ç”¨äº†åŠ¨æ€batchsizeï¼Œå› æ­¤å¿…é¡»æŒ‡å®šè¾“å…¥çš„ç»´åº¦æ‰èƒ½æ‰§è¡Œæ¨ç†ã€‚å¯ä»¥é€šè¿‡æŸ¥è¯¢ç½‘ç»œè¾“å‡ºç»´åº¦æ¥ç¡®å®šè¾“å‡ºç¼“å†²åŒºçš„ç›¸åº”å¤§å°ã€‚

    ```cpp
    auto input_idx = mEngine->getBindingIndex("input");
    assert(mEngine->getBindingDataType(input_idx) == nvinfer1::DataType::kFLOAT);
    auto input_dims = nvinfer1::Dims4{1, 3 /* channels */, height, width};
    context->setBindingDimensions(input_idx, input_dims);
    auto input_size = util::getMemorySize(input_dims, sizeof(float));
    auto output_idx = mEngine->getBindingIndex("output");
    assert(mEngine->getBindingDataType(output_idx) == nvinfer1::DataType::kINT32);
    auto output_dims = context->getBindingDimensions(output_idx);
    auto output_size = util::getMemorySize(output_dims, sizeof(int32_t));
    ```

    > æ³¨æ„ï¼šç½‘ç»œ I/O çš„ç»‘å®šç´¢å¼•å¯æŒ‰åç§°æŸ¥è¯¢ã€‚
3.  åœ¨å‡†å¤‡æ¨ç†æ—¶ï¼Œä¼šä¸ºæ‰€æœ‰è¾“å…¥å’Œè¾“å‡ºæ•°æ®åˆ†é… CUDA è®¾å¤‡å†…å­˜ï¼Œimage data is processed and copied into input memory, and a list of engine bindings is generated.

    å¯¹äºè¯­ä¹‰åˆ†å‰²ï¼Œè¾“å…¥å›¾åƒæ•°æ®çš„å¤„ç†æ–¹æ³•æ˜¯æ‹Ÿåˆåˆ°\[0, 1]èŒƒå›´å†…ï¼Œå¹¶ä½¿ç”¨å‡å€¼ \[0.485, 0.456, 0.406]å’Œstddeviation\[0.229, 0.224, 0.225] è¿›è¡Œå½’ä¸€åŒ–ã€‚è¯·å‚é˜…[æ­¤å¤„](https://github.com/pytorch/vision/blob/main/docs/source/models.rst) torchvisionæ¨¡å‹çš„é¢„å¤„ç†è¦æ±‚ã€‚è¯¥æ“ä½œç”±ç±»RGBImageReader æŠ½è±¡å‡ºæ¥ã€‚

    ```
    void* input_mem{nullptr}; cudaMalloc(&input_mem, input_size); void* output_mem{nullptr}; cudaMalloc(&output_mem, output_size); const std::vector<float> mean{0.485f, 0.456f, 0.406f}; const std::vector<float> stddev{0.229f, 0.224f, 0.225f}; auto input_image{util::RGBImageReader(input_filename, input_dims, mean, stddev)}; input_image.read(); auto input_buffer = input_image.process(); cudaMemcpyAsync(input_mem, input_buffer.get(), input_size, cudaMemcpyHostToDevice, stream)ï¼›
    ```
4.  æ¨ç†æ‰§è¡Œæ˜¯é€šè¿‡ä¸Šä¸‹æ–‡çš„executeV2æˆ–enqueueV2æ–¹æ³•å¯åŠ¨çš„ã€‚æ‰§è¡Œå®Œæˆåï¼Œæˆ‘ä»¬ä¼šå°†ç»“æœæ‹·è´å›ä¸»æœºç¼“å†²åŒºï¼Œå¹¶é‡Šæ”¾æ‰€æœ‰è®¾å¤‡å†…å­˜åˆ†é…ã€‚

    ```cpp
    void* input_mem{nullptr};
    cudaMalloc(&input_mem, input_size);
    void* output_mem{nullptr};
    cudaMalloc(&output_mem, output_size); 
    const std::vector<float> mean{0.485f, 0.456f, 0.406f};
    const std::vector<float> stddev{0.229f, 0.224f, 0.225f};
    auto input_image{util::RGBImageReader(input_filename, input_dims, mean, stddev)};
    input_image.read();
    auto input_buffer = input_image.process();
    cudaMemcpyAsync(input_mem, input_buffer.get(), input_size, cudaMemcpyHostToDevice, stream);
    ```
5.  å¯¹é¢„æµ‹ç»“æœè¿›è¡Œå¯è§†åŒ–

    ```
    const int num_classes{21};
    const std::vector<int> palette{(0x1 << 25) - 1, (0x1 << 15) - 1, (0x1 << 21) - 1};
    auto output_image{util::ArgmaxImageWriter(output_filename, output_dims, palette, num_classes)};
    output_image.process(output_buffer.get());
    output_image.write();
    ```

    æµ‹è¯•å›¾åƒçš„é¢„æœŸè¾“å‡ºå¦‚ä¸‹ï¼š

<figure><img src="../../.gitbook/assets/å›¾ç‰‡ (6).png" alt=""><figcaption></figcaption></figure>

#### åœ¨ Python ä¸­è¿è¡Œå¼•æ“

1.  å®‰è£…æ‰€éœ€çš„ Python åŒ…

    ```bash
    $ pip install pycuda
    ```
2.  å¯åŠ¨ Jupyter&#x20;

    ```bash
    $ jupyter notebook --port=8888 --no-browser --ip=0.0.0.0 --allow-root
    ```
3. æ‰“å¼€[tutorial-runtime.ipynb](https://github.com/NVIDIA/TensorRT/blob/main/quickstart/SemanticSegmentation/tutorial-runtime.ipynb)ç¬”è®°æœ¬å¹¶æŒ‰å…¶æ­¥éª¤æ“ä½œã€‚

TensorRT Python runtime API ä¸ C++ runtime APIä¸€ä¸€æ˜ å°„ã€‚





















